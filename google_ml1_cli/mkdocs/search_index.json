{
    "docs": [
        {
            "location": "/", 
            "text": "The \nml1\n command-line interface \n(CLI)\n allows to use most features of the \nGoogle Cloud Machine Learning Engine\n service from the comfort of your terminal.\n\n\nBy default all output is printed to standard out, but flags can be set to direct it into a file independent of your shell's\ncapabilities. Errors will be printed to standard error, and cause the program's exit code to be non-zero.\n\n\nIf data-structures are requested, these will be returned as pretty-printed JSON, to be useful as input to other tools.\n\n\nEverything else about the \nCloud Machine Learning Engine\n API can be found at the\n\nofficial documentation site\n.\n\n\nInstallation and Source Code\n\n\nInstall the command-line interface with cargo using:\n\n\ncargo install google-ml1-cli\n\n\n\n\nFind the source code \non github\n.\n\n\nUsage\n\n\nThis documentation was generated from the \nCloud Machine Learning Engine\n API at revision \n20190621\n. The CLI is at version \n1.0.10\n.\n\n\nml1 [options]\n        projects\n                get-config \nname\n [-p \nv\n]... [-o \nout\n]\n                jobs-cancel \nname\n (-r \nkv\n)... [-p \nv\n]... [-o \nout\n]\n                jobs-create \nparent\n (-r \nkv\n)... [-p \nv\n]... [-o \nout\n]\n                jobs-get \nname\n [-p \nv\n]... [-o \nout\n]\n                jobs-get-iam-policy \nresource\n [-p \nv\n]... [-o \nout\n]\n                jobs-list \nparent\n [-p \nv\n]... [-o \nout\n]\n                jobs-patch \nname\n (-r \nkv\n)... [-p \nv\n]... [-o \nout\n]\n                jobs-set-iam-policy \nresource\n (-r \nkv\n)... [-p \nv\n]... [-o \nout\n]\n                jobs-test-iam-permissions \nresource\n (-r \nkv\n)... [-p \nv\n]... [-o \nout\n]\n                locations-get \nname\n [-p \nv\n]... [-o \nout\n]\n                locations-list \nparent\n [-p \nv\n]... [-o \nout\n]\n                models-create \nparent\n (-r \nkv\n)... [-p \nv\n]... [-o \nout\n]\n                models-delete \nname\n [-p \nv\n]... [-o \nout\n]\n                models-get \nname\n [-p \nv\n]... [-o \nout\n]\n                models-get-iam-policy \nresource\n [-p \nv\n]... [-o \nout\n]\n                models-list \nparent\n [-p \nv\n]... [-o \nout\n]\n                models-patch \nname\n (-r \nkv\n)... [-p \nv\n]... [-o \nout\n]\n                models-set-iam-policy \nresource\n (-r \nkv\n)... [-p \nv\n]... [-o \nout\n]\n                models-test-iam-permissions \nresource\n (-r \nkv\n)... [-p \nv\n]... [-o \nout\n]\n                models-versions-create \nparent\n (-r \nkv\n)... [-p \nv\n]... [-o \nout\n]\n                models-versions-delete \nname\n [-p \nv\n]... [-o \nout\n]\n                models-versions-get \nname\n [-p \nv\n]... [-o \nout\n]\n                models-versions-list \nparent\n [-p \nv\n]... [-o \nout\n]\n                models-versions-patch \nname\n (-r \nkv\n)... [-p \nv\n]... [-o \nout\n]\n                models-versions-set-default \nname\n (-r \nkv\n)... [-p \nv\n]... [-o \nout\n]\n                operations-cancel \nname\n [-p \nv\n]... [-o \nout\n]\n                operations-get \nname\n [-p \nv\n]... [-o \nout\n]\n                operations-list \nname\n [-p \nv\n]... [-o \nout\n]\n                predict \nname\n (-r \nkv\n)... [-p \nv\n]... [-o \nout\n]\n  ml1 --help\n\nConfiguration:\n  [--scope \nurl\n]...\n            Specify the authentication a method should be executed in. Each scope\n            requires the user to grant this application permission to use it.\n            If unset, it defaults to the shortest scope url for a particular method.\n  --config-dir \nfolder\n\n            A directory into which we will store our persistent data. Defaults to\n            a user-writable directory that we will create during the first invocation.\n            [default: ~/.google-service-cli]\n  --debug\n            Output all server communication to standard error. `tx` and `rx` are placed\n            into the same stream.\n  --debug-auth\n            Output all communication related to authentication to standard error. `tx`\n            and `rx` are placed into the same stream.\n\n\n\n\n\nConfiguration\n\n\nThe program will store all persistent data in the \n~/.google-service-cli\n directory in \nJSON\n files prefixed with \nml1-\n.  You can change the directory used to store configuration with the \n--config-dir\n flag on a per-invocation basis.\n\n\nMore information about the various kinds of persistent data are given in the following paragraphs.\n\n\nAuthentication\n\n\nMost APIs require a user to authenticate any request. If this is the case, the \nscope\n determines the \nset of permissions granted. The granularity of these is usually no more than \nread-only\n or \nfull-access\n.\n\n\nIf not set, the system will automatically select the smallest feasible scope, e.g. when invoking a\nmethod that is read-only, it will ask only for a read-only scope. \nYou may use the \n--scope\n flag to specify a scope directly. \nAll applicable scopes are documented in the respective method's CLI documentation.\n\n\nThe first time a scope is used, the user is asked for permission. Follow the instructions given \nby the CLI to grant permissions, or to decline.\n\n\nIf a scope was authenticated by the user, the respective information will be stored as \nJSON\n in the configuration\ndirectory, e.g. \n~/.google-service-cli/ml1-token-\nscope-hash\n.json\n. No manual management of these tokens\nis necessary.\n\n\nTo revoke granted authentication, please refer to the \nofficial documentation\n.\n\n\nApplication Secrets\n\n\nIn order to allow any application to use Google services, it will need to be registered using the \n\nGoogle Developer Console\n. APIs the application may use are then enabled for it\none by one. Most APIs can be used for free and have a daily quota.\n\n\nTo allow more comfortable usage of the CLI without forcing anyone to register an own application, the CLI\ncomes with a default application secret that is configured accordingly. This also means that heavy usage\nall around the world may deplete the daily quota.\n\n\nYou can workaround this limitation by putting your own secrets file at this location: \n\n~/.google-service-cli/ml1-secret.json\n, assuming that the required \nml\n API \nwas enabled for it. Such a secret file can be downloaded in the \nGoogle Developer Console\n at \n\nAPIs \n auth -\n Credentials -\n Download JSON\n and used as is.\n\n\nLearn more about how to setup Google projects and enable APIs using the \nofficial documentation\n.\n\n\nDebugging\n\n\nEven though the CLI does its best to provide usable error messages, sometimes it might be desirable to know\nwhat exactly led to a particular issue. This is done by allowing all client-server communication to be \noutput to standard error \nas-is\n.\n\n\nThe \n--debug\n flag will print all client-server communication to standard error, whereas the \n--debug-auth\n flag\nwill cause all communication related to authentication to standard error.\nIf the \n--debug\n flag is set, error-results will be debug-printed, possibly yielding more information about the \nissue at hand.\n\n\nYou may consider redirecting standard error into a file for ease of use, e.g. \nml1 --debug \nresource\n \nmethod\n [options] 2\ndebug.txt\n.", 
            "title": "Home"
        }, 
        {
            "location": "/#installation-and-source-code", 
            "text": "Install the command-line interface with cargo using:  cargo install google-ml1-cli  Find the source code  on github .", 
            "title": "Installation and Source Code"
        }, 
        {
            "location": "/#usage", 
            "text": "This documentation was generated from the  Cloud Machine Learning Engine  API at revision  20190621 . The CLI is at version  1.0.10 .  ml1 [options]\n        projects\n                get-config  name  [-p  v ]... [-o  out ]\n                jobs-cancel  name  (-r  kv )... [-p  v ]... [-o  out ]\n                jobs-create  parent  (-r  kv )... [-p  v ]... [-o  out ]\n                jobs-get  name  [-p  v ]... [-o  out ]\n                jobs-get-iam-policy  resource  [-p  v ]... [-o  out ]\n                jobs-list  parent  [-p  v ]... [-o  out ]\n                jobs-patch  name  (-r  kv )... [-p  v ]... [-o  out ]\n                jobs-set-iam-policy  resource  (-r  kv )... [-p  v ]... [-o  out ]\n                jobs-test-iam-permissions  resource  (-r  kv )... [-p  v ]... [-o  out ]\n                locations-get  name  [-p  v ]... [-o  out ]\n                locations-list  parent  [-p  v ]... [-o  out ]\n                models-create  parent  (-r  kv )... [-p  v ]... [-o  out ]\n                models-delete  name  [-p  v ]... [-o  out ]\n                models-get  name  [-p  v ]... [-o  out ]\n                models-get-iam-policy  resource  [-p  v ]... [-o  out ]\n                models-list  parent  [-p  v ]... [-o  out ]\n                models-patch  name  (-r  kv )... [-p  v ]... [-o  out ]\n                models-set-iam-policy  resource  (-r  kv )... [-p  v ]... [-o  out ]\n                models-test-iam-permissions  resource  (-r  kv )... [-p  v ]... [-o  out ]\n                models-versions-create  parent  (-r  kv )... [-p  v ]... [-o  out ]\n                models-versions-delete  name  [-p  v ]... [-o  out ]\n                models-versions-get  name  [-p  v ]... [-o  out ]\n                models-versions-list  parent  [-p  v ]... [-o  out ]\n                models-versions-patch  name  (-r  kv )... [-p  v ]... [-o  out ]\n                models-versions-set-default  name  (-r  kv )... [-p  v ]... [-o  out ]\n                operations-cancel  name  [-p  v ]... [-o  out ]\n                operations-get  name  [-p  v ]... [-o  out ]\n                operations-list  name  [-p  v ]... [-o  out ]\n                predict  name  (-r  kv )... [-p  v ]... [-o  out ]\n  ml1 --help\n\nConfiguration:\n  [--scope  url ]...\n            Specify the authentication a method should be executed in. Each scope\n            requires the user to grant this application permission to use it.\n            If unset, it defaults to the shortest scope url for a particular method.\n  --config-dir  folder \n            A directory into which we will store our persistent data. Defaults to\n            a user-writable directory that we will create during the first invocation.\n            [default: ~/.google-service-cli]\n  --debug\n            Output all server communication to standard error. `tx` and `rx` are placed\n            into the same stream.\n  --debug-auth\n            Output all communication related to authentication to standard error. `tx`\n            and `rx` are placed into the same stream.", 
            "title": "Usage"
        }, 
        {
            "location": "/#configuration", 
            "text": "The program will store all persistent data in the  ~/.google-service-cli  directory in  JSON  files prefixed with  ml1- .  You can change the directory used to store configuration with the  --config-dir  flag on a per-invocation basis.  More information about the various kinds of persistent data are given in the following paragraphs.", 
            "title": "Configuration"
        }, 
        {
            "location": "/#authentication", 
            "text": "Most APIs require a user to authenticate any request. If this is the case, the  scope  determines the \nset of permissions granted. The granularity of these is usually no more than  read-only  or  full-access .  If not set, the system will automatically select the smallest feasible scope, e.g. when invoking a\nmethod that is read-only, it will ask only for a read-only scope. \nYou may use the  --scope  flag to specify a scope directly. \nAll applicable scopes are documented in the respective method's CLI documentation.  The first time a scope is used, the user is asked for permission. Follow the instructions given \nby the CLI to grant permissions, or to decline.  If a scope was authenticated by the user, the respective information will be stored as  JSON  in the configuration\ndirectory, e.g.  ~/.google-service-cli/ml1-token- scope-hash .json . No manual management of these tokens\nis necessary.  To revoke granted authentication, please refer to the  official documentation .", 
            "title": "Authentication"
        }, 
        {
            "location": "/#application-secrets", 
            "text": "In order to allow any application to use Google services, it will need to be registered using the  Google Developer Console . APIs the application may use are then enabled for it\none by one. Most APIs can be used for free and have a daily quota.  To allow more comfortable usage of the CLI without forcing anyone to register an own application, the CLI\ncomes with a default application secret that is configured accordingly. This also means that heavy usage\nall around the world may deplete the daily quota.  You can workaround this limitation by putting your own secrets file at this location:  ~/.google-service-cli/ml1-secret.json , assuming that the required  ml  API \nwas enabled for it. Such a secret file can be downloaded in the  Google Developer Console  at  APIs   auth -  Credentials -  Download JSON  and used as is.  Learn more about how to setup Google projects and enable APIs using the  official documentation .", 
            "title": "Application Secrets"
        }, 
        {
            "location": "/#debugging", 
            "text": "Even though the CLI does its best to provide usable error messages, sometimes it might be desirable to know\nwhat exactly led to a particular issue. This is done by allowing all client-server communication to be \noutput to standard error  as-is .  The  --debug  flag will print all client-server communication to standard error, whereas the  --debug-auth  flag\nwill cause all communication related to authentication to standard error.\nIf the  --debug  flag is set, error-results will be debug-printed, possibly yielding more information about the \nissue at hand.  You may consider redirecting standard error into a file for ease of use, e.g.  ml1 --debug  resource   method  [options] 2 debug.txt .", 
            "title": "Debugging"
        }, 
        {
            "location": "/projects_get-config/", 
            "text": "Get the service account information associated with your project. You need\nthis information in order to grant the service account permissions for\nthe Google Cloud Storage location where you put your model training code\nfor training the model with Google Cloud Machine Learning.\n\n\nScopes\n\n\nYou will need authorization for the \nhttps://www.googleapis.com/auth/cloud-platform\n scope to make a valid call.\n\n\nIf unset, the scope for this method defaults to \nhttps://www.googleapis.com/auth/cloud-platform\n.\nYou can set the scope for this method like this: \nml1 --scope \nscope\n projects get-config ...\n\n\nRequired Scalar Argument\n\n\n\n\nname\n \n(string)\n\n\nRequired. The project name.\n\n\n\n\n\n\n\n\nOptional Output Flags\n\n\nThe method's return value a JSON encoded structure, which will be written to standard output by default.\n\n\n\n\n-o out\n\n\nout\n specifies the \ndestination\n to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The \ndestination\n may be \n-\n to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.\n\n\n\n\n\n\n\n\nOptional General Properties\n\n\nThe following properties can configure any call, and are not specific to this method.\n\n\n\n\n\n\n-p $-xgafv=string\n\n\n\n\nV1 error format.\n\n\n\n\n\n\n\n\n-p access-token=string\n\n\n\n\nOAuth access token.\n\n\n\n\n\n\n\n\n-p alt=string\n\n\n\n\nData format for response.\n\n\n\n\n\n\n\n\n-p callback=string\n\n\n\n\nJSONP\n\n\n\n\n\n\n\n\n-p fields=string\n\n\n\n\nSelector specifying which fields to include in a partial response.\n\n\n\n\n\n\n\n\n-p key=string\n\n\n\n\nAPI key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.\n\n\n\n\n\n\n\n\n-p oauth-token=string\n\n\n\n\nOAuth 2.0 token for the current user.\n\n\n\n\n\n\n\n\n-p pretty-print=boolean\n\n\n\n\nReturns response with indentations and line breaks.\n\n\n\n\n\n\n\n\n-p quota-user=string\n\n\n\n\nAvailable to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.\n\n\n\n\n\n\n\n\n-p upload-type=string\n\n\n\n\nLegacy upload protocol for media (e.g. \nmedia\n, \nmultipart\n).\n\n\n\n\n\n\n\n\n-p upload-protocol=string\n\n\n\n\nUpload protocol for media (e.g. \nraw\n, \nmultipart\n).", 
            "title": "Get Config"
        }, 
        {
            "location": "/projects_get-config/#scopes", 
            "text": "You will need authorization for the  https://www.googleapis.com/auth/cloud-platform  scope to make a valid call.  If unset, the scope for this method defaults to  https://www.googleapis.com/auth/cloud-platform .\nYou can set the scope for this method like this:  ml1 --scope  scope  projects get-config ...", 
            "title": "Scopes"
        }, 
        {
            "location": "/projects_get-config/#required-scalar-argument", 
            "text": "name   (string)  Required. The project name.", 
            "title": "Required Scalar Argument"
        }, 
        {
            "location": "/projects_get-config/#optional-output-flags", 
            "text": "The method's return value a JSON encoded structure, which will be written to standard output by default.   -o out  out  specifies the  destination  to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The  destination  may be  -  to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.", 
            "title": "Optional Output Flags"
        }, 
        {
            "location": "/projects_get-config/#optional-general-properties", 
            "text": "The following properties can configure any call, and are not specific to this method.    -p $-xgafv=string   V1 error format.     -p access-token=string   OAuth access token.     -p alt=string   Data format for response.     -p callback=string   JSONP     -p fields=string   Selector specifying which fields to include in a partial response.     -p key=string   API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.     -p oauth-token=string   OAuth 2.0 token for the current user.     -p pretty-print=boolean   Returns response with indentations and line breaks.     -p quota-user=string   Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.     -p upload-type=string   Legacy upload protocol for media (e.g.  media ,  multipart ).     -p upload-protocol=string   Upload protocol for media (e.g.  raw ,  multipart ).", 
            "title": "Optional General Properties"
        }, 
        {
            "location": "/projects_jobs-cancel/", 
            "text": "Cancels a running job.\n\n\nScopes\n\n\nYou will need authorization for the \nhttps://www.googleapis.com/auth/cloud-platform\n scope to make a valid call.\n\n\nIf unset, the scope for this method defaults to \nhttps://www.googleapis.com/auth/cloud-platform\n.\nYou can set the scope for this method like this: \nml1 --scope \nscope\n projects jobs-cancel ...\n\n\nRequired Scalar Argument\n\n\n\n\nname\n \n(string)\n\n\nRequired. The name of the job to cancel.\n\n\n\n\n\n\n\n\nRequired Request Value\n\n\nThe request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure.\nIn the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely.\n\n\nFor example, a structure like this:\n\n\nGoogleCloudMlV1__CancelJobRequest:\n\n\n\n\n\ncan be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time.\n\n\nAbout Cursors\n\n\nThe cursor position is key to comfortably set complex nested structures. The following rules apply:\n\n\n\n\nThe cursor position is always set relative to the current one, unless the field name starts with the \n.\n character. Fields can be nested such as in \n-r f.s.o\n .\n\n\nThe cursor position is set relative to the top-level structure if it starts with \n.\n, e.g. \n-r .s.s\n\n\nYou can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify \n-r struct.sub_struct=bar\n.\n\n\nYou can move the cursor one level up by using \n..\n. Each additional \n.\n moves it up one additional level. E.g. \n...\n would go three levels up.\n\n\n\n\nOptional Output Flags\n\n\nThe method's return value a JSON encoded structure, which will be written to standard output by default.\n\n\n\n\n-o out\n\n\nout\n specifies the \ndestination\n to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The \ndestination\n may be \n-\n to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.\n\n\n\n\n\n\n\n\nOptional General Properties\n\n\nThe following properties can configure any call, and are not specific to this method.\n\n\n\n\n\n\n-p $-xgafv=string\n\n\n\n\nV1 error format.\n\n\n\n\n\n\n\n\n-p access-token=string\n\n\n\n\nOAuth access token.\n\n\n\n\n\n\n\n\n-p alt=string\n\n\n\n\nData format for response.\n\n\n\n\n\n\n\n\n-p callback=string\n\n\n\n\nJSONP\n\n\n\n\n\n\n\n\n-p fields=string\n\n\n\n\nSelector specifying which fields to include in a partial response.\n\n\n\n\n\n\n\n\n-p key=string\n\n\n\n\nAPI key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.\n\n\n\n\n\n\n\n\n-p oauth-token=string\n\n\n\n\nOAuth 2.0 token for the current user.\n\n\n\n\n\n\n\n\n-p pretty-print=boolean\n\n\n\n\nReturns response with indentations and line breaks.\n\n\n\n\n\n\n\n\n-p quota-user=string\n\n\n\n\nAvailable to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.\n\n\n\n\n\n\n\n\n-p upload-type=string\n\n\n\n\nLegacy upload protocol for media (e.g. \nmedia\n, \nmultipart\n).\n\n\n\n\n\n\n\n\n-p upload-protocol=string\n\n\n\n\nUpload protocol for media (e.g. \nraw\n, \nmultipart\n).", 
            "title": "Jobs Cancel"
        }, 
        {
            "location": "/projects_jobs-cancel/#scopes", 
            "text": "You will need authorization for the  https://www.googleapis.com/auth/cloud-platform  scope to make a valid call.  If unset, the scope for this method defaults to  https://www.googleapis.com/auth/cloud-platform .\nYou can set the scope for this method like this:  ml1 --scope  scope  projects jobs-cancel ...", 
            "title": "Scopes"
        }, 
        {
            "location": "/projects_jobs-cancel/#required-scalar-argument", 
            "text": "name   (string)  Required. The name of the job to cancel.", 
            "title": "Required Scalar Argument"
        }, 
        {
            "location": "/projects_jobs-cancel/#required-request-value", 
            "text": "The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure.\nIn the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely.  For example, a structure like this:  GoogleCloudMlV1__CancelJobRequest:  can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time.", 
            "title": "Required Request Value"
        }, 
        {
            "location": "/projects_jobs-cancel/#about-cursors", 
            "text": "The cursor position is key to comfortably set complex nested structures. The following rules apply:   The cursor position is always set relative to the current one, unless the field name starts with the  .  character. Fields can be nested such as in  -r f.s.o  .  The cursor position is set relative to the top-level structure if it starts with  . , e.g.  -r .s.s  You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify  -r struct.sub_struct=bar .  You can move the cursor one level up by using  .. . Each additional  .  moves it up one additional level. E.g.  ...  would go three levels up.", 
            "title": "About Cursors"
        }, 
        {
            "location": "/projects_jobs-cancel/#optional-output-flags", 
            "text": "The method's return value a JSON encoded structure, which will be written to standard output by default.   -o out  out  specifies the  destination  to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The  destination  may be  -  to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.", 
            "title": "Optional Output Flags"
        }, 
        {
            "location": "/projects_jobs-cancel/#optional-general-properties", 
            "text": "The following properties can configure any call, and are not specific to this method.    -p $-xgafv=string   V1 error format.     -p access-token=string   OAuth access token.     -p alt=string   Data format for response.     -p callback=string   JSONP     -p fields=string   Selector specifying which fields to include in a partial response.     -p key=string   API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.     -p oauth-token=string   OAuth 2.0 token for the current user.     -p pretty-print=boolean   Returns response with indentations and line breaks.     -p quota-user=string   Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.     -p upload-type=string   Legacy upload protocol for media (e.g.  media ,  multipart ).     -p upload-protocol=string   Upload protocol for media (e.g.  raw ,  multipart ).", 
            "title": "Optional General Properties"
        }, 
        {
            "location": "/projects_jobs-create/", 
            "text": "Creates a training or a batch prediction job.\n\n\nScopes\n\n\nYou will need authorization for the \nhttps://www.googleapis.com/auth/cloud-platform\n scope to make a valid call.\n\n\nIf unset, the scope for this method defaults to \nhttps://www.googleapis.com/auth/cloud-platform\n.\nYou can set the scope for this method like this: \nml1 --scope \nscope\n projects jobs-create ...\n\n\nRequired Scalar Argument\n\n\n\n\nparent\n \n(string)\n\n\nRequired. The project name.\n\n\n\n\n\n\n\n\nRequired Request Value\n\n\nThe request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure.\nIn the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely.\n\n\nFor example, a structure like this:\n\n\nGoogleCloudMlV1__Job:\n  create-time: string\n  end-time: string\n  error-message: string\n  etag: string\n  job-id: string\n  labels: { string: string }\n  prediction-input:\n    batch-size: string\n    data-format: string\n    input-paths: [string]\n    max-worker-count: int64\n    model-name: string\n    output-data-format: string\n    output-path: string\n    region: string\n    runtime-version: string\n    signature-name: string\n    uri: string\n    version-name: string\n  prediction-output:\n    error-count: int64\n    node-hours: number\n    output-path: string\n    prediction-count: int64\n  start-time: string\n  state: string\n  training-input:\n    args: [string]\n    hyperparameters:\n      algorithm: string\n      enable-trial-early-stopping: boolean\n      goal: string\n      hyperparameter-metric-tag: string\n      max-failed-trials: integer\n      max-parallel-trials: integer\n      max-trials: integer\n      resume-previous-job-id: string\n    job-dir: string\n    master-config:\n      accelerator-config:\n        count: string\n        type: string\n      image-uri: string\n      tpu-tf-version: string\n    master-type: string\n    max-running-time: string\n    package-uris: [string]\n    parameter-server-config:\n      accelerator-config:\n        count: string\n        type: string\n      image-uri: string\n      tpu-tf-version: string\n    parameter-server-count: int64\n    parameter-server-type: string\n    python-module: string\n    python-version: string\n    region: string\n    runtime-version: string\n    scale-tier: string\n    worker-config:\n      accelerator-config:\n        count: string\n        type: string\n      image-uri: string\n      tpu-tf-version: string\n    worker-count: int64\n    worker-type: string\n  training-output:\n    built-in-algorithm-output:\n      framework: string\n      model-path: string\n      python-version: string\n      runtime-version: string\n    completed-trial-count: int64\n    consumed-ml-units: number\n    hyperparameter-metric-tag: string\n    is-built-in-algorithm-job: boolean\n    is-hyperparameter-tuning-job: boolean\n\n\n\n\n\ncan be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time.\n\n\n\n\n-r .    create-time=eirmod\n\n\nOutput only. When the job was created.\n\n\n\n\n\n\nend-time=sit\n\n\nOutput only. When the job processing was completed.\n\n\n\n\n\n\nerror-message=stet\n\n\nOutput only. The details of a failure or a cancellation.\n\n\n\n\n\n\netag=sed\n\n\netag\n is used for optimistic concurrency control as a way to help\n    prevent simultaneous updates of a job from overwriting each other.\n    It is strongly suggested that systems make use of the \netag\n in the\n    read-modify-write cycle to perform job updates in order to avoid race\n    conditions: An \netag\n is returned in the response to \nGetJob\n, and\n    systems are expected to put that etag in the request to \nUpdateJob\n to\n    ensure that their change will be applied to the same version of the job.\n\n\n\n\n\n\njob-id=et\n\n\nRequired. The user-specified id of the job.\n\n\n\n\n\n\nlabels=key=dolores\n\n\nOptional. One or more labels that you can add, to organize your jobs.\n    Each label is a key-value pair, where both the key and the value are\n    arbitrary strings that you supply.\n    For more information, see the documentation on\n    \na href=\n/ml-engine/docs/tensorflow/resource-labels\nusing labels\n/a\n.\n\n\nthe value will be associated with the given \nkey\n\n\n\n\n\n\nprediction-input    batch-size=kasd\n\n\nOptional. Number of records per batch, defaults to 64.\n    The service will buffer batch_size number of records in memory before\n    invoking one Tensorflow prediction call internally. So take the record\n    size and memory available into consideration when setting this parameter.\n\n\n\n\n\n\ndata-format=accusam\n\n\nRequired. The format of the input data files.\n\n\n\n\n\n\ninput-paths=takimata\n\n\nRequired. The Cloud Storage location of the input data files. May contain\n    \na href=\n/storage/docs/gsutil/addlhelp/WildcardNames\nwildcards\n/a\n.\n\n\nEach invocation of this argument appends the given value to the array.\n\n\n\n\n\n\nmax-worker-count=-70\n\n\nOptional. The maximum number of workers to be used for parallel processing.\n    Defaults to 10 if not specified.\n\n\n\n\n\n\n\n\nmodel-name=amet.\n\n\n\n\n\n\nUse this field if you want to use the default version for the specified\n    model. The string must use the following format:\n\n\n#34;projects/YOUR_PROJECT/models/YOUR_MODEL\n#34;\n\n* \noutput-data-format=erat\n\n    - Optional. Format of the output data files, defaults to JSON.\n* \noutput-path=labore\n\n    - Required. The output Google Cloud Storage location.\n* \nregion=sea\n\n    - Required. The Google Compute Engine region to run the prediction job in.\nSee the \na href=\n/ml-engine/docs/tensorflow/regions\navailable regions\n/a\n\nfor AI Platform services.\n* \nruntime-version=nonumy\n\n    - Optional. The AI Platform runtime version to use for this batch\nprediction. If not set, AI Platform will pick the runtime version used\nduring the CreateVersion request for this model version, or choose the\nlatest stable version when model version information is not available\nsuch as when the model is specified by uri.\n* \nsignature-name=dolores\n\n    - Optional. The name of the signature defined in the SavedModel to use for\nthis job. Please refer to\n\nSavedModel\n\nfor information about how to use signatures.\n\n\nDefaults to\n\nDEFAULT_SERVING_SIGNATURE_DEF_KEY\n\n, which is \nserving_default\n.\n* \nuri=gubergren\n\n    - Use this field if you want to specify a Google Cloud Storage path for\nthe model to use.\n* \nversion-name=sadipscing\n\n    - Use this field if you want to specify a version of the model to use. The\nstring is formatted the same way as \nmodel_version\n, with the addition\nof the version information:\n\n\n#34;projects/YOUR_PROJECT/models/YOUR_MODEL/versions/YOUR_VERSION\n#34;\n\n\n\n\n\n\n\n\n\n\n..prediction-output    error-count=-31\n\n\n\n\nThe number of data instances which resulted in errors.\n\n\n\n\n\n\nnode-hours=0.348101942899\n\n\nNode hours used by the batch prediction job.\n\n\n\n\n\n\noutput-path=no\n\n\nThe output Google Cloud Storage location provided at the job creation time.\n\n\n\n\n\n\n\n\nprediction-count=-21\n\n\n\n\nThe number of generated predictions.\n\n\n\n\n\n\n\n\n..    start-time=justo\n\n\n\n\nOutput only. When the job processing was started.\n\n\n\n\n\n\nstate=et\n\n\nOutput only. The detailed state of a job.\n\n\n\n\n\n\ntraining-input    args=et\n\n\nOptional. Command line arguments to pass to the program.\n\n\nEach invocation of this argument appends the given value to the array.\n\n\n\n\n\n\nhyperparameters    algorithm=diam\n\n\nOptional. The search algorithm specified for the hyperparameter\n    tuning job.\n    Uses the default AI Platform hyperparameter tuning\n    algorithm if unspecified.\n\n\n\n\n\n\nenable-trial-early-stopping=false\n\n\nOptional. Indicates if the hyperparameter tuning job enables auto trial\n    early stopping.\n\n\n\n\n\n\n\n\ngoal=lorem\n\n\n\n\n\n\nRequired. The type of goal to use for tuning. Available types are\n    \nMAXIMIZE\n and \nMINIMIZE\n.\n\n\nDefaults to \nMAXIMIZE\n.\n* \nhyperparameter-metric-tag=et\n\n    - Optional. The TensorFlow summary tag name to use for optimizing trials. For\ncurrent versions of TensorFlow, this tag name should exactly match what is\nshown in TensorBoard, including all scopes.  For versions of TensorFlow\nprior to 0.12, this should be only the tag passed to tf.Summary.\nBy default, \ntraining/hptuning/metric\n will be used.\n* \nmax-failed-trials=31\n\n    - Optional. The number of failed trials that need to be seen before failing\nthe hyperparameter tuning job. You can specify this field to override the\ndefault failing criteria for AI Platform hyperparameter tuning jobs.\n\n\nDefaults to zero, which means the service decides when a hyperparameter\njob should fail.\n* \nmax-parallel-trials=69\n\n    - Optional. The number of training trials to run concurrently.\nYou can reduce the time it takes to perform hyperparameter tuning by adding\ntrials in parallel. However, each trail only benefits from the information\ngained in completed trials. That means that a trial does not get access to\nthe results of trials running at the same time, which could reduce the\nquality of the overall optimization.\n\n\nEach trial will use the same scale tier and machine types.\n\n\nDefaults to one.\n* \nmax-trials=92\n\n    - Optional. How many training trials should be attempted to optimize\nthe specified hyperparameters.\n\n\nDefaults to one.\n* \nresume-previous-job-id=lorem\n\n    - Optional. The prior hyperparameter tuning job id that users hope to\ncontinue with. The job id will be used to find the corresponding vizier\nstudy guid and resume the study.\n\n\n\n\n\n\n\n\n\n\n..    job-dir=eos\n\n\n\n\nOptional. A Google Cloud Storage path in which to store training outputs\n    and other data needed for training. This path is passed to your TensorFlow\n    program as the \n--job-dir\n command-line argument. The benefit of specifying\n    this field is that Cloud ML validates the path for use in training.\n\n\n\n\n\n\nmaster-config.accelerator-config    count=erat\n\n\nThe number of accelerators to attach to each machine running the job.\n\n\n\n\n\n\n\n\ntype=sadipscing\n\n\n\n\nThe type of accelerator to use.\n\n\n\n\n\n\n\n\n..    image-uri=dolor\n\n\n\n\nThe Docker image to run on the replica. This image must be in Container\n    Registry. Learn more about \nconfiguring custom\n    containers\n.\n\n\n\n\n\n\n\n\ntpu-tf-version=eirmod\n\n\n\n\nTensorFlow version used in the custom container. This field is required if\n    the replica is a TPU worker that uses a custom container. Otherwise, do not\n    specify this field.\n\n\n\n\n\n\n\n\n..    master-type=elitr\n\n\n\n\n\n\nOptional. Specifies the type of virtual machine to use for your training\n    job\ns master worker.\n\n\nThe following types are supported:\n\n\ndl\n\n  \ndt\nstandard\n/dt\n\n  \ndd\n\n  A basic machine configuration suitable for training simple models with\n  small to moderate datasets.\n  \n/dd\n\n  \ndt\nlarge_model\n/dt\n\n  \ndd\n\n  A machine with a lot of memory, specially suited for parameter servers\n  when your model is large (having many hidden layers or layers with very\n  large numbers of nodes).\n  \n/dd\n\n  \ndt\ncomplex_model_s\n/dt\n\n  \ndd\n\n  A machine suitable for the master and workers of the cluster when your\n  model requires more computation than the standard machine can handle\n  satisfactorily.\n  \n/dd\n\n  \ndt\ncomplex_model_m\n/dt\n\n  \ndd\n\n  A machine with roughly twice the number of cores and roughly double the\n  memory of \ni\ncomplex_model_s\n/i\n.\n  \n/dd\n\n  \ndt\ncomplex_model_l\n/dt\n\n  \ndd\n\n  A machine with roughly twice the number of cores and roughly double the\n  memory of \ni\ncomplex_model_m\n/i\n.\n  \n/dd\n\n  \ndt\nstandard_gpu\n/dt\n\n  \ndd\n\n  A machine equivalent to \ni\nstandard\n/i\n that\n  also includes a single NVIDIA Tesla K80 GPU. See more about\n  \na href=\n/ml-engine/docs/tensorflow/using-gpus\nusing GPUs to\n  train your model\n/a\n.\n  \n/dd\n\n  \ndt\ncomplex_model_m_gpu\n/dt\n\n  \ndd\n\n  A machine equivalent to \ni\ncomplex_model_m\n/i\n that also includes\n  four NVIDIA Tesla K80 GPUs.\n  \n/dd\n\n  \ndt\ncomplex_model_l_gpu\n/dt\n\n  \ndd\n\n  A machine equivalent to \ni\ncomplex_model_l\n/i\n that also includes\n  eight NVIDIA Tesla K80 GPUs.\n  \n/dd\n\n  \ndt\nstandard_p100\n/dt\n\n  \ndd\n\n  A machine equivalent to \ni\nstandard\n/i\n that\n  also includes a single NVIDIA Tesla P100 GPU.\n  \n/dd\n\n  \ndt\ncomplex_model_m_p100\n/dt\n\n  \ndd\n\n  A machine equivalent to \ni\ncomplex_model_m\n/i\n that also includes\n  four NVIDIA Tesla P100 GPUs.\n  \n/dd\n\n  \ndt\nstandard_v100\n/dt\n\n  \ndd\n\n  A machine equivalent to \ni\nstandard\n/i\n that\n  also includes a single NVIDIA Tesla V100 GPU.\n  \n/dd\n\n  \ndt\nlarge_model_v100\n/dt\n\n  \ndd\n\n  A machine equivalent to \ni\nlarge_model\n/i\n that\n  also includes a single NVIDIA Tesla V100 GPU.\n  \n/dd\n\n  \ndt\ncomplex_model_m_v100\n/dt\n\n  \ndd\n\n  A machine equivalent to \ni\ncomplex_model_m\n/i\n that\n  also includes four NVIDIA Tesla V100 GPUs.\n  \n/dd\n\n  \ndt\ncomplex_model_l_v100\n/dt\n\n  \ndd\n\n  A machine equivalent to \ni\ncomplex_model_l\n/i\n that\n  also includes eight NVIDIA Tesla V100 GPUs.\n  \n/dd\n\n  \ndt\ncloud_tpu\n/dt\n\n  \ndd\n\n  A TPU VM including one Cloud TPU. See more about\n  \na href=\n/ml-engine/docs/tensorflow/using-tpus\nusing TPUs to train\n  your model\n/a\n.\n  \n/dd\n\n\n/dl\n\n\nYou may also use certain Compute Engine machine types directly in this\nfield. The following types are supported:\n\n\n\n\nn1-standard-4\n\n\nn1-standard-8\n\n\nn1-standard-16\n\n\nn1-standard-32\n\n\nn1-standard-64\n\n\nn1-standard-96\n\n\nn1-highmem-2\n\n\nn1-highmem-4\n\n\nn1-highmem-8\n\n\nn1-highmem-16\n\n\nn1-highmem-32\n\n\nn1-highmem-64\n\n\nn1-highmem-96\n\n\nn1-highcpu-16\n\n\nn1-highcpu-32\n\n\nn1-highcpu-64\n\n\nn1-highcpu-96\n\n\n\n\nSee more about \nusing Compute Engine machine\ntypes\n.\n\n\nYou must set this value when \nscaleTier\n is set to \nCUSTOM\n.\n* \nmax-running-time=amet\n\n    - Optional. The maximum job running time. The default is 7 days.\n* \npackage-uris=no\n\n    - Required. The Google Cloud Storage location of the packages with\nthe training program and any additional dependencies.\nThe maximum number of package URIs is 100.\n    - Each invocation of this argument appends the given value to the array.\n* \nparameter-server-config.accelerator-config    count=labore\n\n    - The number of accelerators to attach to each machine running the job.\n* \ntype=eirmod\n\n    - The type of accelerator to use.\n\n\n\n\n\n\n\n\n\n\n..    image-uri=dolore\n\n\n\n\nThe Docker image to run on the replica. This image must be in Container\n    Registry. Learn more about \nconfiguring custom\n    containers\n.\n\n\n\n\n\n\n\n\ntpu-tf-version=invidunt\n\n\n\n\nTensorFlow version used in the custom container. This field is required if\n    the replica is a TPU worker that uses a custom container. Otherwise, do not\n    specify this field.\n\n\n\n\n\n\n\n\n..    parameter-server-count=-82\n\n\n\n\n\n\nOptional. The number of parameter server replicas to use for the training\n    job. Each replica in the cluster will be of the type specified in\n    \nparameter_server_type\n.\n\n\nThis value can only be used when \nscale_tier\n is set to \nCUSTOM\n.If you\nset this value, you must also set \nparameter_server_type\n.\n\n\nThe default value is zero.\n* \nparameter-server-type=accusam\n\n    - Optional. Specifies the type of virtual machine to use for your training\njob\ns parameter server.\n\n\nThe supported values are the same as those described in the entry for\n\nmaster_type\n.\n\n\nThis value must be consistent with the category of machine type that\n\nmasterType\n uses. In other words, both must be AI Platform machine\ntypes or both must be Compute Engine machine types.\n\n\nThis value must be present when \nscaleTier\n is set to \nCUSTOM\n and\n\nparameter_server_count\n is greater than zero.\n* \npython-module=lorem\n\n    - Required. The Python module name to run after installing the packages.\n* \npython-version=sea\n\n    - Optional. The version of Python used in training. If not set, the default\nversion is \n2.7\n. Python \n3.5\n is available when \nruntime_version\n is set\nto \n1.4\n and above. Python \n2.7\n works with all supported\n\na href=\n/ml-engine/docs/runtime-version-list\nruntime versions\n/a\n.\n* \nregion=et\n\n    - Required. The Google Compute Engine region to run the training job in.\nSee the \na href=\n/ml-engine/docs/tensorflow/regions\navailable regions\n/a\n\nfor AI Platform services.\n* \nruntime-version=duo\n\n    - Optional. The AI Platform runtime version to use for training. If not\nset, AI Platform uses the default stable version, 1.0. For more\ninformation, see the\n\na href=\n/ml-engine/docs/runtime-version-list\nruntime version list\n/a\n\nand\n\na href=\n/ml-engine/docs/versioning\nhow to manage runtime versions\n/a\n.\n* \nscale-tier=et\n\n    - Required. Specifies the machine types, the number of replicas for workers\nand parameter servers.\n* \nworker-config.accelerator-config    count=eirmod\n\n    - The number of accelerators to attach to each machine running the job.\n* \ntype=sanctus\n\n    - The type of accelerator to use.\n\n\n\n\n\n\n\n\n\n\n..    image-uri=et\n\n\n\n\nThe Docker image to run on the replica. This image must be in Container\n    Registry. Learn more about \nconfiguring custom\n    containers\n.\n\n\n\n\n\n\n\n\ntpu-tf-version=amet\n\n\n\n\nTensorFlow version used in the custom container. This field is required if\n    the replica is a TPU worker that uses a custom container. Otherwise, do not\n    specify this field.\n\n\n\n\n\n\n\n\n..    worker-count=-23\n\n\n\n\n\n\nOptional. The number of worker replicas to use for the training job. Each\n    replica in the cluster will be of the type specified in \nworker_type\n.\n\n\nThis value can only be used when \nscale_tier\n is set to \nCUSTOM\n. If you\nset this value, you must also set \nworker_type\n.\n\n\nThe default value is zero.\n* \nworker-type=consetetur\n\n    - Optional. Specifies the type of virtual machine to use for your training\njob\ns worker nodes.\n\n\nThe supported values are the same as those described in the entry for\n\nmasterType\n.\n\n\nThis value must be consistent with the category of machine type that\n\nmasterType\n uses. In other words, both must be AI Platform machine\ntypes or both must be Compute Engine machine types.\n\n\nIf you use \ncloud_tpu\n for this value, see special instructions for\n\nconfiguring a custom TPU\nmachine\n.\n\n\nThis value must be present when \nscaleTier\n is set to \nCUSTOM\n and\n\nworkerCount\n is greater than zero.\n\n\n\n\n\n\n\n\n\n\n..training-output.built-in-algorithm-output    framework=ut\n\n\n\n\nFramework on which the built-in algorithm was trained.\n\n\n\n\n\n\nmodel-path=ea\n\n\nThe Cloud Storage path to the \nmodel/\n directory where the training job\n    saves the trained model. Only set for successful jobs that don\nt use\n    hyperparameter tuning.\n\n\n\n\n\n\npython-version=sed\n\n\nPython version on which the built-in algorithm was trained.\n\n\n\n\n\n\n\n\nruntime-version=dolor\n\n\n\n\nAI Platform runtime version on which the built-in algorithm was\n    trained.\n\n\n\n\n\n\n\n\n..    completed-trial-count=-48\n\n\n\n\nThe number of hyperparameter tuning trials that completed successfully.\n    Only set for hyperparameter tuning jobs.\n\n\n\n\n\n\nconsumed-ml-units=0.528448098786\n\n\nThe amount of ML units consumed by the job.\n\n\n\n\n\n\nhyperparameter-metric-tag=et\n\n\nThe TensorFlow summary tag name used for optimizing hyperparameter tuning\n    trials. See\n    \nHyperparameterSpec.hyperparameterMetricTag\n\n    for more information. Only set for hyperparameter tuning jobs.\n\n\n\n\n\n\nis-built-in-algorithm-job=false\n\n\nWhether this job is a built-in Algorithm job.\n\n\n\n\n\n\nis-hyperparameter-tuning-job=false\n\n\nWhether this job is a hyperparameter tuning job.\n\n\n\n\n\n\n\n\nAbout Cursors\n\n\nThe cursor position is key to comfortably set complex nested structures. The following rules apply:\n\n\n\n\nThe cursor position is always set relative to the current one, unless the field name starts with the \n.\n character. Fields can be nested such as in \n-r f.s.o\n .\n\n\nThe cursor position is set relative to the top-level structure if it starts with \n.\n, e.g. \n-r .s.s\n\n\nYou can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify \n-r struct.sub_struct=bar\n.\n\n\nYou can move the cursor one level up by using \n..\n. Each additional \n.\n moves it up one additional level. E.g. \n...\n would go three levels up.\n\n\n\n\nOptional Output Flags\n\n\nThe method's return value a JSON encoded structure, which will be written to standard output by default.\n\n\n\n\n-o out\n\n\nout\n specifies the \ndestination\n to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The \ndestination\n may be \n-\n to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.\n\n\n\n\n\n\n\n\nOptional General Properties\n\n\nThe following properties can configure any call, and are not specific to this method.\n\n\n\n\n\n\n-p $-xgafv=string\n\n\n\n\nV1 error format.\n\n\n\n\n\n\n\n\n-p access-token=string\n\n\n\n\nOAuth access token.\n\n\n\n\n\n\n\n\n-p alt=string\n\n\n\n\nData format for response.\n\n\n\n\n\n\n\n\n-p callback=string\n\n\n\n\nJSONP\n\n\n\n\n\n\n\n\n-p fields=string\n\n\n\n\nSelector specifying which fields to include in a partial response.\n\n\n\n\n\n\n\n\n-p key=string\n\n\n\n\nAPI key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.\n\n\n\n\n\n\n\n\n-p oauth-token=string\n\n\n\n\nOAuth 2.0 token for the current user.\n\n\n\n\n\n\n\n\n-p pretty-print=boolean\n\n\n\n\nReturns response with indentations and line breaks.\n\n\n\n\n\n\n\n\n-p quota-user=string\n\n\n\n\nAvailable to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.\n\n\n\n\n\n\n\n\n-p upload-type=string\n\n\n\n\nLegacy upload protocol for media (e.g. \nmedia\n, \nmultipart\n).\n\n\n\n\n\n\n\n\n-p upload-protocol=string\n\n\n\n\nUpload protocol for media (e.g. \nraw\n, \nmultipart\n).", 
            "title": "Jobs Create"
        }, 
        {
            "location": "/projects_jobs-create/#scopes", 
            "text": "You will need authorization for the  https://www.googleapis.com/auth/cloud-platform  scope to make a valid call.  If unset, the scope for this method defaults to  https://www.googleapis.com/auth/cloud-platform .\nYou can set the scope for this method like this:  ml1 --scope  scope  projects jobs-create ...", 
            "title": "Scopes"
        }, 
        {
            "location": "/projects_jobs-create/#required-scalar-argument", 
            "text": "parent   (string)  Required. The project name.", 
            "title": "Required Scalar Argument"
        }, 
        {
            "location": "/projects_jobs-create/#required-request-value", 
            "text": "The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure.\nIn the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely.  For example, a structure like this:  GoogleCloudMlV1__Job:\n  create-time: string\n  end-time: string\n  error-message: string\n  etag: string\n  job-id: string\n  labels: { string: string }\n  prediction-input:\n    batch-size: string\n    data-format: string\n    input-paths: [string]\n    max-worker-count: int64\n    model-name: string\n    output-data-format: string\n    output-path: string\n    region: string\n    runtime-version: string\n    signature-name: string\n    uri: string\n    version-name: string\n  prediction-output:\n    error-count: int64\n    node-hours: number\n    output-path: string\n    prediction-count: int64\n  start-time: string\n  state: string\n  training-input:\n    args: [string]\n    hyperparameters:\n      algorithm: string\n      enable-trial-early-stopping: boolean\n      goal: string\n      hyperparameter-metric-tag: string\n      max-failed-trials: integer\n      max-parallel-trials: integer\n      max-trials: integer\n      resume-previous-job-id: string\n    job-dir: string\n    master-config:\n      accelerator-config:\n        count: string\n        type: string\n      image-uri: string\n      tpu-tf-version: string\n    master-type: string\n    max-running-time: string\n    package-uris: [string]\n    parameter-server-config:\n      accelerator-config:\n        count: string\n        type: string\n      image-uri: string\n      tpu-tf-version: string\n    parameter-server-count: int64\n    parameter-server-type: string\n    python-module: string\n    python-version: string\n    region: string\n    runtime-version: string\n    scale-tier: string\n    worker-config:\n      accelerator-config:\n        count: string\n        type: string\n      image-uri: string\n      tpu-tf-version: string\n    worker-count: int64\n    worker-type: string\n  training-output:\n    built-in-algorithm-output:\n      framework: string\n      model-path: string\n      python-version: string\n      runtime-version: string\n    completed-trial-count: int64\n    consumed-ml-units: number\n    hyperparameter-metric-tag: string\n    is-built-in-algorithm-job: boolean\n    is-hyperparameter-tuning-job: boolean  can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time.   -r .    create-time=eirmod  Output only. When the job was created.    end-time=sit  Output only. When the job processing was completed.    error-message=stet  Output only. The details of a failure or a cancellation.    etag=sed  etag  is used for optimistic concurrency control as a way to help\n    prevent simultaneous updates of a job from overwriting each other.\n    It is strongly suggested that systems make use of the  etag  in the\n    read-modify-write cycle to perform job updates in order to avoid race\n    conditions: An  etag  is returned in the response to  GetJob , and\n    systems are expected to put that etag in the request to  UpdateJob  to\n    ensure that their change will be applied to the same version of the job.    job-id=et  Required. The user-specified id of the job.    labels=key=dolores  Optional. One or more labels that you can add, to organize your jobs.\n    Each label is a key-value pair, where both the key and the value are\n    arbitrary strings that you supply.\n    For more information, see the documentation on\n     a href= /ml-engine/docs/tensorflow/resource-labels using labels /a .  the value will be associated with the given  key    prediction-input    batch-size=kasd  Optional. Number of records per batch, defaults to 64.\n    The service will buffer batch_size number of records in memory before\n    invoking one Tensorflow prediction call internally. So take the record\n    size and memory available into consideration when setting this parameter.    data-format=accusam  Required. The format of the input data files.    input-paths=takimata  Required. The Cloud Storage location of the input data files. May contain\n     a href= /storage/docs/gsutil/addlhelp/WildcardNames wildcards /a .  Each invocation of this argument appends the given value to the array.    max-worker-count=-70  Optional. The maximum number of workers to be used for parallel processing.\n    Defaults to 10 if not specified.     model-name=amet.    Use this field if you want to use the default version for the specified\n    model. The string must use the following format:  #34;projects/YOUR_PROJECT/models/YOUR_MODEL #34; \n*  output-data-format=erat \n    - Optional. Format of the output data files, defaults to JSON.\n*  output-path=labore \n    - Required. The output Google Cloud Storage location.\n*  region=sea \n    - Required. The Google Compute Engine region to run the prediction job in.\nSee the  a href= /ml-engine/docs/tensorflow/regions available regions /a \nfor AI Platform services.\n*  runtime-version=nonumy \n    - Optional. The AI Platform runtime version to use for this batch\nprediction. If not set, AI Platform will pick the runtime version used\nduring the CreateVersion request for this model version, or choose the\nlatest stable version when model version information is not available\nsuch as when the model is specified by uri.\n*  signature-name=dolores \n    - Optional. The name of the signature defined in the SavedModel to use for\nthis job. Please refer to SavedModel \nfor information about how to use signatures.  Defaults to DEFAULT_SERVING_SIGNATURE_DEF_KEY \n, which is  serving_default .\n*  uri=gubergren \n    - Use this field if you want to specify a Google Cloud Storage path for\nthe model to use.\n*  version-name=sadipscing \n    - Use this field if you want to specify a version of the model to use. The\nstring is formatted the same way as  model_version , with the addition\nof the version information:  #34;projects/YOUR_PROJECT/models/YOUR_MODEL/versions/YOUR_VERSION #34;      ..prediction-output    error-count=-31   The number of data instances which resulted in errors.    node-hours=0.348101942899  Node hours used by the batch prediction job.    output-path=no  The output Google Cloud Storage location provided at the job creation time.     prediction-count=-21   The number of generated predictions.     ..    start-time=justo   Output only. When the job processing was started.    state=et  Output only. The detailed state of a job.    training-input    args=et  Optional. Command line arguments to pass to the program.  Each invocation of this argument appends the given value to the array.    hyperparameters    algorithm=diam  Optional. The search algorithm specified for the hyperparameter\n    tuning job.\n    Uses the default AI Platform hyperparameter tuning\n    algorithm if unspecified.    enable-trial-early-stopping=false  Optional. Indicates if the hyperparameter tuning job enables auto trial\n    early stopping.     goal=lorem    Required. The type of goal to use for tuning. Available types are\n     MAXIMIZE  and  MINIMIZE .  Defaults to  MAXIMIZE .\n*  hyperparameter-metric-tag=et \n    - Optional. The TensorFlow summary tag name to use for optimizing trials. For\ncurrent versions of TensorFlow, this tag name should exactly match what is\nshown in TensorBoard, including all scopes.  For versions of TensorFlow\nprior to 0.12, this should be only the tag passed to tf.Summary.\nBy default,  training/hptuning/metric  will be used.\n*  max-failed-trials=31 \n    - Optional. The number of failed trials that need to be seen before failing\nthe hyperparameter tuning job. You can specify this field to override the\ndefault failing criteria for AI Platform hyperparameter tuning jobs.  Defaults to zero, which means the service decides when a hyperparameter\njob should fail.\n*  max-parallel-trials=69 \n    - Optional. The number of training trials to run concurrently.\nYou can reduce the time it takes to perform hyperparameter tuning by adding\ntrials in parallel. However, each trail only benefits from the information\ngained in completed trials. That means that a trial does not get access to\nthe results of trials running at the same time, which could reduce the\nquality of the overall optimization.  Each trial will use the same scale tier and machine types.  Defaults to one.\n*  max-trials=92 \n    - Optional. How many training trials should be attempted to optimize\nthe specified hyperparameters.  Defaults to one.\n*  resume-previous-job-id=lorem \n    - Optional. The prior hyperparameter tuning job id that users hope to\ncontinue with. The job id will be used to find the corresponding vizier\nstudy guid and resume the study.      ..    job-dir=eos   Optional. A Google Cloud Storage path in which to store training outputs\n    and other data needed for training. This path is passed to your TensorFlow\n    program as the  --job-dir  command-line argument. The benefit of specifying\n    this field is that Cloud ML validates the path for use in training.    master-config.accelerator-config    count=erat  The number of accelerators to attach to each machine running the job.     type=sadipscing   The type of accelerator to use.     ..    image-uri=dolor   The Docker image to run on the replica. This image must be in Container\n    Registry. Learn more about  configuring custom\n    containers .     tpu-tf-version=eirmod   TensorFlow version used in the custom container. This field is required if\n    the replica is a TPU worker that uses a custom container. Otherwise, do not\n    specify this field.     ..    master-type=elitr    Optional. Specifies the type of virtual machine to use for your training\n    job s master worker.  The following types are supported:  dl \n   dt standard /dt \n   dd \n  A basic machine configuration suitable for training simple models with\n  small to moderate datasets.\n   /dd \n   dt large_model /dt \n   dd \n  A machine with a lot of memory, specially suited for parameter servers\n  when your model is large (having many hidden layers or layers with very\n  large numbers of nodes).\n   /dd \n   dt complex_model_s /dt \n   dd \n  A machine suitable for the master and workers of the cluster when your\n  model requires more computation than the standard machine can handle\n  satisfactorily.\n   /dd \n   dt complex_model_m /dt \n   dd \n  A machine with roughly twice the number of cores and roughly double the\n  memory of  i complex_model_s /i .\n   /dd \n   dt complex_model_l /dt \n   dd \n  A machine with roughly twice the number of cores and roughly double the\n  memory of  i complex_model_m /i .\n   /dd \n   dt standard_gpu /dt \n   dd \n  A machine equivalent to  i standard /i  that\n  also includes a single NVIDIA Tesla K80 GPU. See more about\n   a href= /ml-engine/docs/tensorflow/using-gpus using GPUs to\n  train your model /a .\n   /dd \n   dt complex_model_m_gpu /dt \n   dd \n  A machine equivalent to  i complex_model_m /i  that also includes\n  four NVIDIA Tesla K80 GPUs.\n   /dd \n   dt complex_model_l_gpu /dt \n   dd \n  A machine equivalent to  i complex_model_l /i  that also includes\n  eight NVIDIA Tesla K80 GPUs.\n   /dd \n   dt standard_p100 /dt \n   dd \n  A machine equivalent to  i standard /i  that\n  also includes a single NVIDIA Tesla P100 GPU.\n   /dd \n   dt complex_model_m_p100 /dt \n   dd \n  A machine equivalent to  i complex_model_m /i  that also includes\n  four NVIDIA Tesla P100 GPUs.\n   /dd \n   dt standard_v100 /dt \n   dd \n  A machine equivalent to  i standard /i  that\n  also includes a single NVIDIA Tesla V100 GPU.\n   /dd \n   dt large_model_v100 /dt \n   dd \n  A machine equivalent to  i large_model /i  that\n  also includes a single NVIDIA Tesla V100 GPU.\n   /dd \n   dt complex_model_m_v100 /dt \n   dd \n  A machine equivalent to  i complex_model_m /i  that\n  also includes four NVIDIA Tesla V100 GPUs.\n   /dd \n   dt complex_model_l_v100 /dt \n   dd \n  A machine equivalent to  i complex_model_l /i  that\n  also includes eight NVIDIA Tesla V100 GPUs.\n   /dd \n   dt cloud_tpu /dt \n   dd \n  A TPU VM including one Cloud TPU. See more about\n   a href= /ml-engine/docs/tensorflow/using-tpus using TPUs to train\n  your model /a .\n   /dd  /dl  You may also use certain Compute Engine machine types directly in this\nfield. The following types are supported:   n1-standard-4  n1-standard-8  n1-standard-16  n1-standard-32  n1-standard-64  n1-standard-96  n1-highmem-2  n1-highmem-4  n1-highmem-8  n1-highmem-16  n1-highmem-32  n1-highmem-64  n1-highmem-96  n1-highcpu-16  n1-highcpu-32  n1-highcpu-64  n1-highcpu-96   See more about  using Compute Engine machine\ntypes .  You must set this value when  scaleTier  is set to  CUSTOM .\n*  max-running-time=amet \n    - Optional. The maximum job running time. The default is 7 days.\n*  package-uris=no \n    - Required. The Google Cloud Storage location of the packages with\nthe training program and any additional dependencies.\nThe maximum number of package URIs is 100.\n    - Each invocation of this argument appends the given value to the array.\n*  parameter-server-config.accelerator-config    count=labore \n    - The number of accelerators to attach to each machine running the job.\n*  type=eirmod \n    - The type of accelerator to use.      ..    image-uri=dolore   The Docker image to run on the replica. This image must be in Container\n    Registry. Learn more about  configuring custom\n    containers .     tpu-tf-version=invidunt   TensorFlow version used in the custom container. This field is required if\n    the replica is a TPU worker that uses a custom container. Otherwise, do not\n    specify this field.     ..    parameter-server-count=-82    Optional. The number of parameter server replicas to use for the training\n    job. Each replica in the cluster will be of the type specified in\n     parameter_server_type .  This value can only be used when  scale_tier  is set to  CUSTOM .If you\nset this value, you must also set  parameter_server_type .  The default value is zero.\n*  parameter-server-type=accusam \n    - Optional. Specifies the type of virtual machine to use for your training\njob s parameter server.  The supported values are the same as those described in the entry for master_type .  This value must be consistent with the category of machine type that masterType  uses. In other words, both must be AI Platform machine\ntypes or both must be Compute Engine machine types.  This value must be present when  scaleTier  is set to  CUSTOM  and parameter_server_count  is greater than zero.\n*  python-module=lorem \n    - Required. The Python module name to run after installing the packages.\n*  python-version=sea \n    - Optional. The version of Python used in training. If not set, the default\nversion is  2.7 . Python  3.5  is available when  runtime_version  is set\nto  1.4  and above. Python  2.7  works with all supported a href= /ml-engine/docs/runtime-version-list runtime versions /a .\n*  region=et \n    - Required. The Google Compute Engine region to run the training job in.\nSee the  a href= /ml-engine/docs/tensorflow/regions available regions /a \nfor AI Platform services.\n*  runtime-version=duo \n    - Optional. The AI Platform runtime version to use for training. If not\nset, AI Platform uses the default stable version, 1.0. For more\ninformation, see the a href= /ml-engine/docs/runtime-version-list runtime version list /a \nand a href= /ml-engine/docs/versioning how to manage runtime versions /a .\n*  scale-tier=et \n    - Required. Specifies the machine types, the number of replicas for workers\nand parameter servers.\n*  worker-config.accelerator-config    count=eirmod \n    - The number of accelerators to attach to each machine running the job.\n*  type=sanctus \n    - The type of accelerator to use.      ..    image-uri=et   The Docker image to run on the replica. This image must be in Container\n    Registry. Learn more about  configuring custom\n    containers .     tpu-tf-version=amet   TensorFlow version used in the custom container. This field is required if\n    the replica is a TPU worker that uses a custom container. Otherwise, do not\n    specify this field.     ..    worker-count=-23    Optional. The number of worker replicas to use for the training job. Each\n    replica in the cluster will be of the type specified in  worker_type .  This value can only be used when  scale_tier  is set to  CUSTOM . If you\nset this value, you must also set  worker_type .  The default value is zero.\n*  worker-type=consetetur \n    - Optional. Specifies the type of virtual machine to use for your training\njob s worker nodes.  The supported values are the same as those described in the entry for masterType .  This value must be consistent with the category of machine type that masterType  uses. In other words, both must be AI Platform machine\ntypes or both must be Compute Engine machine types.  If you use  cloud_tpu  for this value, see special instructions for configuring a custom TPU\nmachine .  This value must be present when  scaleTier  is set to  CUSTOM  and workerCount  is greater than zero.      ..training-output.built-in-algorithm-output    framework=ut   Framework on which the built-in algorithm was trained.    model-path=ea  The Cloud Storage path to the  model/  directory where the training job\n    saves the trained model. Only set for successful jobs that don t use\n    hyperparameter tuning.    python-version=sed  Python version on which the built-in algorithm was trained.     runtime-version=dolor   AI Platform runtime version on which the built-in algorithm was\n    trained.     ..    completed-trial-count=-48   The number of hyperparameter tuning trials that completed successfully.\n    Only set for hyperparameter tuning jobs.    consumed-ml-units=0.528448098786  The amount of ML units consumed by the job.    hyperparameter-metric-tag=et  The TensorFlow summary tag name used for optimizing hyperparameter tuning\n    trials. See\n     HyperparameterSpec.hyperparameterMetricTag \n    for more information. Only set for hyperparameter tuning jobs.    is-built-in-algorithm-job=false  Whether this job is a built-in Algorithm job.    is-hyperparameter-tuning-job=false  Whether this job is a hyperparameter tuning job.", 
            "title": "Required Request Value"
        }, 
        {
            "location": "/projects_jobs-create/#about-cursors", 
            "text": "The cursor position is key to comfortably set complex nested structures. The following rules apply:   The cursor position is always set relative to the current one, unless the field name starts with the  .  character. Fields can be nested such as in  -r f.s.o  .  The cursor position is set relative to the top-level structure if it starts with  . , e.g.  -r .s.s  You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify  -r struct.sub_struct=bar .  You can move the cursor one level up by using  .. . Each additional  .  moves it up one additional level. E.g.  ...  would go three levels up.", 
            "title": "About Cursors"
        }, 
        {
            "location": "/projects_jobs-create/#optional-output-flags", 
            "text": "The method's return value a JSON encoded structure, which will be written to standard output by default.   -o out  out  specifies the  destination  to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The  destination  may be  -  to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.", 
            "title": "Optional Output Flags"
        }, 
        {
            "location": "/projects_jobs-create/#optional-general-properties", 
            "text": "The following properties can configure any call, and are not specific to this method.    -p $-xgafv=string   V1 error format.     -p access-token=string   OAuth access token.     -p alt=string   Data format for response.     -p callback=string   JSONP     -p fields=string   Selector specifying which fields to include in a partial response.     -p key=string   API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.     -p oauth-token=string   OAuth 2.0 token for the current user.     -p pretty-print=boolean   Returns response with indentations and line breaks.     -p quota-user=string   Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.     -p upload-type=string   Legacy upload protocol for media (e.g.  media ,  multipart ).     -p upload-protocol=string   Upload protocol for media (e.g.  raw ,  multipart ).", 
            "title": "Optional General Properties"
        }, 
        {
            "location": "/projects_jobs-get/", 
            "text": "Describes a job.\n\n\nScopes\n\n\nYou will need authorization for the \nhttps://www.googleapis.com/auth/cloud-platform\n scope to make a valid call.\n\n\nIf unset, the scope for this method defaults to \nhttps://www.googleapis.com/auth/cloud-platform\n.\nYou can set the scope for this method like this: \nml1 --scope \nscope\n projects jobs-get ...\n\n\nRequired Scalar Argument\n\n\n\n\nname\n \n(string)\n\n\nRequired. The name of the job to get the description of.\n\n\n\n\n\n\n\n\nOptional Output Flags\n\n\nThe method's return value a JSON encoded structure, which will be written to standard output by default.\n\n\n\n\n-o out\n\n\nout\n specifies the \ndestination\n to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The \ndestination\n may be \n-\n to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.\n\n\n\n\n\n\n\n\nOptional General Properties\n\n\nThe following properties can configure any call, and are not specific to this method.\n\n\n\n\n\n\n-p $-xgafv=string\n\n\n\n\nV1 error format.\n\n\n\n\n\n\n\n\n-p access-token=string\n\n\n\n\nOAuth access token.\n\n\n\n\n\n\n\n\n-p alt=string\n\n\n\n\nData format for response.\n\n\n\n\n\n\n\n\n-p callback=string\n\n\n\n\nJSONP\n\n\n\n\n\n\n\n\n-p fields=string\n\n\n\n\nSelector specifying which fields to include in a partial response.\n\n\n\n\n\n\n\n\n-p key=string\n\n\n\n\nAPI key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.\n\n\n\n\n\n\n\n\n-p oauth-token=string\n\n\n\n\nOAuth 2.0 token for the current user.\n\n\n\n\n\n\n\n\n-p pretty-print=boolean\n\n\n\n\nReturns response with indentations and line breaks.\n\n\n\n\n\n\n\n\n-p quota-user=string\n\n\n\n\nAvailable to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.\n\n\n\n\n\n\n\n\n-p upload-type=string\n\n\n\n\nLegacy upload protocol for media (e.g. \nmedia\n, \nmultipart\n).\n\n\n\n\n\n\n\n\n-p upload-protocol=string\n\n\n\n\nUpload protocol for media (e.g. \nraw\n, \nmultipart\n).", 
            "title": "Jobs Get"
        }, 
        {
            "location": "/projects_jobs-get/#scopes", 
            "text": "You will need authorization for the  https://www.googleapis.com/auth/cloud-platform  scope to make a valid call.  If unset, the scope for this method defaults to  https://www.googleapis.com/auth/cloud-platform .\nYou can set the scope for this method like this:  ml1 --scope  scope  projects jobs-get ...", 
            "title": "Scopes"
        }, 
        {
            "location": "/projects_jobs-get/#required-scalar-argument", 
            "text": "name   (string)  Required. The name of the job to get the description of.", 
            "title": "Required Scalar Argument"
        }, 
        {
            "location": "/projects_jobs-get/#optional-output-flags", 
            "text": "The method's return value a JSON encoded structure, which will be written to standard output by default.   -o out  out  specifies the  destination  to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The  destination  may be  -  to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.", 
            "title": "Optional Output Flags"
        }, 
        {
            "location": "/projects_jobs-get/#optional-general-properties", 
            "text": "The following properties can configure any call, and are not specific to this method.    -p $-xgafv=string   V1 error format.     -p access-token=string   OAuth access token.     -p alt=string   Data format for response.     -p callback=string   JSONP     -p fields=string   Selector specifying which fields to include in a partial response.     -p key=string   API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.     -p oauth-token=string   OAuth 2.0 token for the current user.     -p pretty-print=boolean   Returns response with indentations and line breaks.     -p quota-user=string   Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.     -p upload-type=string   Legacy upload protocol for media (e.g.  media ,  multipart ).     -p upload-protocol=string   Upload protocol for media (e.g.  raw ,  multipart ).", 
            "title": "Optional General Properties"
        }, 
        {
            "location": "/projects_jobs-get-iam-policy/", 
            "text": "Gets the access control policy for a resource.\nReturns an empty policy if the resource exists and does not have a policy\nset.\n\n\nScopes\n\n\nYou will need authorization for the \nhttps://www.googleapis.com/auth/cloud-platform\n scope to make a valid call.\n\n\nIf unset, the scope for this method defaults to \nhttps://www.googleapis.com/auth/cloud-platform\n.\nYou can set the scope for this method like this: \nml1 --scope \nscope\n projects jobs-get-iam-policy ...\n\n\nRequired Scalar Argument\n\n\n\n\nresource\n \n(string)\n\n\nREQUIRED: The resource for which the policy is being requested.\n    See the operation documentation for the appropriate value for this field.\n\n\n\n\n\n\n\n\nOptional Output Flags\n\n\nThe method's return value a JSON encoded structure, which will be written to standard output by default.\n\n\n\n\n-o out\n\n\nout\n specifies the \ndestination\n to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The \ndestination\n may be \n-\n to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.\n\n\n\n\n\n\n\n\nOptional General Properties\n\n\nThe following properties can configure any call, and are not specific to this method.\n\n\n\n\n\n\n-p $-xgafv=string\n\n\n\n\nV1 error format.\n\n\n\n\n\n\n\n\n-p access-token=string\n\n\n\n\nOAuth access token.\n\n\n\n\n\n\n\n\n-p alt=string\n\n\n\n\nData format for response.\n\n\n\n\n\n\n\n\n-p callback=string\n\n\n\n\nJSONP\n\n\n\n\n\n\n\n\n-p fields=string\n\n\n\n\nSelector specifying which fields to include in a partial response.\n\n\n\n\n\n\n\n\n-p key=string\n\n\n\n\nAPI key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.\n\n\n\n\n\n\n\n\n-p oauth-token=string\n\n\n\n\nOAuth 2.0 token for the current user.\n\n\n\n\n\n\n\n\n-p pretty-print=boolean\n\n\n\n\nReturns response with indentations and line breaks.\n\n\n\n\n\n\n\n\n-p quota-user=string\n\n\n\n\nAvailable to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.\n\n\n\n\n\n\n\n\n-p upload-type=string\n\n\n\n\nLegacy upload protocol for media (e.g. \nmedia\n, \nmultipart\n).\n\n\n\n\n\n\n\n\n-p upload-protocol=string\n\n\n\n\nUpload protocol for media (e.g. \nraw\n, \nmultipart\n).", 
            "title": "Jobs Get Iam Policy"
        }, 
        {
            "location": "/projects_jobs-get-iam-policy/#scopes", 
            "text": "You will need authorization for the  https://www.googleapis.com/auth/cloud-platform  scope to make a valid call.  If unset, the scope for this method defaults to  https://www.googleapis.com/auth/cloud-platform .\nYou can set the scope for this method like this:  ml1 --scope  scope  projects jobs-get-iam-policy ...", 
            "title": "Scopes"
        }, 
        {
            "location": "/projects_jobs-get-iam-policy/#required-scalar-argument", 
            "text": "resource   (string)  REQUIRED: The resource for which the policy is being requested.\n    See the operation documentation for the appropriate value for this field.", 
            "title": "Required Scalar Argument"
        }, 
        {
            "location": "/projects_jobs-get-iam-policy/#optional-output-flags", 
            "text": "The method's return value a JSON encoded structure, which will be written to standard output by default.   -o out  out  specifies the  destination  to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The  destination  may be  -  to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.", 
            "title": "Optional Output Flags"
        }, 
        {
            "location": "/projects_jobs-get-iam-policy/#optional-general-properties", 
            "text": "The following properties can configure any call, and are not specific to this method.    -p $-xgafv=string   V1 error format.     -p access-token=string   OAuth access token.     -p alt=string   Data format for response.     -p callback=string   JSONP     -p fields=string   Selector specifying which fields to include in a partial response.     -p key=string   API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.     -p oauth-token=string   OAuth 2.0 token for the current user.     -p pretty-print=boolean   Returns response with indentations and line breaks.     -p quota-user=string   Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.     -p upload-type=string   Legacy upload protocol for media (e.g.  media ,  multipart ).     -p upload-protocol=string   Upload protocol for media (e.g.  raw ,  multipart ).", 
            "title": "Optional General Properties"
        }, 
        {
            "location": "/projects_jobs-list/", 
            "text": "Lists the jobs in the project.\n\n\nIf there are no jobs that match the request parameters, the list\nrequest returns an empty response body: {}.\n\n\nScopes\n\n\nYou will need authorization for the \nhttps://www.googleapis.com/auth/cloud-platform\n scope to make a valid call.\n\n\nIf unset, the scope for this method defaults to \nhttps://www.googleapis.com/auth/cloud-platform\n.\nYou can set the scope for this method like this: \nml1 --scope \nscope\n projects jobs-list ...\n\n\nRequired Scalar Argument\n\n\n\n\nparent\n \n(string)\n\n\nRequired. The name of the project for which to list jobs.\n\n\n\n\n\n\n\n\nOptional Output Flags\n\n\nThe method's return value a JSON encoded structure, which will be written to standard output by default.\n\n\n\n\n-o out\n\n\nout\n specifies the \ndestination\n to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The \ndestination\n may be \n-\n to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.\n\n\n\n\n\n\n\n\nOptional Method Properties\n\n\nYou may set the following properties to further configure the call. Please note that \n-p\n is followed by one \nor more key-value-pairs, and is called like this \n-p k1=v1 k2=v2\n even though the listing below repeats the\n\n-p\n for completeness.\n\n\n\n\n\n\n-p filter=string\n\n\n\n\nOptional. Specifies the subset of jobs to retrieve.\n    You can filter on the value of one or more attributes of the job object.\n    For example, retrieve jobs with a job identifier that starts with \ncensus\n:\n    \np\ncode\ngcloud ai-platform jobs list --filter=\njobId:census\n/code\n\n    \np\nList all failed jobs with names that start with \nrnn\n:\n    \np\ncode\ngcloud ai-platform jobs list --filter=\njobId:rnn\n\n    AND state:FAILED\n/code\n\n    \np\nFor more examples, see the guide to\n    \na href=\n/ml-engine/docs/tensorflow/monitor-training\nmonitoring jobs\n/a\n.\n\n\n\n\n\n\n\n\n-p page-size=integer\n\n\n\n\n\n\nOptional. The number of jobs to retrieve per \npage\n of results. If there\n    are more remaining results than this number, the response message will\n    contain a valid value in the \nnext_page_token\n field.\n\n\nThe default value is 20, and the maximum page size is 100.\n\n\n\n\n\n\n\n\n\n\n-p page-token=string\n\n\n\n\n\n\nOptional. A page token to request the next page of results.\n\n\nYou get the token from the \nnext_page_token\n field of the response from\nthe previous call.\n\n\n\n\n\n\n\n\n\n\nOptional General Properties\n\n\nThe following properties can configure any call, and are not specific to this method.\n\n\n\n\n\n\n-p $-xgafv=string\n\n\n\n\nV1 error format.\n\n\n\n\n\n\n\n\n-p access-token=string\n\n\n\n\nOAuth access token.\n\n\n\n\n\n\n\n\n-p alt=string\n\n\n\n\nData format for response.\n\n\n\n\n\n\n\n\n-p callback=string\n\n\n\n\nJSONP\n\n\n\n\n\n\n\n\n-p fields=string\n\n\n\n\nSelector specifying which fields to include in a partial response.\n\n\n\n\n\n\n\n\n-p key=string\n\n\n\n\nAPI key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.\n\n\n\n\n\n\n\n\n-p oauth-token=string\n\n\n\n\nOAuth 2.0 token for the current user.\n\n\n\n\n\n\n\n\n-p pretty-print=boolean\n\n\n\n\nReturns response with indentations and line breaks.\n\n\n\n\n\n\n\n\n-p quota-user=string\n\n\n\n\nAvailable to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.\n\n\n\n\n\n\n\n\n-p upload-type=string\n\n\n\n\nLegacy upload protocol for media (e.g. \nmedia\n, \nmultipart\n).\n\n\n\n\n\n\n\n\n-p upload-protocol=string\n\n\n\n\nUpload protocol for media (e.g. \nraw\n, \nmultipart\n).", 
            "title": "Jobs List"
        }, 
        {
            "location": "/projects_jobs-list/#scopes", 
            "text": "You will need authorization for the  https://www.googleapis.com/auth/cloud-platform  scope to make a valid call.  If unset, the scope for this method defaults to  https://www.googleapis.com/auth/cloud-platform .\nYou can set the scope for this method like this:  ml1 --scope  scope  projects jobs-list ...", 
            "title": "Scopes"
        }, 
        {
            "location": "/projects_jobs-list/#required-scalar-argument", 
            "text": "parent   (string)  Required. The name of the project for which to list jobs.", 
            "title": "Required Scalar Argument"
        }, 
        {
            "location": "/projects_jobs-list/#optional-output-flags", 
            "text": "The method's return value a JSON encoded structure, which will be written to standard output by default.   -o out  out  specifies the  destination  to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The  destination  may be  -  to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.", 
            "title": "Optional Output Flags"
        }, 
        {
            "location": "/projects_jobs-list/#optional-method-properties", 
            "text": "You may set the following properties to further configure the call. Please note that  -p  is followed by one \nor more key-value-pairs, and is called like this  -p k1=v1 k2=v2  even though the listing below repeats the -p  for completeness.    -p filter=string   Optional. Specifies the subset of jobs to retrieve.\n    You can filter on the value of one or more attributes of the job object.\n    For example, retrieve jobs with a job identifier that starts with  census :\n     p code gcloud ai-platform jobs list --filter= jobId:census /code \n     p List all failed jobs with names that start with  rnn :\n     p code gcloud ai-platform jobs list --filter= jobId:rnn \n    AND state:FAILED /code \n     p For more examples, see the guide to\n     a href= /ml-engine/docs/tensorflow/monitor-training monitoring jobs /a .     -p page-size=integer    Optional. The number of jobs to retrieve per  page  of results. If there\n    are more remaining results than this number, the response message will\n    contain a valid value in the  next_page_token  field.  The default value is 20, and the maximum page size is 100.      -p page-token=string    Optional. A page token to request the next page of results.  You get the token from the  next_page_token  field of the response from\nthe previous call.", 
            "title": "Optional Method Properties"
        }, 
        {
            "location": "/projects_jobs-list/#optional-general-properties", 
            "text": "The following properties can configure any call, and are not specific to this method.    -p $-xgafv=string   V1 error format.     -p access-token=string   OAuth access token.     -p alt=string   Data format for response.     -p callback=string   JSONP     -p fields=string   Selector specifying which fields to include in a partial response.     -p key=string   API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.     -p oauth-token=string   OAuth 2.0 token for the current user.     -p pretty-print=boolean   Returns response with indentations and line breaks.     -p quota-user=string   Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.     -p upload-type=string   Legacy upload protocol for media (e.g.  media ,  multipart ).     -p upload-protocol=string   Upload protocol for media (e.g.  raw ,  multipart ).", 
            "title": "Optional General Properties"
        }, 
        {
            "location": "/projects_jobs-patch/", 
            "text": "Updates a specific job resource.\n\n\nCurrently the only supported fields to update are \nlabels\n.\n\n\nScopes\n\n\nYou will need authorization for the \nhttps://www.googleapis.com/auth/cloud-platform\n scope to make a valid call.\n\n\nIf unset, the scope for this method defaults to \nhttps://www.googleapis.com/auth/cloud-platform\n.\nYou can set the scope for this method like this: \nml1 --scope \nscope\n projects jobs-patch ...\n\n\nRequired Scalar Argument\n\n\n\n\nname\n \n(string)\n\n\nRequired. The job name.\n\n\n\n\n\n\n\n\nRequired Request Value\n\n\nThe request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure.\nIn the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely.\n\n\nFor example, a structure like this:\n\n\nGoogleCloudMlV1__Job:\n  create-time: string\n  end-time: string\n  error-message: string\n  etag: string\n  job-id: string\n  labels: { string: string }\n  prediction-input:\n    batch-size: string\n    data-format: string\n    input-paths: [string]\n    max-worker-count: int64\n    model-name: string\n    output-data-format: string\n    output-path: string\n    region: string\n    runtime-version: string\n    signature-name: string\n    uri: string\n    version-name: string\n  prediction-output:\n    error-count: int64\n    node-hours: number\n    output-path: string\n    prediction-count: int64\n  start-time: string\n  state: string\n  training-input:\n    args: [string]\n    hyperparameters:\n      algorithm: string\n      enable-trial-early-stopping: boolean\n      goal: string\n      hyperparameter-metric-tag: string\n      max-failed-trials: integer\n      max-parallel-trials: integer\n      max-trials: integer\n      resume-previous-job-id: string\n    job-dir: string\n    master-config:\n      accelerator-config:\n        count: string\n        type: string\n      image-uri: string\n      tpu-tf-version: string\n    master-type: string\n    max-running-time: string\n    package-uris: [string]\n    parameter-server-config:\n      accelerator-config:\n        count: string\n        type: string\n      image-uri: string\n      tpu-tf-version: string\n    parameter-server-count: int64\n    parameter-server-type: string\n    python-module: string\n    python-version: string\n    region: string\n    runtime-version: string\n    scale-tier: string\n    worker-config:\n      accelerator-config:\n        count: string\n        type: string\n      image-uri: string\n      tpu-tf-version: string\n    worker-count: int64\n    worker-type: string\n  training-output:\n    built-in-algorithm-output:\n      framework: string\n      model-path: string\n      python-version: string\n      runtime-version: string\n    completed-trial-count: int64\n    consumed-ml-units: number\n    hyperparameter-metric-tag: string\n    is-built-in-algorithm-job: boolean\n    is-hyperparameter-tuning-job: boolean\n\n\n\n\n\ncan be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time.\n\n\n\n\n-r .    create-time=voluptua.\n\n\nOutput only. When the job was created.\n\n\n\n\n\n\nend-time=lorem\n\n\nOutput only. When the job processing was completed.\n\n\n\n\n\n\nerror-message=gubergren\n\n\nOutput only. The details of a failure or a cancellation.\n\n\n\n\n\n\netag=justo\n\n\netag\n is used for optimistic concurrency control as a way to help\n    prevent simultaneous updates of a job from overwriting each other.\n    It is strongly suggested that systems make use of the \netag\n in the\n    read-modify-write cycle to perform job updates in order to avoid race\n    conditions: An \netag\n is returned in the response to \nGetJob\n, and\n    systems are expected to put that etag in the request to \nUpdateJob\n to\n    ensure that their change will be applied to the same version of the job.\n\n\n\n\n\n\njob-id=sit\n\n\nRequired. The user-specified id of the job.\n\n\n\n\n\n\nlabels=key=vero\n\n\nOptional. One or more labels that you can add, to organize your jobs.\n    Each label is a key-value pair, where both the key and the value are\n    arbitrary strings that you supply.\n    For more information, see the documentation on\n    \na href=\n/ml-engine/docs/tensorflow/resource-labels\nusing labels\n/a\n.\n\n\nthe value will be associated with the given \nkey\n\n\n\n\n\n\nprediction-input    batch-size=diam\n\n\nOptional. Number of records per batch, defaults to 64.\n    The service will buffer batch_size number of records in memory before\n    invoking one Tensorflow prediction call internally. So take the record\n    size and memory available into consideration when setting this parameter.\n\n\n\n\n\n\ndata-format=rebum.\n\n\nRequired. The format of the input data files.\n\n\n\n\n\n\ninput-paths=consetetur\n\n\nRequired. The Cloud Storage location of the input data files. May contain\n    \na href=\n/storage/docs/gsutil/addlhelp/WildcardNames\nwildcards\n/a\n.\n\n\nEach invocation of this argument appends the given value to the array.\n\n\n\n\n\n\nmax-worker-count=-44\n\n\nOptional. The maximum number of workers to be used for parallel processing.\n    Defaults to 10 if not specified.\n\n\n\n\n\n\n\n\nmodel-name=vero\n\n\n\n\n\n\nUse this field if you want to use the default version for the specified\n    model. The string must use the following format:\n\n\n#34;projects/YOUR_PROJECT/models/YOUR_MODEL\n#34;\n\n* \noutput-data-format=sadipscing\n\n    - Optional. Format of the output data files, defaults to JSON.\n* \noutput-path=invidunt\n\n    - Required. The output Google Cloud Storage location.\n* \nregion=consetetur\n\n    - Required. The Google Compute Engine region to run the prediction job in.\nSee the \na href=\n/ml-engine/docs/tensorflow/regions\navailable regions\n/a\n\nfor AI Platform services.\n* \nruntime-version=dolore\n\n    - Optional. The AI Platform runtime version to use for this batch\nprediction. If not set, AI Platform will pick the runtime version used\nduring the CreateVersion request for this model version, or choose the\nlatest stable version when model version information is not available\nsuch as when the model is specified by uri.\n* \nsignature-name=duo\n\n    - Optional. The name of the signature defined in the SavedModel to use for\nthis job. Please refer to\n\nSavedModel\n\nfor information about how to use signatures.\n\n\nDefaults to\n\nDEFAULT_SERVING_SIGNATURE_DEF_KEY\n\n, which is \nserving_default\n.\n* \nuri=aliquyam\n\n    - Use this field if you want to specify a Google Cloud Storage path for\nthe model to use.\n* \nversion-name=lorem\n\n    - Use this field if you want to specify a version of the model to use. The\nstring is formatted the same way as \nmodel_version\n, with the addition\nof the version information:\n\n\n#34;projects/YOUR_PROJECT/models/YOUR_MODEL/versions/YOUR_VERSION\n#34;\n\n\n\n\n\n\n\n\n\n\n..prediction-output    error-count=-17\n\n\n\n\nThe number of data instances which resulted in errors.\n\n\n\n\n\n\nnode-hours=0.877582930428\n\n\nNode hours used by the batch prediction job.\n\n\n\n\n\n\noutput-path=consetetur\n\n\nThe output Google Cloud Storage location provided at the job creation time.\n\n\n\n\n\n\n\n\nprediction-count=-58\n\n\n\n\nThe number of generated predictions.\n\n\n\n\n\n\n\n\n..    start-time=nonumy\n\n\n\n\nOutput only. When the job processing was started.\n\n\n\n\n\n\nstate=kasd\n\n\nOutput only. The detailed state of a job.\n\n\n\n\n\n\ntraining-input    args=sanctus\n\n\nOptional. Command line arguments to pass to the program.\n\n\nEach invocation of this argument appends the given value to the array.\n\n\n\n\n\n\nhyperparameters    algorithm=takimata\n\n\nOptional. The search algorithm specified for the hyperparameter\n    tuning job.\n    Uses the default AI Platform hyperparameter tuning\n    algorithm if unspecified.\n\n\n\n\n\n\nenable-trial-early-stopping=true\n\n\nOptional. Indicates if the hyperparameter tuning job enables auto trial\n    early stopping.\n\n\n\n\n\n\n\n\ngoal=labore\n\n\n\n\n\n\nRequired. The type of goal to use for tuning. Available types are\n    \nMAXIMIZE\n and \nMINIMIZE\n.\n\n\nDefaults to \nMAXIMIZE\n.\n* \nhyperparameter-metric-tag=invidunt\n\n    - Optional. The TensorFlow summary tag name to use for optimizing trials. For\ncurrent versions of TensorFlow, this tag name should exactly match what is\nshown in TensorBoard, including all scopes.  For versions of TensorFlow\nprior to 0.12, this should be only the tag passed to tf.Summary.\nBy default, \ntraining/hptuning/metric\n will be used.\n* \nmax-failed-trials=35\n\n    - Optional. The number of failed trials that need to be seen before failing\nthe hyperparameter tuning job. You can specify this field to override the\ndefault failing criteria for AI Platform hyperparameter tuning jobs.\n\n\nDefaults to zero, which means the service decides when a hyperparameter\njob should fail.\n* \nmax-parallel-trials=6\n\n    - Optional. The number of training trials to run concurrently.\nYou can reduce the time it takes to perform hyperparameter tuning by adding\ntrials in parallel. However, each trail only benefits from the information\ngained in completed trials. That means that a trial does not get access to\nthe results of trials running at the same time, which could reduce the\nquality of the overall optimization.\n\n\nEach trial will use the same scale tier and machine types.\n\n\nDefaults to one.\n* \nmax-trials=35\n\n    - Optional. How many training trials should be attempted to optimize\nthe specified hyperparameters.\n\n\nDefaults to one.\n* \nresume-previous-job-id=dolore\n\n    - Optional. The prior hyperparameter tuning job id that users hope to\ncontinue with. The job id will be used to find the corresponding vizier\nstudy guid and resume the study.\n\n\n\n\n\n\n\n\n\n\n..    job-dir=nonumy\n\n\n\n\nOptional. A Google Cloud Storage path in which to store training outputs\n    and other data needed for training. This path is passed to your TensorFlow\n    program as the \n--job-dir\n command-line argument. The benefit of specifying\n    this field is that Cloud ML validates the path for use in training.\n\n\n\n\n\n\nmaster-config.accelerator-config    count=sed\n\n\nThe number of accelerators to attach to each machine running the job.\n\n\n\n\n\n\n\n\ntype=aliquyam\n\n\n\n\nThe type of accelerator to use.\n\n\n\n\n\n\n\n\n..    image-uri=sit\n\n\n\n\nThe Docker image to run on the replica. This image must be in Container\n    Registry. Learn more about \nconfiguring custom\n    containers\n.\n\n\n\n\n\n\n\n\ntpu-tf-version=eirmod\n\n\n\n\nTensorFlow version used in the custom container. This field is required if\n    the replica is a TPU worker that uses a custom container. Otherwise, do not\n    specify this field.\n\n\n\n\n\n\n\n\n..    master-type=consetetur\n\n\n\n\n\n\nOptional. Specifies the type of virtual machine to use for your training\n    job\ns master worker.\n\n\nThe following types are supported:\n\n\ndl\n\n  \ndt\nstandard\n/dt\n\n  \ndd\n\n  A basic machine configuration suitable for training simple models with\n  small to moderate datasets.\n  \n/dd\n\n  \ndt\nlarge_model\n/dt\n\n  \ndd\n\n  A machine with a lot of memory, specially suited for parameter servers\n  when your model is large (having many hidden layers or layers with very\n  large numbers of nodes).\n  \n/dd\n\n  \ndt\ncomplex_model_s\n/dt\n\n  \ndd\n\n  A machine suitable for the master and workers of the cluster when your\n  model requires more computation than the standard machine can handle\n  satisfactorily.\n  \n/dd\n\n  \ndt\ncomplex_model_m\n/dt\n\n  \ndd\n\n  A machine with roughly twice the number of cores and roughly double the\n  memory of \ni\ncomplex_model_s\n/i\n.\n  \n/dd\n\n  \ndt\ncomplex_model_l\n/dt\n\n  \ndd\n\n  A machine with roughly twice the number of cores and roughly double the\n  memory of \ni\ncomplex_model_m\n/i\n.\n  \n/dd\n\n  \ndt\nstandard_gpu\n/dt\n\n  \ndd\n\n  A machine equivalent to \ni\nstandard\n/i\n that\n  also includes a single NVIDIA Tesla K80 GPU. See more about\n  \na href=\n/ml-engine/docs/tensorflow/using-gpus\nusing GPUs to\n  train your model\n/a\n.\n  \n/dd\n\n  \ndt\ncomplex_model_m_gpu\n/dt\n\n  \ndd\n\n  A machine equivalent to \ni\ncomplex_model_m\n/i\n that also includes\n  four NVIDIA Tesla K80 GPUs.\n  \n/dd\n\n  \ndt\ncomplex_model_l_gpu\n/dt\n\n  \ndd\n\n  A machine equivalent to \ni\ncomplex_model_l\n/i\n that also includes\n  eight NVIDIA Tesla K80 GPUs.\n  \n/dd\n\n  \ndt\nstandard_p100\n/dt\n\n  \ndd\n\n  A machine equivalent to \ni\nstandard\n/i\n that\n  also includes a single NVIDIA Tesla P100 GPU.\n  \n/dd\n\n  \ndt\ncomplex_model_m_p100\n/dt\n\n  \ndd\n\n  A machine equivalent to \ni\ncomplex_model_m\n/i\n that also includes\n  four NVIDIA Tesla P100 GPUs.\n  \n/dd\n\n  \ndt\nstandard_v100\n/dt\n\n  \ndd\n\n  A machine equivalent to \ni\nstandard\n/i\n that\n  also includes a single NVIDIA Tesla V100 GPU.\n  \n/dd\n\n  \ndt\nlarge_model_v100\n/dt\n\n  \ndd\n\n  A machine equivalent to \ni\nlarge_model\n/i\n that\n  also includes a single NVIDIA Tesla V100 GPU.\n  \n/dd\n\n  \ndt\ncomplex_model_m_v100\n/dt\n\n  \ndd\n\n  A machine equivalent to \ni\ncomplex_model_m\n/i\n that\n  also includes four NVIDIA Tesla V100 GPUs.\n  \n/dd\n\n  \ndt\ncomplex_model_l_v100\n/dt\n\n  \ndd\n\n  A machine equivalent to \ni\ncomplex_model_l\n/i\n that\n  also includes eight NVIDIA Tesla V100 GPUs.\n  \n/dd\n\n  \ndt\ncloud_tpu\n/dt\n\n  \ndd\n\n  A TPU VM including one Cloud TPU. See more about\n  \na href=\n/ml-engine/docs/tensorflow/using-tpus\nusing TPUs to train\n  your model\n/a\n.\n  \n/dd\n\n\n/dl\n\n\nYou may also use certain Compute Engine machine types directly in this\nfield. The following types are supported:\n\n\n\n\nn1-standard-4\n\n\nn1-standard-8\n\n\nn1-standard-16\n\n\nn1-standard-32\n\n\nn1-standard-64\n\n\nn1-standard-96\n\n\nn1-highmem-2\n\n\nn1-highmem-4\n\n\nn1-highmem-8\n\n\nn1-highmem-16\n\n\nn1-highmem-32\n\n\nn1-highmem-64\n\n\nn1-highmem-96\n\n\nn1-highcpu-16\n\n\nn1-highcpu-32\n\n\nn1-highcpu-64\n\n\nn1-highcpu-96\n\n\n\n\nSee more about \nusing Compute Engine machine\ntypes\n.\n\n\nYou must set this value when \nscaleTier\n is set to \nCUSTOM\n.\n* \nmax-running-time=labore\n\n    - Optional. The maximum job running time. The default is 7 days.\n* \npackage-uris=sed\n\n    - Required. The Google Cloud Storage location of the packages with\nthe training program and any additional dependencies.\nThe maximum number of package URIs is 100.\n    - Each invocation of this argument appends the given value to the array.\n* \nparameter-server-config.accelerator-config    count=ea\n\n    - The number of accelerators to attach to each machine running the job.\n* \ntype=gubergren\n\n    - The type of accelerator to use.\n\n\n\n\n\n\n\n\n\n\n..    image-uri=aliquyam\n\n\n\n\nThe Docker image to run on the replica. This image must be in Container\n    Registry. Learn more about \nconfiguring custom\n    containers\n.\n\n\n\n\n\n\n\n\ntpu-tf-version=eos\n\n\n\n\nTensorFlow version used in the custom container. This field is required if\n    the replica is a TPU worker that uses a custom container. Otherwise, do not\n    specify this field.\n\n\n\n\n\n\n\n\n..    parameter-server-count=-38\n\n\n\n\n\n\nOptional. The number of parameter server replicas to use for the training\n    job. Each replica in the cluster will be of the type specified in\n    \nparameter_server_type\n.\n\n\nThis value can only be used when \nscale_tier\n is set to \nCUSTOM\n.If you\nset this value, you must also set \nparameter_server_type\n.\n\n\nThe default value is zero.\n* \nparameter-server-type=sea\n\n    - Optional. Specifies the type of virtual machine to use for your training\njob\ns parameter server.\n\n\nThe supported values are the same as those described in the entry for\n\nmaster_type\n.\n\n\nThis value must be consistent with the category of machine type that\n\nmasterType\n uses. In other words, both must be AI Platform machine\ntypes or both must be Compute Engine machine types.\n\n\nThis value must be present when \nscaleTier\n is set to \nCUSTOM\n and\n\nparameter_server_count\n is greater than zero.\n* \npython-module=labore\n\n    - Required. The Python module name to run after installing the packages.\n* \npython-version=ipsum\n\n    - Optional. The version of Python used in training. If not set, the default\nversion is \n2.7\n. Python \n3.5\n is available when \nruntime_version\n is set\nto \n1.4\n and above. Python \n2.7\n works with all supported\n\na href=\n/ml-engine/docs/runtime-version-list\nruntime versions\n/a\n.\n* \nregion=aliquyam\n\n    - Required. The Google Compute Engine region to run the training job in.\nSee the \na href=\n/ml-engine/docs/tensorflow/regions\navailable regions\n/a\n\nfor AI Platform services.\n* \nruntime-version=dolores\n\n    - Optional. The AI Platform runtime version to use for training. If not\nset, AI Platform uses the default stable version, 1.0. For more\ninformation, see the\n\na href=\n/ml-engine/docs/runtime-version-list\nruntime version list\n/a\n\nand\n\na href=\n/ml-engine/docs/versioning\nhow to manage runtime versions\n/a\n.\n* \nscale-tier=sit\n\n    - Required. Specifies the machine types, the number of replicas for workers\nand parameter servers.\n* \nworker-config.accelerator-config    count=diam\n\n    - The number of accelerators to attach to each machine running the job.\n* \ntype=ut\n\n    - The type of accelerator to use.\n\n\n\n\n\n\n\n\n\n\n..    image-uri=justo\n\n\n\n\nThe Docker image to run on the replica. This image must be in Container\n    Registry. Learn more about \nconfiguring custom\n    containers\n.\n\n\n\n\n\n\n\n\ntpu-tf-version=est\n\n\n\n\nTensorFlow version used in the custom container. This field is required if\n    the replica is a TPU worker that uses a custom container. Otherwise, do not\n    specify this field.\n\n\n\n\n\n\n\n\n..    worker-count=-46\n\n\n\n\n\n\nOptional. The number of worker replicas to use for the training job. Each\n    replica in the cluster will be of the type specified in \nworker_type\n.\n\n\nThis value can only be used when \nscale_tier\n is set to \nCUSTOM\n. If you\nset this value, you must also set \nworker_type\n.\n\n\nThe default value is zero.\n* \nworker-type=accusam\n\n    - Optional. Specifies the type of virtual machine to use for your training\njob\ns worker nodes.\n\n\nThe supported values are the same as those described in the entry for\n\nmasterType\n.\n\n\nThis value must be consistent with the category of machine type that\n\nmasterType\n uses. In other words, both must be AI Platform machine\ntypes or both must be Compute Engine machine types.\n\n\nIf you use \ncloud_tpu\n for this value, see special instructions for\n\nconfiguring a custom TPU\nmachine\n.\n\n\nThis value must be present when \nscaleTier\n is set to \nCUSTOM\n and\n\nworkerCount\n is greater than zero.\n\n\n\n\n\n\n\n\n\n\n..training-output.built-in-algorithm-output    framework=clita\n\n\n\n\nFramework on which the built-in algorithm was trained.\n\n\n\n\n\n\nmodel-path=diam\n\n\nThe Cloud Storage path to the \nmodel/\n directory where the training job\n    saves the trained model. Only set for successful jobs that don\nt use\n    hyperparameter tuning.\n\n\n\n\n\n\npython-version=justo\n\n\nPython version on which the built-in algorithm was trained.\n\n\n\n\n\n\n\n\nruntime-version=est\n\n\n\n\nAI Platform runtime version on which the built-in algorithm was\n    trained.\n\n\n\n\n\n\n\n\n..    completed-trial-count=-63\n\n\n\n\nThe number of hyperparameter tuning trials that completed successfully.\n    Only set for hyperparameter tuning jobs.\n\n\n\n\n\n\nconsumed-ml-units=0.636549512895\n\n\nThe amount of ML units consumed by the job.\n\n\n\n\n\n\nhyperparameter-metric-tag=ut\n\n\nThe TensorFlow summary tag name used for optimizing hyperparameter tuning\n    trials. See\n    \nHyperparameterSpec.hyperparameterMetricTag\n\n    for more information. Only set for hyperparameter tuning jobs.\n\n\n\n\n\n\nis-built-in-algorithm-job=true\n\n\nWhether this job is a built-in Algorithm job.\n\n\n\n\n\n\nis-hyperparameter-tuning-job=true\n\n\nWhether this job is a hyperparameter tuning job.\n\n\n\n\n\n\n\n\nAbout Cursors\n\n\nThe cursor position is key to comfortably set complex nested structures. The following rules apply:\n\n\n\n\nThe cursor position is always set relative to the current one, unless the field name starts with the \n.\n character. Fields can be nested such as in \n-r f.s.o\n .\n\n\nThe cursor position is set relative to the top-level structure if it starts with \n.\n, e.g. \n-r .s.s\n\n\nYou can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify \n-r struct.sub_struct=bar\n.\n\n\nYou can move the cursor one level up by using \n..\n. Each additional \n.\n moves it up one additional level. E.g. \n...\n would go three levels up.\n\n\n\n\nOptional Output Flags\n\n\nThe method's return value a JSON encoded structure, which will be written to standard output by default.\n\n\n\n\n-o out\n\n\nout\n specifies the \ndestination\n to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The \ndestination\n may be \n-\n to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.\n\n\n\n\n\n\n\n\nOptional Method Properties\n\n\nYou may set the following properties to further configure the call. Please note that \n-p\n is followed by one \nor more key-value-pairs, and is called like this \n-p k1=v1 k2=v2\n even though the listing below repeats the\n\n-p\n for completeness.\n\n\n\n\n-p update-mask=string\n\n\n\n\nRequired. Specifies the path, relative to \nJob\n, of the field to update.\n    To adopt etag mechanism, include \netag\n field in the mask, and include the\n    \netag\n value in your job resource.\n\n\nFor example, to change the labels of a job, the \nupdate_mask\n parameter\nwould be specified as \nlabels\n, \netag\n, and the\n\nPATCH\n request body would specify the new value, as follows:\n    {\n      \nlabels\n: {\n         \nowner\n: \nGoogle\n,\n         \ncolor\n: \nBlue\n\n      }\n      \netag\n: \n33a64df551425fcc55e4d42a148795d9f25f89d4\n\n    }\nIf \netag\n matches the one on the server, the labels of the job will be\nreplaced with the given ones, and the server end \netag\n will be\nrecalculated.\n\n\nCurrently the only supported update masks are \nlabels\n and \netag\n.\n\n\n\n\n\n\n\n\n\n\nOptional General Properties\n\n\nThe following properties can configure any call, and are not specific to this method.\n\n\n\n\n\n\n-p $-xgafv=string\n\n\n\n\nV1 error format.\n\n\n\n\n\n\n\n\n-p access-token=string\n\n\n\n\nOAuth access token.\n\n\n\n\n\n\n\n\n-p alt=string\n\n\n\n\nData format for response.\n\n\n\n\n\n\n\n\n-p callback=string\n\n\n\n\nJSONP\n\n\n\n\n\n\n\n\n-p fields=string\n\n\n\n\nSelector specifying which fields to include in a partial response.\n\n\n\n\n\n\n\n\n-p key=string\n\n\n\n\nAPI key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.\n\n\n\n\n\n\n\n\n-p oauth-token=string\n\n\n\n\nOAuth 2.0 token for the current user.\n\n\n\n\n\n\n\n\n-p pretty-print=boolean\n\n\n\n\nReturns response with indentations and line breaks.\n\n\n\n\n\n\n\n\n-p quota-user=string\n\n\n\n\nAvailable to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.\n\n\n\n\n\n\n\n\n-p upload-type=string\n\n\n\n\nLegacy upload protocol for media (e.g. \nmedia\n, \nmultipart\n).\n\n\n\n\n\n\n\n\n-p upload-protocol=string\n\n\n\n\nUpload protocol for media (e.g. \nraw\n, \nmultipart\n).", 
            "title": "Jobs Patch"
        }, 
        {
            "location": "/projects_jobs-patch/#scopes", 
            "text": "You will need authorization for the  https://www.googleapis.com/auth/cloud-platform  scope to make a valid call.  If unset, the scope for this method defaults to  https://www.googleapis.com/auth/cloud-platform .\nYou can set the scope for this method like this:  ml1 --scope  scope  projects jobs-patch ...", 
            "title": "Scopes"
        }, 
        {
            "location": "/projects_jobs-patch/#required-scalar-argument", 
            "text": "name   (string)  Required. The job name.", 
            "title": "Required Scalar Argument"
        }, 
        {
            "location": "/projects_jobs-patch/#required-request-value", 
            "text": "The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure.\nIn the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely.  For example, a structure like this:  GoogleCloudMlV1__Job:\n  create-time: string\n  end-time: string\n  error-message: string\n  etag: string\n  job-id: string\n  labels: { string: string }\n  prediction-input:\n    batch-size: string\n    data-format: string\n    input-paths: [string]\n    max-worker-count: int64\n    model-name: string\n    output-data-format: string\n    output-path: string\n    region: string\n    runtime-version: string\n    signature-name: string\n    uri: string\n    version-name: string\n  prediction-output:\n    error-count: int64\n    node-hours: number\n    output-path: string\n    prediction-count: int64\n  start-time: string\n  state: string\n  training-input:\n    args: [string]\n    hyperparameters:\n      algorithm: string\n      enable-trial-early-stopping: boolean\n      goal: string\n      hyperparameter-metric-tag: string\n      max-failed-trials: integer\n      max-parallel-trials: integer\n      max-trials: integer\n      resume-previous-job-id: string\n    job-dir: string\n    master-config:\n      accelerator-config:\n        count: string\n        type: string\n      image-uri: string\n      tpu-tf-version: string\n    master-type: string\n    max-running-time: string\n    package-uris: [string]\n    parameter-server-config:\n      accelerator-config:\n        count: string\n        type: string\n      image-uri: string\n      tpu-tf-version: string\n    parameter-server-count: int64\n    parameter-server-type: string\n    python-module: string\n    python-version: string\n    region: string\n    runtime-version: string\n    scale-tier: string\n    worker-config:\n      accelerator-config:\n        count: string\n        type: string\n      image-uri: string\n      tpu-tf-version: string\n    worker-count: int64\n    worker-type: string\n  training-output:\n    built-in-algorithm-output:\n      framework: string\n      model-path: string\n      python-version: string\n      runtime-version: string\n    completed-trial-count: int64\n    consumed-ml-units: number\n    hyperparameter-metric-tag: string\n    is-built-in-algorithm-job: boolean\n    is-hyperparameter-tuning-job: boolean  can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time.   -r .    create-time=voluptua.  Output only. When the job was created.    end-time=lorem  Output only. When the job processing was completed.    error-message=gubergren  Output only. The details of a failure or a cancellation.    etag=justo  etag  is used for optimistic concurrency control as a way to help\n    prevent simultaneous updates of a job from overwriting each other.\n    It is strongly suggested that systems make use of the  etag  in the\n    read-modify-write cycle to perform job updates in order to avoid race\n    conditions: An  etag  is returned in the response to  GetJob , and\n    systems are expected to put that etag in the request to  UpdateJob  to\n    ensure that their change will be applied to the same version of the job.    job-id=sit  Required. The user-specified id of the job.    labels=key=vero  Optional. One or more labels that you can add, to organize your jobs.\n    Each label is a key-value pair, where both the key and the value are\n    arbitrary strings that you supply.\n    For more information, see the documentation on\n     a href= /ml-engine/docs/tensorflow/resource-labels using labels /a .  the value will be associated with the given  key    prediction-input    batch-size=diam  Optional. Number of records per batch, defaults to 64.\n    The service will buffer batch_size number of records in memory before\n    invoking one Tensorflow prediction call internally. So take the record\n    size and memory available into consideration when setting this parameter.    data-format=rebum.  Required. The format of the input data files.    input-paths=consetetur  Required. The Cloud Storage location of the input data files. May contain\n     a href= /storage/docs/gsutil/addlhelp/WildcardNames wildcards /a .  Each invocation of this argument appends the given value to the array.    max-worker-count=-44  Optional. The maximum number of workers to be used for parallel processing.\n    Defaults to 10 if not specified.     model-name=vero    Use this field if you want to use the default version for the specified\n    model. The string must use the following format:  #34;projects/YOUR_PROJECT/models/YOUR_MODEL #34; \n*  output-data-format=sadipscing \n    - Optional. Format of the output data files, defaults to JSON.\n*  output-path=invidunt \n    - Required. The output Google Cloud Storage location.\n*  region=consetetur \n    - Required. The Google Compute Engine region to run the prediction job in.\nSee the  a href= /ml-engine/docs/tensorflow/regions available regions /a \nfor AI Platform services.\n*  runtime-version=dolore \n    - Optional. The AI Platform runtime version to use for this batch\nprediction. If not set, AI Platform will pick the runtime version used\nduring the CreateVersion request for this model version, or choose the\nlatest stable version when model version information is not available\nsuch as when the model is specified by uri.\n*  signature-name=duo \n    - Optional. The name of the signature defined in the SavedModel to use for\nthis job. Please refer to SavedModel \nfor information about how to use signatures.  Defaults to DEFAULT_SERVING_SIGNATURE_DEF_KEY \n, which is  serving_default .\n*  uri=aliquyam \n    - Use this field if you want to specify a Google Cloud Storage path for\nthe model to use.\n*  version-name=lorem \n    - Use this field if you want to specify a version of the model to use. The\nstring is formatted the same way as  model_version , with the addition\nof the version information:  #34;projects/YOUR_PROJECT/models/YOUR_MODEL/versions/YOUR_VERSION #34;      ..prediction-output    error-count=-17   The number of data instances which resulted in errors.    node-hours=0.877582930428  Node hours used by the batch prediction job.    output-path=consetetur  The output Google Cloud Storage location provided at the job creation time.     prediction-count=-58   The number of generated predictions.     ..    start-time=nonumy   Output only. When the job processing was started.    state=kasd  Output only. The detailed state of a job.    training-input    args=sanctus  Optional. Command line arguments to pass to the program.  Each invocation of this argument appends the given value to the array.    hyperparameters    algorithm=takimata  Optional. The search algorithm specified for the hyperparameter\n    tuning job.\n    Uses the default AI Platform hyperparameter tuning\n    algorithm if unspecified.    enable-trial-early-stopping=true  Optional. Indicates if the hyperparameter tuning job enables auto trial\n    early stopping.     goal=labore    Required. The type of goal to use for tuning. Available types are\n     MAXIMIZE  and  MINIMIZE .  Defaults to  MAXIMIZE .\n*  hyperparameter-metric-tag=invidunt \n    - Optional. The TensorFlow summary tag name to use for optimizing trials. For\ncurrent versions of TensorFlow, this tag name should exactly match what is\nshown in TensorBoard, including all scopes.  For versions of TensorFlow\nprior to 0.12, this should be only the tag passed to tf.Summary.\nBy default,  training/hptuning/metric  will be used.\n*  max-failed-trials=35 \n    - Optional. The number of failed trials that need to be seen before failing\nthe hyperparameter tuning job. You can specify this field to override the\ndefault failing criteria for AI Platform hyperparameter tuning jobs.  Defaults to zero, which means the service decides when a hyperparameter\njob should fail.\n*  max-parallel-trials=6 \n    - Optional. The number of training trials to run concurrently.\nYou can reduce the time it takes to perform hyperparameter tuning by adding\ntrials in parallel. However, each trail only benefits from the information\ngained in completed trials. That means that a trial does not get access to\nthe results of trials running at the same time, which could reduce the\nquality of the overall optimization.  Each trial will use the same scale tier and machine types.  Defaults to one.\n*  max-trials=35 \n    - Optional. How many training trials should be attempted to optimize\nthe specified hyperparameters.  Defaults to one.\n*  resume-previous-job-id=dolore \n    - Optional. The prior hyperparameter tuning job id that users hope to\ncontinue with. The job id will be used to find the corresponding vizier\nstudy guid and resume the study.      ..    job-dir=nonumy   Optional. A Google Cloud Storage path in which to store training outputs\n    and other data needed for training. This path is passed to your TensorFlow\n    program as the  --job-dir  command-line argument. The benefit of specifying\n    this field is that Cloud ML validates the path for use in training.    master-config.accelerator-config    count=sed  The number of accelerators to attach to each machine running the job.     type=aliquyam   The type of accelerator to use.     ..    image-uri=sit   The Docker image to run on the replica. This image must be in Container\n    Registry. Learn more about  configuring custom\n    containers .     tpu-tf-version=eirmod   TensorFlow version used in the custom container. This field is required if\n    the replica is a TPU worker that uses a custom container. Otherwise, do not\n    specify this field.     ..    master-type=consetetur    Optional. Specifies the type of virtual machine to use for your training\n    job s master worker.  The following types are supported:  dl \n   dt standard /dt \n   dd \n  A basic machine configuration suitable for training simple models with\n  small to moderate datasets.\n   /dd \n   dt large_model /dt \n   dd \n  A machine with a lot of memory, specially suited for parameter servers\n  when your model is large (having many hidden layers or layers with very\n  large numbers of nodes).\n   /dd \n   dt complex_model_s /dt \n   dd \n  A machine suitable for the master and workers of the cluster when your\n  model requires more computation than the standard machine can handle\n  satisfactorily.\n   /dd \n   dt complex_model_m /dt \n   dd \n  A machine with roughly twice the number of cores and roughly double the\n  memory of  i complex_model_s /i .\n   /dd \n   dt complex_model_l /dt \n   dd \n  A machine with roughly twice the number of cores and roughly double the\n  memory of  i complex_model_m /i .\n   /dd \n   dt standard_gpu /dt \n   dd \n  A machine equivalent to  i standard /i  that\n  also includes a single NVIDIA Tesla K80 GPU. See more about\n   a href= /ml-engine/docs/tensorflow/using-gpus using GPUs to\n  train your model /a .\n   /dd \n   dt complex_model_m_gpu /dt \n   dd \n  A machine equivalent to  i complex_model_m /i  that also includes\n  four NVIDIA Tesla K80 GPUs.\n   /dd \n   dt complex_model_l_gpu /dt \n   dd \n  A machine equivalent to  i complex_model_l /i  that also includes\n  eight NVIDIA Tesla K80 GPUs.\n   /dd \n   dt standard_p100 /dt \n   dd \n  A machine equivalent to  i standard /i  that\n  also includes a single NVIDIA Tesla P100 GPU.\n   /dd \n   dt complex_model_m_p100 /dt \n   dd \n  A machine equivalent to  i complex_model_m /i  that also includes\n  four NVIDIA Tesla P100 GPUs.\n   /dd \n   dt standard_v100 /dt \n   dd \n  A machine equivalent to  i standard /i  that\n  also includes a single NVIDIA Tesla V100 GPU.\n   /dd \n   dt large_model_v100 /dt \n   dd \n  A machine equivalent to  i large_model /i  that\n  also includes a single NVIDIA Tesla V100 GPU.\n   /dd \n   dt complex_model_m_v100 /dt \n   dd \n  A machine equivalent to  i complex_model_m /i  that\n  also includes four NVIDIA Tesla V100 GPUs.\n   /dd \n   dt complex_model_l_v100 /dt \n   dd \n  A machine equivalent to  i complex_model_l /i  that\n  also includes eight NVIDIA Tesla V100 GPUs.\n   /dd \n   dt cloud_tpu /dt \n   dd \n  A TPU VM including one Cloud TPU. See more about\n   a href= /ml-engine/docs/tensorflow/using-tpus using TPUs to train\n  your model /a .\n   /dd  /dl  You may also use certain Compute Engine machine types directly in this\nfield. The following types are supported:   n1-standard-4  n1-standard-8  n1-standard-16  n1-standard-32  n1-standard-64  n1-standard-96  n1-highmem-2  n1-highmem-4  n1-highmem-8  n1-highmem-16  n1-highmem-32  n1-highmem-64  n1-highmem-96  n1-highcpu-16  n1-highcpu-32  n1-highcpu-64  n1-highcpu-96   See more about  using Compute Engine machine\ntypes .  You must set this value when  scaleTier  is set to  CUSTOM .\n*  max-running-time=labore \n    - Optional. The maximum job running time. The default is 7 days.\n*  package-uris=sed \n    - Required. The Google Cloud Storage location of the packages with\nthe training program and any additional dependencies.\nThe maximum number of package URIs is 100.\n    - Each invocation of this argument appends the given value to the array.\n*  parameter-server-config.accelerator-config    count=ea \n    - The number of accelerators to attach to each machine running the job.\n*  type=gubergren \n    - The type of accelerator to use.      ..    image-uri=aliquyam   The Docker image to run on the replica. This image must be in Container\n    Registry. Learn more about  configuring custom\n    containers .     tpu-tf-version=eos   TensorFlow version used in the custom container. This field is required if\n    the replica is a TPU worker that uses a custom container. Otherwise, do not\n    specify this field.     ..    parameter-server-count=-38    Optional. The number of parameter server replicas to use for the training\n    job. Each replica in the cluster will be of the type specified in\n     parameter_server_type .  This value can only be used when  scale_tier  is set to  CUSTOM .If you\nset this value, you must also set  parameter_server_type .  The default value is zero.\n*  parameter-server-type=sea \n    - Optional. Specifies the type of virtual machine to use for your training\njob s parameter server.  The supported values are the same as those described in the entry for master_type .  This value must be consistent with the category of machine type that masterType  uses. In other words, both must be AI Platform machine\ntypes or both must be Compute Engine machine types.  This value must be present when  scaleTier  is set to  CUSTOM  and parameter_server_count  is greater than zero.\n*  python-module=labore \n    - Required. The Python module name to run after installing the packages.\n*  python-version=ipsum \n    - Optional. The version of Python used in training. If not set, the default\nversion is  2.7 . Python  3.5  is available when  runtime_version  is set\nto  1.4  and above. Python  2.7  works with all supported a href= /ml-engine/docs/runtime-version-list runtime versions /a .\n*  region=aliquyam \n    - Required. The Google Compute Engine region to run the training job in.\nSee the  a href= /ml-engine/docs/tensorflow/regions available regions /a \nfor AI Platform services.\n*  runtime-version=dolores \n    - Optional. The AI Platform runtime version to use for training. If not\nset, AI Platform uses the default stable version, 1.0. For more\ninformation, see the a href= /ml-engine/docs/runtime-version-list runtime version list /a \nand a href= /ml-engine/docs/versioning how to manage runtime versions /a .\n*  scale-tier=sit \n    - Required. Specifies the machine types, the number of replicas for workers\nand parameter servers.\n*  worker-config.accelerator-config    count=diam \n    - The number of accelerators to attach to each machine running the job.\n*  type=ut \n    - The type of accelerator to use.      ..    image-uri=justo   The Docker image to run on the replica. This image must be in Container\n    Registry. Learn more about  configuring custom\n    containers .     tpu-tf-version=est   TensorFlow version used in the custom container. This field is required if\n    the replica is a TPU worker that uses a custom container. Otherwise, do not\n    specify this field.     ..    worker-count=-46    Optional. The number of worker replicas to use for the training job. Each\n    replica in the cluster will be of the type specified in  worker_type .  This value can only be used when  scale_tier  is set to  CUSTOM . If you\nset this value, you must also set  worker_type .  The default value is zero.\n*  worker-type=accusam \n    - Optional. Specifies the type of virtual machine to use for your training\njob s worker nodes.  The supported values are the same as those described in the entry for masterType .  This value must be consistent with the category of machine type that masterType  uses. In other words, both must be AI Platform machine\ntypes or both must be Compute Engine machine types.  If you use  cloud_tpu  for this value, see special instructions for configuring a custom TPU\nmachine .  This value must be present when  scaleTier  is set to  CUSTOM  and workerCount  is greater than zero.      ..training-output.built-in-algorithm-output    framework=clita   Framework on which the built-in algorithm was trained.    model-path=diam  The Cloud Storage path to the  model/  directory where the training job\n    saves the trained model. Only set for successful jobs that don t use\n    hyperparameter tuning.    python-version=justo  Python version on which the built-in algorithm was trained.     runtime-version=est   AI Platform runtime version on which the built-in algorithm was\n    trained.     ..    completed-trial-count=-63   The number of hyperparameter tuning trials that completed successfully.\n    Only set for hyperparameter tuning jobs.    consumed-ml-units=0.636549512895  The amount of ML units consumed by the job.    hyperparameter-metric-tag=ut  The TensorFlow summary tag name used for optimizing hyperparameter tuning\n    trials. See\n     HyperparameterSpec.hyperparameterMetricTag \n    for more information. Only set for hyperparameter tuning jobs.    is-built-in-algorithm-job=true  Whether this job is a built-in Algorithm job.    is-hyperparameter-tuning-job=true  Whether this job is a hyperparameter tuning job.", 
            "title": "Required Request Value"
        }, 
        {
            "location": "/projects_jobs-patch/#about-cursors", 
            "text": "The cursor position is key to comfortably set complex nested structures. The following rules apply:   The cursor position is always set relative to the current one, unless the field name starts with the  .  character. Fields can be nested such as in  -r f.s.o  .  The cursor position is set relative to the top-level structure if it starts with  . , e.g.  -r .s.s  You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify  -r struct.sub_struct=bar .  You can move the cursor one level up by using  .. . Each additional  .  moves it up one additional level. E.g.  ...  would go three levels up.", 
            "title": "About Cursors"
        }, 
        {
            "location": "/projects_jobs-patch/#optional-output-flags", 
            "text": "The method's return value a JSON encoded structure, which will be written to standard output by default.   -o out  out  specifies the  destination  to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The  destination  may be  -  to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.", 
            "title": "Optional Output Flags"
        }, 
        {
            "location": "/projects_jobs-patch/#optional-method-properties", 
            "text": "You may set the following properties to further configure the call. Please note that  -p  is followed by one \nor more key-value-pairs, and is called like this  -p k1=v1 k2=v2  even though the listing below repeats the -p  for completeness.   -p update-mask=string   Required. Specifies the path, relative to  Job , of the field to update.\n    To adopt etag mechanism, include  etag  field in the mask, and include the\n     etag  value in your job resource.  For example, to change the labels of a job, the  update_mask  parameter\nwould be specified as  labels ,  etag , and the PATCH  request body would specify the new value, as follows:\n    {\n       labels : {\n          owner :  Google ,\n          color :  Blue \n      }\n       etag :  33a64df551425fcc55e4d42a148795d9f25f89d4 \n    }\nIf  etag  matches the one on the server, the labels of the job will be\nreplaced with the given ones, and the server end  etag  will be\nrecalculated.  Currently the only supported update masks are  labels  and  etag .", 
            "title": "Optional Method Properties"
        }, 
        {
            "location": "/projects_jobs-patch/#optional-general-properties", 
            "text": "The following properties can configure any call, and are not specific to this method.    -p $-xgafv=string   V1 error format.     -p access-token=string   OAuth access token.     -p alt=string   Data format for response.     -p callback=string   JSONP     -p fields=string   Selector specifying which fields to include in a partial response.     -p key=string   API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.     -p oauth-token=string   OAuth 2.0 token for the current user.     -p pretty-print=boolean   Returns response with indentations and line breaks.     -p quota-user=string   Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.     -p upload-type=string   Legacy upload protocol for media (e.g.  media ,  multipart ).     -p upload-protocol=string   Upload protocol for media (e.g.  raw ,  multipart ).", 
            "title": "Optional General Properties"
        }, 
        {
            "location": "/projects_jobs-set-iam-policy/", 
            "text": "Sets the access control policy on the specified resource. Replaces any\nexisting policy.\n\n\nScopes\n\n\nYou will need authorization for the \nhttps://www.googleapis.com/auth/cloud-platform\n scope to make a valid call.\n\n\nIf unset, the scope for this method defaults to \nhttps://www.googleapis.com/auth/cloud-platform\n.\nYou can set the scope for this method like this: \nml1 --scope \nscope\n projects jobs-set-iam-policy ...\n\n\nRequired Scalar Argument\n\n\n\n\nresource\n \n(string)\n\n\nREQUIRED: The resource for which the policy is being specified.\n    See the operation documentation for the appropriate value for this field.\n\n\n\n\n\n\n\n\nRequired Request Value\n\n\nThe request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure.\nIn the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely.\n\n\nFor example, a structure like this:\n\n\nGoogleIamV1__SetIamPolicyRequest:\n  policy:\n    etag: string\n    version: integer\n  update-mask: string\n\n\n\n\n\ncan be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time.\n\n\n\n\n\n\n-r .policy    etag=voluptua.\n\n\n\n\n\n\netag\n is used for optimistic concurrency control as a way to help\n    prevent simultaneous updates of a policy from overwriting each other.\n    It is strongly suggested that systems make use of the \netag\n in the\n    read-modify-write cycle to perform policy updates in order to avoid race\n    conditions: An \netag\n is returned in the response to \ngetIamPolicy\n, and\n    systems are expected to put that etag in the request to \nsetIamPolicy\n to\n    ensure that their change will be applied to the same version of the policy.\n\n\nIf no \netag\n is provided in the call to \nsetIamPolicy\n, then the existing\npolicy is overwritten blindly.\n* \nversion=82\n\n    - Deprecated.\n\n\n\n\n\n\n\n\n\n\n..    update-mask=sed\n\n\n\n\nOPTIONAL: A FieldMask specifying which fields of the policy to modify. Only\n    the fields in the mask will be modified. If no mask is provided, the\n    following default mask is used:\n    paths: \nbindings, etag\n\n    This field is only used by Cloud IAM.\n\n\n\n\n\n\n\n\nAbout Cursors\n\n\nThe cursor position is key to comfortably set complex nested structures. The following rules apply:\n\n\n\n\nThe cursor position is always set relative to the current one, unless the field name starts with the \n.\n character. Fields can be nested such as in \n-r f.s.o\n .\n\n\nThe cursor position is set relative to the top-level structure if it starts with \n.\n, e.g. \n-r .s.s\n\n\nYou can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify \n-r struct.sub_struct=bar\n.\n\n\nYou can move the cursor one level up by using \n..\n. Each additional \n.\n moves it up one additional level. E.g. \n...\n would go three levels up.\n\n\n\n\nOptional Output Flags\n\n\nThe method's return value a JSON encoded structure, which will be written to standard output by default.\n\n\n\n\n-o out\n\n\nout\n specifies the \ndestination\n to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The \ndestination\n may be \n-\n to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.\n\n\n\n\n\n\n\n\nOptional General Properties\n\n\nThe following properties can configure any call, and are not specific to this method.\n\n\n\n\n\n\n-p $-xgafv=string\n\n\n\n\nV1 error format.\n\n\n\n\n\n\n\n\n-p access-token=string\n\n\n\n\nOAuth access token.\n\n\n\n\n\n\n\n\n-p alt=string\n\n\n\n\nData format for response.\n\n\n\n\n\n\n\n\n-p callback=string\n\n\n\n\nJSONP\n\n\n\n\n\n\n\n\n-p fields=string\n\n\n\n\nSelector specifying which fields to include in a partial response.\n\n\n\n\n\n\n\n\n-p key=string\n\n\n\n\nAPI key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.\n\n\n\n\n\n\n\n\n-p oauth-token=string\n\n\n\n\nOAuth 2.0 token for the current user.\n\n\n\n\n\n\n\n\n-p pretty-print=boolean\n\n\n\n\nReturns response with indentations and line breaks.\n\n\n\n\n\n\n\n\n-p quota-user=string\n\n\n\n\nAvailable to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.\n\n\n\n\n\n\n\n\n-p upload-type=string\n\n\n\n\nLegacy upload protocol for media (e.g. \nmedia\n, \nmultipart\n).\n\n\n\n\n\n\n\n\n-p upload-protocol=string\n\n\n\n\nUpload protocol for media (e.g. \nraw\n, \nmultipart\n).", 
            "title": "Jobs Set Iam Policy"
        }, 
        {
            "location": "/projects_jobs-set-iam-policy/#scopes", 
            "text": "You will need authorization for the  https://www.googleapis.com/auth/cloud-platform  scope to make a valid call.  If unset, the scope for this method defaults to  https://www.googleapis.com/auth/cloud-platform .\nYou can set the scope for this method like this:  ml1 --scope  scope  projects jobs-set-iam-policy ...", 
            "title": "Scopes"
        }, 
        {
            "location": "/projects_jobs-set-iam-policy/#required-scalar-argument", 
            "text": "resource   (string)  REQUIRED: The resource for which the policy is being specified.\n    See the operation documentation for the appropriate value for this field.", 
            "title": "Required Scalar Argument"
        }, 
        {
            "location": "/projects_jobs-set-iam-policy/#required-request-value", 
            "text": "The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure.\nIn the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely.  For example, a structure like this:  GoogleIamV1__SetIamPolicyRequest:\n  policy:\n    etag: string\n    version: integer\n  update-mask: string  can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time.    -r .policy    etag=voluptua.    etag  is used for optimistic concurrency control as a way to help\n    prevent simultaneous updates of a policy from overwriting each other.\n    It is strongly suggested that systems make use of the  etag  in the\n    read-modify-write cycle to perform policy updates in order to avoid race\n    conditions: An  etag  is returned in the response to  getIamPolicy , and\n    systems are expected to put that etag in the request to  setIamPolicy  to\n    ensure that their change will be applied to the same version of the policy.  If no  etag  is provided in the call to  setIamPolicy , then the existing\npolicy is overwritten blindly.\n*  version=82 \n    - Deprecated.      ..    update-mask=sed   OPTIONAL: A FieldMask specifying which fields of the policy to modify. Only\n    the fields in the mask will be modified. If no mask is provided, the\n    following default mask is used:\n    paths:  bindings, etag \n    This field is only used by Cloud IAM.", 
            "title": "Required Request Value"
        }, 
        {
            "location": "/projects_jobs-set-iam-policy/#about-cursors", 
            "text": "The cursor position is key to comfortably set complex nested structures. The following rules apply:   The cursor position is always set relative to the current one, unless the field name starts with the  .  character. Fields can be nested such as in  -r f.s.o  .  The cursor position is set relative to the top-level structure if it starts with  . , e.g.  -r .s.s  You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify  -r struct.sub_struct=bar .  You can move the cursor one level up by using  .. . Each additional  .  moves it up one additional level. E.g.  ...  would go three levels up.", 
            "title": "About Cursors"
        }, 
        {
            "location": "/projects_jobs-set-iam-policy/#optional-output-flags", 
            "text": "The method's return value a JSON encoded structure, which will be written to standard output by default.   -o out  out  specifies the  destination  to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The  destination  may be  -  to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.", 
            "title": "Optional Output Flags"
        }, 
        {
            "location": "/projects_jobs-set-iam-policy/#optional-general-properties", 
            "text": "The following properties can configure any call, and are not specific to this method.    -p $-xgafv=string   V1 error format.     -p access-token=string   OAuth access token.     -p alt=string   Data format for response.     -p callback=string   JSONP     -p fields=string   Selector specifying which fields to include in a partial response.     -p key=string   API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.     -p oauth-token=string   OAuth 2.0 token for the current user.     -p pretty-print=boolean   Returns response with indentations and line breaks.     -p quota-user=string   Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.     -p upload-type=string   Legacy upload protocol for media (e.g.  media ,  multipart ).     -p upload-protocol=string   Upload protocol for media (e.g.  raw ,  multipart ).", 
            "title": "Optional General Properties"
        }, 
        {
            "location": "/projects_jobs-test-iam-permissions/", 
            "text": "Returns permissions that a caller has on the specified resource.\nIf the resource does not exist, this will return an empty set of\npermissions, not a NOT_FOUND error.\n\n\nNote: This operation is designed to be used for building permission-aware\nUIs and command-line tools, not for authorization checking. This operation\nmay \nfail open\n without warning.\n\n\nScopes\n\n\nYou will need authorization for the \nhttps://www.googleapis.com/auth/cloud-platform\n scope to make a valid call.\n\n\nIf unset, the scope for this method defaults to \nhttps://www.googleapis.com/auth/cloud-platform\n.\nYou can set the scope for this method like this: \nml1 --scope \nscope\n projects jobs-test-iam-permissions ...\n\n\nRequired Scalar Argument\n\n\n\n\nresource\n \n(string)\n\n\nREQUIRED: The resource for which the policy detail is being requested.\n    See the operation documentation for the appropriate value for this field.\n\n\n\n\n\n\n\n\nRequired Request Value\n\n\nThe request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure.\nIn the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely.\n\n\nFor example, a structure like this:\n\n\nGoogleIamV1__TestIamPermissionsRequest:\n  permissions: [string]\n\n\n\n\n\ncan be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time.\n\n\n\n\n-r .    permissions=aliquyam\n\n\nThe set of permissions to check for the \nresource\n. Permissions with\n    wildcards (such as \n or \nstorage.\n) are not allowed. For more\n    information see\n    \nIAM Overview\n.\n\n\nEach invocation of this argument appends the given value to the array.\n\n\n\n\n\n\n\n\nAbout Cursors\n\n\nThe cursor position is key to comfortably set complex nested structures. The following rules apply:\n\n\n\n\nThe cursor position is always set relative to the current one, unless the field name starts with the \n.\n character. Fields can be nested such as in \n-r f.s.o\n .\n\n\nThe cursor position is set relative to the top-level structure if it starts with \n.\n, e.g. \n-r .s.s\n\n\nYou can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify \n-r struct.sub_struct=bar\n.\n\n\nYou can move the cursor one level up by using \n..\n. Each additional \n.\n moves it up one additional level. E.g. \n...\n would go three levels up.\n\n\n\n\nOptional Output Flags\n\n\nThe method's return value a JSON encoded structure, which will be written to standard output by default.\n\n\n\n\n-o out\n\n\nout\n specifies the \ndestination\n to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The \ndestination\n may be \n-\n to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.\n\n\n\n\n\n\n\n\nOptional General Properties\n\n\nThe following properties can configure any call, and are not specific to this method.\n\n\n\n\n\n\n-p $-xgafv=string\n\n\n\n\nV1 error format.\n\n\n\n\n\n\n\n\n-p access-token=string\n\n\n\n\nOAuth access token.\n\n\n\n\n\n\n\n\n-p alt=string\n\n\n\n\nData format for response.\n\n\n\n\n\n\n\n\n-p callback=string\n\n\n\n\nJSONP\n\n\n\n\n\n\n\n\n-p fields=string\n\n\n\n\nSelector specifying which fields to include in a partial response.\n\n\n\n\n\n\n\n\n-p key=string\n\n\n\n\nAPI key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.\n\n\n\n\n\n\n\n\n-p oauth-token=string\n\n\n\n\nOAuth 2.0 token for the current user.\n\n\n\n\n\n\n\n\n-p pretty-print=boolean\n\n\n\n\nReturns response with indentations and line breaks.\n\n\n\n\n\n\n\n\n-p quota-user=string\n\n\n\n\nAvailable to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.\n\n\n\n\n\n\n\n\n-p upload-type=string\n\n\n\n\nLegacy upload protocol for media (e.g. \nmedia\n, \nmultipart\n).\n\n\n\n\n\n\n\n\n-p upload-protocol=string\n\n\n\n\nUpload protocol for media (e.g. \nraw\n, \nmultipart\n).", 
            "title": "Jobs Test Iam Permissions"
        }, 
        {
            "location": "/projects_jobs-test-iam-permissions/#scopes", 
            "text": "You will need authorization for the  https://www.googleapis.com/auth/cloud-platform  scope to make a valid call.  If unset, the scope for this method defaults to  https://www.googleapis.com/auth/cloud-platform .\nYou can set the scope for this method like this:  ml1 --scope  scope  projects jobs-test-iam-permissions ...", 
            "title": "Scopes"
        }, 
        {
            "location": "/projects_jobs-test-iam-permissions/#required-scalar-argument", 
            "text": "resource   (string)  REQUIRED: The resource for which the policy detail is being requested.\n    See the operation documentation for the appropriate value for this field.", 
            "title": "Required Scalar Argument"
        }, 
        {
            "location": "/projects_jobs-test-iam-permissions/#required-request-value", 
            "text": "The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure.\nIn the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely.  For example, a structure like this:  GoogleIamV1__TestIamPermissionsRequest:\n  permissions: [string]  can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time.   -r .    permissions=aliquyam  The set of permissions to check for the  resource . Permissions with\n    wildcards (such as   or  storage. ) are not allowed. For more\n    information see\n     IAM Overview .  Each invocation of this argument appends the given value to the array.", 
            "title": "Required Request Value"
        }, 
        {
            "location": "/projects_jobs-test-iam-permissions/#about-cursors", 
            "text": "The cursor position is key to comfortably set complex nested structures. The following rules apply:   The cursor position is always set relative to the current one, unless the field name starts with the  .  character. Fields can be nested such as in  -r f.s.o  .  The cursor position is set relative to the top-level structure if it starts with  . , e.g.  -r .s.s  You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify  -r struct.sub_struct=bar .  You can move the cursor one level up by using  .. . Each additional  .  moves it up one additional level. E.g.  ...  would go three levels up.", 
            "title": "About Cursors"
        }, 
        {
            "location": "/projects_jobs-test-iam-permissions/#optional-output-flags", 
            "text": "The method's return value a JSON encoded structure, which will be written to standard output by default.   -o out  out  specifies the  destination  to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The  destination  may be  -  to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.", 
            "title": "Optional Output Flags"
        }, 
        {
            "location": "/projects_jobs-test-iam-permissions/#optional-general-properties", 
            "text": "The following properties can configure any call, and are not specific to this method.    -p $-xgafv=string   V1 error format.     -p access-token=string   OAuth access token.     -p alt=string   Data format for response.     -p callback=string   JSONP     -p fields=string   Selector specifying which fields to include in a partial response.     -p key=string   API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.     -p oauth-token=string   OAuth 2.0 token for the current user.     -p pretty-print=boolean   Returns response with indentations and line breaks.     -p quota-user=string   Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.     -p upload-type=string   Legacy upload protocol for media (e.g.  media ,  multipart ).     -p upload-protocol=string   Upload protocol for media (e.g.  raw ,  multipart ).", 
            "title": "Optional General Properties"
        }, 
        {
            "location": "/projects_locations-get/", 
            "text": "Get the complete list of CMLE capabilities in a location, along with their\nlocation-specific properties.\n\n\nScopes\n\n\nYou will need authorization for the \nhttps://www.googleapis.com/auth/cloud-platform\n scope to make a valid call.\n\n\nIf unset, the scope for this method defaults to \nhttps://www.googleapis.com/auth/cloud-platform\n.\nYou can set the scope for this method like this: \nml1 --scope \nscope\n projects locations-get ...\n\n\nRequired Scalar Argument\n\n\n\n\nname\n \n(string)\n\n\nRequired. The name of the location.\n\n\n\n\n\n\n\n\nOptional Output Flags\n\n\nThe method's return value a JSON encoded structure, which will be written to standard output by default.\n\n\n\n\n-o out\n\n\nout\n specifies the \ndestination\n to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The \ndestination\n may be \n-\n to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.\n\n\n\n\n\n\n\n\nOptional General Properties\n\n\nThe following properties can configure any call, and are not specific to this method.\n\n\n\n\n\n\n-p $-xgafv=string\n\n\n\n\nV1 error format.\n\n\n\n\n\n\n\n\n-p access-token=string\n\n\n\n\nOAuth access token.\n\n\n\n\n\n\n\n\n-p alt=string\n\n\n\n\nData format for response.\n\n\n\n\n\n\n\n\n-p callback=string\n\n\n\n\nJSONP\n\n\n\n\n\n\n\n\n-p fields=string\n\n\n\n\nSelector specifying which fields to include in a partial response.\n\n\n\n\n\n\n\n\n-p key=string\n\n\n\n\nAPI key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.\n\n\n\n\n\n\n\n\n-p oauth-token=string\n\n\n\n\nOAuth 2.0 token for the current user.\n\n\n\n\n\n\n\n\n-p pretty-print=boolean\n\n\n\n\nReturns response with indentations and line breaks.\n\n\n\n\n\n\n\n\n-p quota-user=string\n\n\n\n\nAvailable to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.\n\n\n\n\n\n\n\n\n-p upload-type=string\n\n\n\n\nLegacy upload protocol for media (e.g. \nmedia\n, \nmultipart\n).\n\n\n\n\n\n\n\n\n-p upload-protocol=string\n\n\n\n\nUpload protocol for media (e.g. \nraw\n, \nmultipart\n).", 
            "title": "Locations Get"
        }, 
        {
            "location": "/projects_locations-get/#scopes", 
            "text": "You will need authorization for the  https://www.googleapis.com/auth/cloud-platform  scope to make a valid call.  If unset, the scope for this method defaults to  https://www.googleapis.com/auth/cloud-platform .\nYou can set the scope for this method like this:  ml1 --scope  scope  projects locations-get ...", 
            "title": "Scopes"
        }, 
        {
            "location": "/projects_locations-get/#required-scalar-argument", 
            "text": "name   (string)  Required. The name of the location.", 
            "title": "Required Scalar Argument"
        }, 
        {
            "location": "/projects_locations-get/#optional-output-flags", 
            "text": "The method's return value a JSON encoded structure, which will be written to standard output by default.   -o out  out  specifies the  destination  to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The  destination  may be  -  to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.", 
            "title": "Optional Output Flags"
        }, 
        {
            "location": "/projects_locations-get/#optional-general-properties", 
            "text": "The following properties can configure any call, and are not specific to this method.    -p $-xgafv=string   V1 error format.     -p access-token=string   OAuth access token.     -p alt=string   Data format for response.     -p callback=string   JSONP     -p fields=string   Selector specifying which fields to include in a partial response.     -p key=string   API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.     -p oauth-token=string   OAuth 2.0 token for the current user.     -p pretty-print=boolean   Returns response with indentations and line breaks.     -p quota-user=string   Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.     -p upload-type=string   Legacy upload protocol for media (e.g.  media ,  multipart ).     -p upload-protocol=string   Upload protocol for media (e.g.  raw ,  multipart ).", 
            "title": "Optional General Properties"
        }, 
        {
            "location": "/projects_locations-list/", 
            "text": "List all locations that provides at least one type of CMLE capability.\n\n\nScopes\n\n\nYou will need authorization for the \nhttps://www.googleapis.com/auth/cloud-platform\n scope to make a valid call.\n\n\nIf unset, the scope for this method defaults to \nhttps://www.googleapis.com/auth/cloud-platform\n.\nYou can set the scope for this method like this: \nml1 --scope \nscope\n projects locations-list ...\n\n\nRequired Scalar Argument\n\n\n\n\nparent\n \n(string)\n\n\nRequired. The name of the project for which available locations are to be\n    listed (since some locations might be whitelisted for specific projects).\n\n\n\n\n\n\n\n\nOptional Output Flags\n\n\nThe method's return value a JSON encoded structure, which will be written to standard output by default.\n\n\n\n\n-o out\n\n\nout\n specifies the \ndestination\n to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The \ndestination\n may be \n-\n to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.\n\n\n\n\n\n\n\n\nOptional Method Properties\n\n\nYou may set the following properties to further configure the call. Please note that \n-p\n is followed by one \nor more key-value-pairs, and is called like this \n-p k1=v1 k2=v2\n even though the listing below repeats the\n\n-p\n for completeness.\n\n\n\n\n\n\n-p page-token=string\n\n\n\n\n\n\nOptional. A page token to request the next page of results.\n\n\nYou get the token from the \nnext_page_token\n field of the response from\nthe previous call.\n\n\n\n\n\n\n\n\n\n\n-p page-size=integer\n\n\n\n\n\n\nOptional. The number of locations to retrieve per \npage\n of results. If\n    there are more remaining results than this number, the response message\n    will contain a valid value in the \nnext_page_token\n field.\n\n\nThe default value is 20, and the maximum page size is 100.\n\n\n\n\n\n\n\n\n\n\nOptional General Properties\n\n\nThe following properties can configure any call, and are not specific to this method.\n\n\n\n\n\n\n-p $-xgafv=string\n\n\n\n\nV1 error format.\n\n\n\n\n\n\n\n\n-p access-token=string\n\n\n\n\nOAuth access token.\n\n\n\n\n\n\n\n\n-p alt=string\n\n\n\n\nData format for response.\n\n\n\n\n\n\n\n\n-p callback=string\n\n\n\n\nJSONP\n\n\n\n\n\n\n\n\n-p fields=string\n\n\n\n\nSelector specifying which fields to include in a partial response.\n\n\n\n\n\n\n\n\n-p key=string\n\n\n\n\nAPI key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.\n\n\n\n\n\n\n\n\n-p oauth-token=string\n\n\n\n\nOAuth 2.0 token for the current user.\n\n\n\n\n\n\n\n\n-p pretty-print=boolean\n\n\n\n\nReturns response with indentations and line breaks.\n\n\n\n\n\n\n\n\n-p quota-user=string\n\n\n\n\nAvailable to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.\n\n\n\n\n\n\n\n\n-p upload-type=string\n\n\n\n\nLegacy upload protocol for media (e.g. \nmedia\n, \nmultipart\n).\n\n\n\n\n\n\n\n\n-p upload-protocol=string\n\n\n\n\nUpload protocol for media (e.g. \nraw\n, \nmultipart\n).", 
            "title": "Locations List"
        }, 
        {
            "location": "/projects_locations-list/#scopes", 
            "text": "You will need authorization for the  https://www.googleapis.com/auth/cloud-platform  scope to make a valid call.  If unset, the scope for this method defaults to  https://www.googleapis.com/auth/cloud-platform .\nYou can set the scope for this method like this:  ml1 --scope  scope  projects locations-list ...", 
            "title": "Scopes"
        }, 
        {
            "location": "/projects_locations-list/#required-scalar-argument", 
            "text": "parent   (string)  Required. The name of the project for which available locations are to be\n    listed (since some locations might be whitelisted for specific projects).", 
            "title": "Required Scalar Argument"
        }, 
        {
            "location": "/projects_locations-list/#optional-output-flags", 
            "text": "The method's return value a JSON encoded structure, which will be written to standard output by default.   -o out  out  specifies the  destination  to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The  destination  may be  -  to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.", 
            "title": "Optional Output Flags"
        }, 
        {
            "location": "/projects_locations-list/#optional-method-properties", 
            "text": "You may set the following properties to further configure the call. Please note that  -p  is followed by one \nor more key-value-pairs, and is called like this  -p k1=v1 k2=v2  even though the listing below repeats the -p  for completeness.    -p page-token=string    Optional. A page token to request the next page of results.  You get the token from the  next_page_token  field of the response from\nthe previous call.      -p page-size=integer    Optional. The number of locations to retrieve per  page  of results. If\n    there are more remaining results than this number, the response message\n    will contain a valid value in the  next_page_token  field.  The default value is 20, and the maximum page size is 100.", 
            "title": "Optional Method Properties"
        }, 
        {
            "location": "/projects_locations-list/#optional-general-properties", 
            "text": "The following properties can configure any call, and are not specific to this method.    -p $-xgafv=string   V1 error format.     -p access-token=string   OAuth access token.     -p alt=string   Data format for response.     -p callback=string   JSONP     -p fields=string   Selector specifying which fields to include in a partial response.     -p key=string   API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.     -p oauth-token=string   OAuth 2.0 token for the current user.     -p pretty-print=boolean   Returns response with indentations and line breaks.     -p quota-user=string   Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.     -p upload-type=string   Legacy upload protocol for media (e.g.  media ,  multipart ).     -p upload-protocol=string   Upload protocol for media (e.g.  raw ,  multipart ).", 
            "title": "Optional General Properties"
        }, 
        {
            "location": "/projects_models-create/", 
            "text": "Creates a model which will later contain one or more versions.\n\n\nYou must add at least one version before you can request predictions from\nthe model. Add versions by calling\n\nprojects.models.versions.create\n.\n\n\nScopes\n\n\nYou will need authorization for the \nhttps://www.googleapis.com/auth/cloud-platform\n scope to make a valid call.\n\n\nIf unset, the scope for this method defaults to \nhttps://www.googleapis.com/auth/cloud-platform\n.\nYou can set the scope for this method like this: \nml1 --scope \nscope\n projects models-create ...\n\n\nRequired Scalar Argument\n\n\n\n\nparent\n \n(string)\n\n\nRequired. The project name.\n\n\n\n\n\n\n\n\nRequired Request Value\n\n\nThe request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure.\nIn the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely.\n\n\nFor example, a structure like this:\n\n\nGoogleCloudMlV1__Model:\n  default-version:\n    auto-scaling:\n      min-nodes: integer\n    create-time: string\n    deployment-uri: string\n    description: string\n    error-message: string\n    etag: string\n    framework: string\n    is-default: boolean\n    labels: { string: string }\n    last-use-time: string\n    machine-type: string\n    manual-scaling:\n      nodes: integer\n    name: string\n    package-uris: [string]\n    prediction-class: string\n    python-version: string\n    runtime-version: string\n    service-account: string\n    state: string\n  description: string\n  etag: string\n  labels: { string: string }\n  name: string\n  online-prediction-console-logging: boolean\n  online-prediction-logging: boolean\n  regions: [string]\n\n\n\n\n\ncan be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time.\n\n\n\n\n\n\n-r .default-version.auto-scaling    min-nodes=34\n\n\n\n\n\n\nOptional. The minimum number of nodes to allocate for this model. These\n    nodes are always up, starting from the time the model is deployed.\n    Therefore, the cost of operating this model will be at least\n    \nrate\n * \nmin_nodes\n * number of hours since last billing cycle,\n    where \nrate\n is the cost per node-hour as documented in the\n    \npricing guide\n,\n    even if no predictions are performed. There is additional cost for each\n    prediction performed.\n\n\nUnlike manual scaling, if the load gets too heavy for the nodes\nthat are up, the service will automatically add nodes to handle the\nincreased load as well as scale back as traffic drops, always maintaining\nat least \nmin_nodes\n. You will be charged for the time in which additional\nnodes are used.\n\n\nIf not specified, \nmin_nodes\n defaults to 0, in which case, when traffic\nto a model stops (and after a cool-down period), nodes will be shut down\nand no charges will be incurred until traffic to the model resumes.\n\n\nYou can set \nmin_nodes\n when creating the model version, and you can also\nupdate \nmin_nodes\n for an existing version:\n\npre\n\nupdate_body.json:\n{\n  \nautoScaling\n: {\n    \nminNodes\n: 5\n  }\n}\n\n/pre\n\nHTTP request:\n\npre\n\nPATCH\nhttps://ml.googleapis.com/v1/{name=projects/\n/models/\n/versions/*}?update_mask=autoScaling.minNodes\n-d @./update_body.json\n\n/pre\n\n\n\n\n\n\n\n\n\n\n..    create-time=ea\n\n\n\n\nOutput only. The time the version was created.\n\n\n\n\n\n\n\n\ndeployment-uri=et\n\n\n\n\n\n\nRequired. The Cloud Storage location of the trained model used to\n    create the version. See the\n    \nguide to model\n    deployment\n for more\n    information.\n\n\nWhen passing Version to\n\nprojects.models.versions.create\n\nthe model service uses the specified location as the source of the model.\nOnce deployed, the model version is hosted by the prediction service, so\nthis location is useful only as a historical record.\nThe total number of model files can\nt exceed 1000.\n* \ndescription=dolor\n\n    - Optional. The description specified for the version when it was created.\n* \nerror-message=diam\n\n    - Output only. The details of a failure or a cancellation.\n* \netag=kasd\n\n    - \netag\n is used for optimistic concurrency control as a way to help\nprevent simultaneous updates of a model from overwriting each other.\nIt is strongly suggested that systems make use of the \netag\n in the\nread-modify-write cycle to perform model updates in order to avoid race\nconditions: An \netag\n is returned in the response to \nGetVersion\n, and\nsystems are expected to put that etag in the request to \nUpdateVersion\n to\nensure that their change will be applied to the model as intended.\n* \nframework=invidunt\n\n    - Optional. The machine learning framework AI Platform uses to train\nthis version of the model. Valid values are \nTENSORFLOW\n, \nSCIKIT_LEARN\n,\n\nXGBOOST\n. If you do not specify a framework, AI Platform\nwill analyze files in the deployment_uri to determine a framework. If you\nchoose \nSCIKIT_LEARN\n or \nXGBOOST\n, you must also set the runtime version\nof the model to 1.4 or greater.\n\n\nDo \nnot\n specify a framework if you\nre deploying a \ncustom\nprediction routine\n.\n* \nis-default=true\n\n    - Output only. If true, this version will be used to handle prediction\nrequests that do not specify a version.\n\n\nYou can change the default version by calling\n\nprojects.methods.versions.setDefault\n.\n* \nlabels=key=lorem\n\n    - Optional. One or more labels that you can add, to organize your model\nversions. Each label is a key-value pair, where both the key and the value\nare arbitrary strings that you supply.\nFor more information, see the documentation on\n\na href=\n/ml-engine/docs/tensorflow/resource-labels\nusing labels\n/a\n.\n    - the value will be associated with the given \nkey\n\n* \nlast-use-time=clita\n\n    - Output only. The time the version was last used for prediction.\n* \nmachine-type=invidunt\n\n    - Optional. The type of machine on which to serve the model. Currently only\napplies to online prediction service.\n\ndl\n\n  \ndt\nmls1-c1-m2\n/dt\n\n  \ndd\n\n  The \nb\ndefault\n/b\n machine type, with 1 core and 2 GB RAM. The deprecated\n  name for this machine type is \nmls1-highmem-1\n.\n  \n/dd\n\n  \ndt\nmls1-c4-m2\n/dt\n\n  \ndd\n\n  In \nb\nBeta\n/b\n. This machine type has 4 cores and 2 GB RAM. The\n  deprecated name for this machine type is \nmls1-highcpu-4\n.\n  \n/dd\n\n\n/dl\n\n* \nmanual-scaling    nodes=11\n\n    - The number of nodes to allocate for this model. These nodes are always up,\nstarting from the time the model is deployed, so the cost of operating\nthis model will be proportional to \nnodes\n * number of hours since\nlast billing cycle plus the cost for each prediction performed.\n\n\n\n\n\n\n\n\n\n\n..    name=at\n\n\n\n\n\n\nRequired.The name specified for the version when it was created.\n\n\nThe version name must be unique within the model it is created in.\n* \npackage-uris=consetetur\n\n    - Optional. Cloud Storage paths (\ngs://\u2026\n) of packages for \ncustom\nprediction routines\n\nor \nscikit-learn pipelines with custom\ncode\n.\n\n\nFor a custom prediction routine, one of these packages must contain your\nPredictor class (see\n\npredictionClass\n). Additionally,\ninclude any dependencies used by your Predictor or scikit-learn pipeline\nuses that are not already included in your selected \nruntime\nversion\n.\n\n\nIf you specify this field, you must also set\n\nruntimeVersion\n to 1.4 or greater.\n    - Each invocation of this argument appends the given value to the array.\n* \nprediction-class=et\n\n    - Optional. The fully qualified name\n(\nvar\nmodule_name\n/var\n.\nvar\nclass_name\n/var\n) of a class that implements\nthe Predictor interface described in this reference field. The module\ncontaining this class should be included in a package provided to the\n\npackageUris\n field\n.\n\n\nSpecify this field if and only if you are deploying a \ncustom prediction\nroutine (beta)\n.\nIf you specify this field, you must set\n\nruntimeVersion\n to 1.4 or greater.\n\n\nThe following code sample provides the Predictor interface:\n\n\n```py\nclass Predictor(object):\n\nInterface for constructing custom predictors.\n\n\ndef predict(self, instances, **kwargs):\n    \nPerforms custom prediction.\n\n\nInstances are the decoded values from the request. They have already\nbeen deserialized from JSON.\n\nArgs:\n    instances: A list of prediction input instances.\n    **kwargs: A dictionary of keyword args provided as additional\n        fields on the predict request body.\n\nReturns:\n    A list of outputs containing the prediction results. This list must\n    be JSON serializable.\n\n#34;\n#34;\n#34;\nraise NotImplementedError()\n\n\n\n@classmethod\ndef from_path(cls, model_dir):\n    \nCreates an instance of Predictor using the given path.\n\n\nLoading of the predictor should be done in this method.\n\nArgs:\n    model_dir: The local directory that contains the exported model\n        file along with any additional files uploaded when creating the\n        version resource.\n\nReturns:\n    An instance implementing this Predictor class.\n\n#34;\n#34;\n#34;\nraise NotImplementedError()\n\n\n\n```\n\n\nLearn more about \nthe Predictor interface and custom prediction\nroutines\n.\n* \npython-version=sed\n\n    - Optional. The version of Python used in prediction. If not set, the default\nversion is \n2.7\n. Python \n3.5\n is available when \nruntime_version\n is set\nto \n1.4\n and above. Python \n2.7\n works with all supported runtime versions.\n* \nruntime-version=sit\n\n    - Optional. The AI Platform runtime version to use for this deployment.\nIf not set, AI Platform uses the default stable version, 1.0. For more\ninformation, see the\n\nruntime version list\n and\n\nhow to manage runtime versions\n.\n* \nservice-account=takimata\n\n    - Optional. Specifies the service account for resource access control.\n* \nstate=elitr\n\n    - Output only. The state of a version.\n\n\n\n\n\n\n\n\n\n\n..    description=nonumy\n\n\n\n\nOptional. The description specified for the model when it was created.\n\n\n\n\n\n\netag=rebum.\n\n\netag\n is used for optimistic concurrency control as a way to help\n    prevent simultaneous updates of a model from overwriting each other.\n    It is strongly suggested that systems make use of the \netag\n in the\n    read-modify-write cycle to perform model updates in order to avoid race\n    conditions: An \netag\n is returned in the response to \nGetModel\n, and\n    systems are expected to put that etag in the request to \nUpdateModel\n to\n    ensure that their change will be applied to the model as intended.\n\n\n\n\n\n\nlabels=key=lorem\n\n\nOptional. One or more labels that you can add, to organize your models.\n    Each label is a key-value pair, where both the key and the value are\n    arbitrary strings that you supply.\n    For more information, see the documentation on\n    \na href=\n/ml-engine/docs/tensorflow/resource-labels\nusing labels\n/a\n.\n\n\nthe value will be associated with the given \nkey\n\n\n\n\n\n\nname=lorem\n\n\n\n\nRequired. The name specified for the model when it was created.\n\n\nThe model name must be unique within the project it is created in.\n* \nonline-prediction-console-logging=true\n\n    - Optional. If true, online prediction nodes send \nstderr\n and \nstdout\n\nstreams to Stackdriver Logging. These can be more verbose than the standard\naccess logs (see \nonlinePredictionLogging\n) and can incur higher cost.\nHowever, they are helpful for debugging. Note that\n\nStackdriver logs may incur a cost\n, especially if\nyour project receives prediction requests at a high QPS. Estimate your\ncosts before enabling this option.\n\n\nDefault is false.\n* \nonline-prediction-logging=true\n\n    - Optional. If true, online prediction access logs are sent to StackDriver\nLogging. These logs are like standard server access logs, containing\ninformation like timestamp and latency for each request. Note that\n\nStackdriver logs may incur a cost\n, especially if\nyour project receives prediction requests at a high queries per second rate\n(QPS). Estimate your costs before enabling this option.\n\n\nDefault is false.\n* \nregions=ut\n\n    - Optional. The list of regions where the model is going to be deployed.\nCurrently only one region per model is supported.\nDefaults to \nus-central1\n if nothing is set.\nSee the \na href=\n/ml-engine/docs/tensorflow/regions\navailable regions\n/a\n\nfor AI Platform services.\nNote:\n*   No matter where a model is deployed, it can always be accessed by\n    users from anywhere, both for online and batch prediction.\n*   The region for a batch prediction job is set by the region field when\n    submitting the batch prediction job and does not take its value from\n    this field.\n    - Each invocation of this argument appends the given value to the array.\n\n\n\n\n\n\n\n\n\n\nAbout Cursors\n\n\nThe cursor position is key to comfortably set complex nested structures. The following rules apply:\n\n\n\n\nThe cursor position is always set relative to the current one, unless the field name starts with the \n.\n character. Fields can be nested such as in \n-r f.s.o\n .\n\n\nThe cursor position is set relative to the top-level structure if it starts with \n.\n, e.g. \n-r .s.s\n\n\nYou can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify \n-r struct.sub_struct=bar\n.\n\n\nYou can move the cursor one level up by using \n..\n. Each additional \n.\n moves it up one additional level. E.g. \n...\n would go three levels up.\n\n\n\n\nOptional Output Flags\n\n\nThe method's return value a JSON encoded structure, which will be written to standard output by default.\n\n\n\n\n-o out\n\n\nout\n specifies the \ndestination\n to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The \ndestination\n may be \n-\n to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.\n\n\n\n\n\n\n\n\nOptional General Properties\n\n\nThe following properties can configure any call, and are not specific to this method.\n\n\n\n\n\n\n-p $-xgafv=string\n\n\n\n\nV1 error format.\n\n\n\n\n\n\n\n\n-p access-token=string\n\n\n\n\nOAuth access token.\n\n\n\n\n\n\n\n\n-p alt=string\n\n\n\n\nData format for response.\n\n\n\n\n\n\n\n\n-p callback=string\n\n\n\n\nJSONP\n\n\n\n\n\n\n\n\n-p fields=string\n\n\n\n\nSelector specifying which fields to include in a partial response.\n\n\n\n\n\n\n\n\n-p key=string\n\n\n\n\nAPI key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.\n\n\n\n\n\n\n\n\n-p oauth-token=string\n\n\n\n\nOAuth 2.0 token for the current user.\n\n\n\n\n\n\n\n\n-p pretty-print=boolean\n\n\n\n\nReturns response with indentations and line breaks.\n\n\n\n\n\n\n\n\n-p quota-user=string\n\n\n\n\nAvailable to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.\n\n\n\n\n\n\n\n\n-p upload-type=string\n\n\n\n\nLegacy upload protocol for media (e.g. \nmedia\n, \nmultipart\n).\n\n\n\n\n\n\n\n\n-p upload-protocol=string\n\n\n\n\nUpload protocol for media (e.g. \nraw\n, \nmultipart\n).", 
            "title": "Models Create"
        }, 
        {
            "location": "/projects_models-create/#scopes", 
            "text": "You will need authorization for the  https://www.googleapis.com/auth/cloud-platform  scope to make a valid call.  If unset, the scope for this method defaults to  https://www.googleapis.com/auth/cloud-platform .\nYou can set the scope for this method like this:  ml1 --scope  scope  projects models-create ...", 
            "title": "Scopes"
        }, 
        {
            "location": "/projects_models-create/#required-scalar-argument", 
            "text": "parent   (string)  Required. The project name.", 
            "title": "Required Scalar Argument"
        }, 
        {
            "location": "/projects_models-create/#required-request-value", 
            "text": "The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure.\nIn the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely.  For example, a structure like this:  GoogleCloudMlV1__Model:\n  default-version:\n    auto-scaling:\n      min-nodes: integer\n    create-time: string\n    deployment-uri: string\n    description: string\n    error-message: string\n    etag: string\n    framework: string\n    is-default: boolean\n    labels: { string: string }\n    last-use-time: string\n    machine-type: string\n    manual-scaling:\n      nodes: integer\n    name: string\n    package-uris: [string]\n    prediction-class: string\n    python-version: string\n    runtime-version: string\n    service-account: string\n    state: string\n  description: string\n  etag: string\n  labels: { string: string }\n  name: string\n  online-prediction-console-logging: boolean\n  online-prediction-logging: boolean\n  regions: [string]  can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time.    -r .default-version.auto-scaling    min-nodes=34    Optional. The minimum number of nodes to allocate for this model. These\n    nodes are always up, starting from the time the model is deployed.\n    Therefore, the cost of operating this model will be at least\n     rate  *  min_nodes  * number of hours since last billing cycle,\n    where  rate  is the cost per node-hour as documented in the\n     pricing guide ,\n    even if no predictions are performed. There is additional cost for each\n    prediction performed.  Unlike manual scaling, if the load gets too heavy for the nodes\nthat are up, the service will automatically add nodes to handle the\nincreased load as well as scale back as traffic drops, always maintaining\nat least  min_nodes . You will be charged for the time in which additional\nnodes are used.  If not specified,  min_nodes  defaults to 0, in which case, when traffic\nto a model stops (and after a cool-down period), nodes will be shut down\nand no charges will be incurred until traffic to the model resumes.  You can set  min_nodes  when creating the model version, and you can also\nupdate  min_nodes  for an existing version: pre \nupdate_body.json:\n{\n   autoScaling : {\n     minNodes : 5\n  }\n} /pre \nHTTP request: pre \nPATCH\nhttps://ml.googleapis.com/v1/{name=projects/ /models/ /versions/*}?update_mask=autoScaling.minNodes\n-d @./update_body.json /pre      ..    create-time=ea   Output only. The time the version was created.     deployment-uri=et    Required. The Cloud Storage location of the trained model used to\n    create the version. See the\n     guide to model\n    deployment  for more\n    information.  When passing Version to projects.models.versions.create \nthe model service uses the specified location as the source of the model.\nOnce deployed, the model version is hosted by the prediction service, so\nthis location is useful only as a historical record.\nThe total number of model files can t exceed 1000.\n*  description=dolor \n    - Optional. The description specified for the version when it was created.\n*  error-message=diam \n    - Output only. The details of a failure or a cancellation.\n*  etag=kasd \n    -  etag  is used for optimistic concurrency control as a way to help\nprevent simultaneous updates of a model from overwriting each other.\nIt is strongly suggested that systems make use of the  etag  in the\nread-modify-write cycle to perform model updates in order to avoid race\nconditions: An  etag  is returned in the response to  GetVersion , and\nsystems are expected to put that etag in the request to  UpdateVersion  to\nensure that their change will be applied to the model as intended.\n*  framework=invidunt \n    - Optional. The machine learning framework AI Platform uses to train\nthis version of the model. Valid values are  TENSORFLOW ,  SCIKIT_LEARN , XGBOOST . If you do not specify a framework, AI Platform\nwill analyze files in the deployment_uri to determine a framework. If you\nchoose  SCIKIT_LEARN  or  XGBOOST , you must also set the runtime version\nof the model to 1.4 or greater.  Do  not  specify a framework if you re deploying a  custom\nprediction routine .\n*  is-default=true \n    - Output only. If true, this version will be used to handle prediction\nrequests that do not specify a version.  You can change the default version by calling projects.methods.versions.setDefault .\n*  labels=key=lorem \n    - Optional. One or more labels that you can add, to organize your model\nversions. Each label is a key-value pair, where both the key and the value\nare arbitrary strings that you supply.\nFor more information, see the documentation on a href= /ml-engine/docs/tensorflow/resource-labels using labels /a .\n    - the value will be associated with the given  key \n*  last-use-time=clita \n    - Output only. The time the version was last used for prediction.\n*  machine-type=invidunt \n    - Optional. The type of machine on which to serve the model. Currently only\napplies to online prediction service. dl \n   dt mls1-c1-m2 /dt \n   dd \n  The  b default /b  machine type, with 1 core and 2 GB RAM. The deprecated\n  name for this machine type is  mls1-highmem-1 .\n   /dd \n   dt mls1-c4-m2 /dt \n   dd \n  In  b Beta /b . This machine type has 4 cores and 2 GB RAM. The\n  deprecated name for this machine type is  mls1-highcpu-4 .\n   /dd  /dl \n*  manual-scaling    nodes=11 \n    - The number of nodes to allocate for this model. These nodes are always up,\nstarting from the time the model is deployed, so the cost of operating\nthis model will be proportional to  nodes  * number of hours since\nlast billing cycle plus the cost for each prediction performed.      ..    name=at    Required.The name specified for the version when it was created.  The version name must be unique within the model it is created in.\n*  package-uris=consetetur \n    - Optional. Cloud Storage paths ( gs://\u2026 ) of packages for  custom\nprediction routines \nor  scikit-learn pipelines with custom\ncode .  For a custom prediction routine, one of these packages must contain your\nPredictor class (see predictionClass ). Additionally,\ninclude any dependencies used by your Predictor or scikit-learn pipeline\nuses that are not already included in your selected  runtime\nversion .  If you specify this field, you must also set runtimeVersion  to 1.4 or greater.\n    - Each invocation of this argument appends the given value to the array.\n*  prediction-class=et \n    - Optional. The fully qualified name\n( var module_name /var . var class_name /var ) of a class that implements\nthe Predictor interface described in this reference field. The module\ncontaining this class should be included in a package provided to the packageUris  field .  Specify this field if and only if you are deploying a  custom prediction\nroutine (beta) .\nIf you specify this field, you must set runtimeVersion  to 1.4 or greater.  The following code sample provides the Predictor interface:  ```py\nclass Predictor(object): Interface for constructing custom predictors.  def predict(self, instances, **kwargs):\n     Performs custom prediction.  Instances are the decoded values from the request. They have already\nbeen deserialized from JSON.\n\nArgs:\n    instances: A list of prediction input instances.\n    **kwargs: A dictionary of keyword args provided as additional\n        fields on the predict request body.\n\nReturns:\n    A list of outputs containing the prediction results. This list must\n    be JSON serializable. #34; #34; #34;\nraise NotImplementedError()  @classmethod\ndef from_path(cls, model_dir):\n     Creates an instance of Predictor using the given path.  Loading of the predictor should be done in this method.\n\nArgs:\n    model_dir: The local directory that contains the exported model\n        file along with any additional files uploaded when creating the\n        version resource.\n\nReturns:\n    An instance implementing this Predictor class. #34; #34; #34;\nraise NotImplementedError()  ```  Learn more about  the Predictor interface and custom prediction\nroutines .\n*  python-version=sed \n    - Optional. The version of Python used in prediction. If not set, the default\nversion is  2.7 . Python  3.5  is available when  runtime_version  is set\nto  1.4  and above. Python  2.7  works with all supported runtime versions.\n*  runtime-version=sit \n    - Optional. The AI Platform runtime version to use for this deployment.\nIf not set, AI Platform uses the default stable version, 1.0. For more\ninformation, see the runtime version list  and how to manage runtime versions .\n*  service-account=takimata \n    - Optional. Specifies the service account for resource access control.\n*  state=elitr \n    - Output only. The state of a version.      ..    description=nonumy   Optional. The description specified for the model when it was created.    etag=rebum.  etag  is used for optimistic concurrency control as a way to help\n    prevent simultaneous updates of a model from overwriting each other.\n    It is strongly suggested that systems make use of the  etag  in the\n    read-modify-write cycle to perform model updates in order to avoid race\n    conditions: An  etag  is returned in the response to  GetModel , and\n    systems are expected to put that etag in the request to  UpdateModel  to\n    ensure that their change will be applied to the model as intended.    labels=key=lorem  Optional. One or more labels that you can add, to organize your models.\n    Each label is a key-value pair, where both the key and the value are\n    arbitrary strings that you supply.\n    For more information, see the documentation on\n     a href= /ml-engine/docs/tensorflow/resource-labels using labels /a .  the value will be associated with the given  key    name=lorem   Required. The name specified for the model when it was created.  The model name must be unique within the project it is created in.\n*  online-prediction-console-logging=true \n    - Optional. If true, online prediction nodes send  stderr  and  stdout \nstreams to Stackdriver Logging. These can be more verbose than the standard\naccess logs (see  onlinePredictionLogging ) and can incur higher cost.\nHowever, they are helpful for debugging. Note that Stackdriver logs may incur a cost , especially if\nyour project receives prediction requests at a high QPS. Estimate your\ncosts before enabling this option.  Default is false.\n*  online-prediction-logging=true \n    - Optional. If true, online prediction access logs are sent to StackDriver\nLogging. These logs are like standard server access logs, containing\ninformation like timestamp and latency for each request. Note that Stackdriver logs may incur a cost , especially if\nyour project receives prediction requests at a high queries per second rate\n(QPS). Estimate your costs before enabling this option.  Default is false.\n*  regions=ut \n    - Optional. The list of regions where the model is going to be deployed.\nCurrently only one region per model is supported.\nDefaults to  us-central1  if nothing is set.\nSee the  a href= /ml-engine/docs/tensorflow/regions available regions /a \nfor AI Platform services.\nNote:\n*   No matter where a model is deployed, it can always be accessed by\n    users from anywhere, both for online and batch prediction.\n*   The region for a batch prediction job is set by the region field when\n    submitting the batch prediction job and does not take its value from\n    this field.\n    - Each invocation of this argument appends the given value to the array.", 
            "title": "Required Request Value"
        }, 
        {
            "location": "/projects_models-create/#about-cursors", 
            "text": "The cursor position is key to comfortably set complex nested structures. The following rules apply:   The cursor position is always set relative to the current one, unless the field name starts with the  .  character. Fields can be nested such as in  -r f.s.o  .  The cursor position is set relative to the top-level structure if it starts with  . , e.g.  -r .s.s  You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify  -r struct.sub_struct=bar .  You can move the cursor one level up by using  .. . Each additional  .  moves it up one additional level. E.g.  ...  would go three levels up.", 
            "title": "About Cursors"
        }, 
        {
            "location": "/projects_models-create/#optional-output-flags", 
            "text": "The method's return value a JSON encoded structure, which will be written to standard output by default.   -o out  out  specifies the  destination  to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The  destination  may be  -  to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.", 
            "title": "Optional Output Flags"
        }, 
        {
            "location": "/projects_models-create/#optional-general-properties", 
            "text": "The following properties can configure any call, and are not specific to this method.    -p $-xgafv=string   V1 error format.     -p access-token=string   OAuth access token.     -p alt=string   Data format for response.     -p callback=string   JSONP     -p fields=string   Selector specifying which fields to include in a partial response.     -p key=string   API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.     -p oauth-token=string   OAuth 2.0 token for the current user.     -p pretty-print=boolean   Returns response with indentations and line breaks.     -p quota-user=string   Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.     -p upload-type=string   Legacy upload protocol for media (e.g.  media ,  multipart ).     -p upload-protocol=string   Upload protocol for media (e.g.  raw ,  multipart ).", 
            "title": "Optional General Properties"
        }, 
        {
            "location": "/projects_models-delete/", 
            "text": "Deletes a model.\n\n\nYou can only delete a model if there are no versions in it. You can delete\nversions by calling\n\nprojects.models.versions.delete\n.\n\n\nScopes\n\n\nYou will need authorization for the \nhttps://www.googleapis.com/auth/cloud-platform\n scope to make a valid call.\n\n\nIf unset, the scope for this method defaults to \nhttps://www.googleapis.com/auth/cloud-platform\n.\nYou can set the scope for this method like this: \nml1 --scope \nscope\n projects models-delete ...\n\n\nRequired Scalar Argument\n\n\n\n\nname\n \n(string)\n\n\nRequired. The name of the model.\n\n\n\n\n\n\n\n\nOptional Output Flags\n\n\nThe method's return value a JSON encoded structure, which will be written to standard output by default.\n\n\n\n\n-o out\n\n\nout\n specifies the \ndestination\n to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The \ndestination\n may be \n-\n to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.\n\n\n\n\n\n\n\n\nOptional General Properties\n\n\nThe following properties can configure any call, and are not specific to this method.\n\n\n\n\n\n\n-p $-xgafv=string\n\n\n\n\nV1 error format.\n\n\n\n\n\n\n\n\n-p access-token=string\n\n\n\n\nOAuth access token.\n\n\n\n\n\n\n\n\n-p alt=string\n\n\n\n\nData format for response.\n\n\n\n\n\n\n\n\n-p callback=string\n\n\n\n\nJSONP\n\n\n\n\n\n\n\n\n-p fields=string\n\n\n\n\nSelector specifying which fields to include in a partial response.\n\n\n\n\n\n\n\n\n-p key=string\n\n\n\n\nAPI key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.\n\n\n\n\n\n\n\n\n-p oauth-token=string\n\n\n\n\nOAuth 2.0 token for the current user.\n\n\n\n\n\n\n\n\n-p pretty-print=boolean\n\n\n\n\nReturns response with indentations and line breaks.\n\n\n\n\n\n\n\n\n-p quota-user=string\n\n\n\n\nAvailable to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.\n\n\n\n\n\n\n\n\n-p upload-type=string\n\n\n\n\nLegacy upload protocol for media (e.g. \nmedia\n, \nmultipart\n).\n\n\n\n\n\n\n\n\n-p upload-protocol=string\n\n\n\n\nUpload protocol for media (e.g. \nraw\n, \nmultipart\n).", 
            "title": "Models Delete"
        }, 
        {
            "location": "/projects_models-delete/#scopes", 
            "text": "You will need authorization for the  https://www.googleapis.com/auth/cloud-platform  scope to make a valid call.  If unset, the scope for this method defaults to  https://www.googleapis.com/auth/cloud-platform .\nYou can set the scope for this method like this:  ml1 --scope  scope  projects models-delete ...", 
            "title": "Scopes"
        }, 
        {
            "location": "/projects_models-delete/#required-scalar-argument", 
            "text": "name   (string)  Required. The name of the model.", 
            "title": "Required Scalar Argument"
        }, 
        {
            "location": "/projects_models-delete/#optional-output-flags", 
            "text": "The method's return value a JSON encoded structure, which will be written to standard output by default.   -o out  out  specifies the  destination  to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The  destination  may be  -  to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.", 
            "title": "Optional Output Flags"
        }, 
        {
            "location": "/projects_models-delete/#optional-general-properties", 
            "text": "The following properties can configure any call, and are not specific to this method.    -p $-xgafv=string   V1 error format.     -p access-token=string   OAuth access token.     -p alt=string   Data format for response.     -p callback=string   JSONP     -p fields=string   Selector specifying which fields to include in a partial response.     -p key=string   API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.     -p oauth-token=string   OAuth 2.0 token for the current user.     -p pretty-print=boolean   Returns response with indentations and line breaks.     -p quota-user=string   Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.     -p upload-type=string   Legacy upload protocol for media (e.g.  media ,  multipart ).     -p upload-protocol=string   Upload protocol for media (e.g.  raw ,  multipart ).", 
            "title": "Optional General Properties"
        }, 
        {
            "location": "/projects_models-get/", 
            "text": "Gets information about a model, including its name, the description (if\nset), and the default version (if at least one version of the model has\nbeen deployed).\n\n\nScopes\n\n\nYou will need authorization for the \nhttps://www.googleapis.com/auth/cloud-platform\n scope to make a valid call.\n\n\nIf unset, the scope for this method defaults to \nhttps://www.googleapis.com/auth/cloud-platform\n.\nYou can set the scope for this method like this: \nml1 --scope \nscope\n projects models-get ...\n\n\nRequired Scalar Argument\n\n\n\n\nname\n \n(string)\n\n\nRequired. The name of the model.\n\n\n\n\n\n\n\n\nOptional Output Flags\n\n\nThe method's return value a JSON encoded structure, which will be written to standard output by default.\n\n\n\n\n-o out\n\n\nout\n specifies the \ndestination\n to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The \ndestination\n may be \n-\n to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.\n\n\n\n\n\n\n\n\nOptional General Properties\n\n\nThe following properties can configure any call, and are not specific to this method.\n\n\n\n\n\n\n-p $-xgafv=string\n\n\n\n\nV1 error format.\n\n\n\n\n\n\n\n\n-p access-token=string\n\n\n\n\nOAuth access token.\n\n\n\n\n\n\n\n\n-p alt=string\n\n\n\n\nData format for response.\n\n\n\n\n\n\n\n\n-p callback=string\n\n\n\n\nJSONP\n\n\n\n\n\n\n\n\n-p fields=string\n\n\n\n\nSelector specifying which fields to include in a partial response.\n\n\n\n\n\n\n\n\n-p key=string\n\n\n\n\nAPI key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.\n\n\n\n\n\n\n\n\n-p oauth-token=string\n\n\n\n\nOAuth 2.0 token for the current user.\n\n\n\n\n\n\n\n\n-p pretty-print=boolean\n\n\n\n\nReturns response with indentations and line breaks.\n\n\n\n\n\n\n\n\n-p quota-user=string\n\n\n\n\nAvailable to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.\n\n\n\n\n\n\n\n\n-p upload-type=string\n\n\n\n\nLegacy upload protocol for media (e.g. \nmedia\n, \nmultipart\n).\n\n\n\n\n\n\n\n\n-p upload-protocol=string\n\n\n\n\nUpload protocol for media (e.g. \nraw\n, \nmultipart\n).", 
            "title": "Models Get"
        }, 
        {
            "location": "/projects_models-get/#scopes", 
            "text": "You will need authorization for the  https://www.googleapis.com/auth/cloud-platform  scope to make a valid call.  If unset, the scope for this method defaults to  https://www.googleapis.com/auth/cloud-platform .\nYou can set the scope for this method like this:  ml1 --scope  scope  projects models-get ...", 
            "title": "Scopes"
        }, 
        {
            "location": "/projects_models-get/#required-scalar-argument", 
            "text": "name   (string)  Required. The name of the model.", 
            "title": "Required Scalar Argument"
        }, 
        {
            "location": "/projects_models-get/#optional-output-flags", 
            "text": "The method's return value a JSON encoded structure, which will be written to standard output by default.   -o out  out  specifies the  destination  to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The  destination  may be  -  to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.", 
            "title": "Optional Output Flags"
        }, 
        {
            "location": "/projects_models-get/#optional-general-properties", 
            "text": "The following properties can configure any call, and are not specific to this method.    -p $-xgafv=string   V1 error format.     -p access-token=string   OAuth access token.     -p alt=string   Data format for response.     -p callback=string   JSONP     -p fields=string   Selector specifying which fields to include in a partial response.     -p key=string   API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.     -p oauth-token=string   OAuth 2.0 token for the current user.     -p pretty-print=boolean   Returns response with indentations and line breaks.     -p quota-user=string   Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.     -p upload-type=string   Legacy upload protocol for media (e.g.  media ,  multipart ).     -p upload-protocol=string   Upload protocol for media (e.g.  raw ,  multipart ).", 
            "title": "Optional General Properties"
        }, 
        {
            "location": "/projects_models-get-iam-policy/", 
            "text": "Gets the access control policy for a resource.\nReturns an empty policy if the resource exists and does not have a policy\nset.\n\n\nScopes\n\n\nYou will need authorization for the \nhttps://www.googleapis.com/auth/cloud-platform\n scope to make a valid call.\n\n\nIf unset, the scope for this method defaults to \nhttps://www.googleapis.com/auth/cloud-platform\n.\nYou can set the scope for this method like this: \nml1 --scope \nscope\n projects models-get-iam-policy ...\n\n\nRequired Scalar Argument\n\n\n\n\nresource\n \n(string)\n\n\nREQUIRED: The resource for which the policy is being requested.\n    See the operation documentation for the appropriate value for this field.\n\n\n\n\n\n\n\n\nOptional Output Flags\n\n\nThe method's return value a JSON encoded structure, which will be written to standard output by default.\n\n\n\n\n-o out\n\n\nout\n specifies the \ndestination\n to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The \ndestination\n may be \n-\n to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.\n\n\n\n\n\n\n\n\nOptional General Properties\n\n\nThe following properties can configure any call, and are not specific to this method.\n\n\n\n\n\n\n-p $-xgafv=string\n\n\n\n\nV1 error format.\n\n\n\n\n\n\n\n\n-p access-token=string\n\n\n\n\nOAuth access token.\n\n\n\n\n\n\n\n\n-p alt=string\n\n\n\n\nData format for response.\n\n\n\n\n\n\n\n\n-p callback=string\n\n\n\n\nJSONP\n\n\n\n\n\n\n\n\n-p fields=string\n\n\n\n\nSelector specifying which fields to include in a partial response.\n\n\n\n\n\n\n\n\n-p key=string\n\n\n\n\nAPI key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.\n\n\n\n\n\n\n\n\n-p oauth-token=string\n\n\n\n\nOAuth 2.0 token for the current user.\n\n\n\n\n\n\n\n\n-p pretty-print=boolean\n\n\n\n\nReturns response with indentations and line breaks.\n\n\n\n\n\n\n\n\n-p quota-user=string\n\n\n\n\nAvailable to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.\n\n\n\n\n\n\n\n\n-p upload-type=string\n\n\n\n\nLegacy upload protocol for media (e.g. \nmedia\n, \nmultipart\n).\n\n\n\n\n\n\n\n\n-p upload-protocol=string\n\n\n\n\nUpload protocol for media (e.g. \nraw\n, \nmultipart\n).", 
            "title": "Models Get Iam Policy"
        }, 
        {
            "location": "/projects_models-get-iam-policy/#scopes", 
            "text": "You will need authorization for the  https://www.googleapis.com/auth/cloud-platform  scope to make a valid call.  If unset, the scope for this method defaults to  https://www.googleapis.com/auth/cloud-platform .\nYou can set the scope for this method like this:  ml1 --scope  scope  projects models-get-iam-policy ...", 
            "title": "Scopes"
        }, 
        {
            "location": "/projects_models-get-iam-policy/#required-scalar-argument", 
            "text": "resource   (string)  REQUIRED: The resource for which the policy is being requested.\n    See the operation documentation for the appropriate value for this field.", 
            "title": "Required Scalar Argument"
        }, 
        {
            "location": "/projects_models-get-iam-policy/#optional-output-flags", 
            "text": "The method's return value a JSON encoded structure, which will be written to standard output by default.   -o out  out  specifies the  destination  to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The  destination  may be  -  to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.", 
            "title": "Optional Output Flags"
        }, 
        {
            "location": "/projects_models-get-iam-policy/#optional-general-properties", 
            "text": "The following properties can configure any call, and are not specific to this method.    -p $-xgafv=string   V1 error format.     -p access-token=string   OAuth access token.     -p alt=string   Data format for response.     -p callback=string   JSONP     -p fields=string   Selector specifying which fields to include in a partial response.     -p key=string   API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.     -p oauth-token=string   OAuth 2.0 token for the current user.     -p pretty-print=boolean   Returns response with indentations and line breaks.     -p quota-user=string   Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.     -p upload-type=string   Legacy upload protocol for media (e.g.  media ,  multipart ).     -p upload-protocol=string   Upload protocol for media (e.g.  raw ,  multipart ).", 
            "title": "Optional General Properties"
        }, 
        {
            "location": "/projects_models-list/", 
            "text": "Lists the models in a project.\n\n\nEach project can contain multiple models, and each model can have multiple\nversions.\n\n\nIf there are no models that match the request parameters, the list request\nreturns an empty response body: {}.\n\n\nScopes\n\n\nYou will need authorization for the \nhttps://www.googleapis.com/auth/cloud-platform\n scope to make a valid call.\n\n\nIf unset, the scope for this method defaults to \nhttps://www.googleapis.com/auth/cloud-platform\n.\nYou can set the scope for this method like this: \nml1 --scope \nscope\n projects models-list ...\n\n\nRequired Scalar Argument\n\n\n\n\nparent\n \n(string)\n\n\nRequired. The name of the project whose models are to be listed.\n\n\n\n\n\n\n\n\nOptional Output Flags\n\n\nThe method's return value a JSON encoded structure, which will be written to standard output by default.\n\n\n\n\n-o out\n\n\nout\n specifies the \ndestination\n to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The \ndestination\n may be \n-\n to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.\n\n\n\n\n\n\n\n\nOptional Method Properties\n\n\nYou may set the following properties to further configure the call. Please note that \n-p\n is followed by one \nor more key-value-pairs, and is called like this \n-p k1=v1 k2=v2\n even though the listing below repeats the\n\n-p\n for completeness.\n\n\n\n\n\n\n-p page-size=integer\n\n\n\n\n\n\nOptional. The number of models to retrieve per \npage\n of results. If there\n    are more remaining results than this number, the response message will\n    contain a valid value in the \nnext_page_token\n field.\n\n\nThe default value is 20, and the maximum page size is 100.\n\n\n\n\n\n\n\n\n\n\n-p filter=string\n\n\n\n\nOptional. Specifies the subset of models to retrieve.\n\n\n\n\n\n\n\n\n-p page-token=string\n\n\n\n\n\n\nOptional. A page token to request the next page of results.\n\n\nYou get the token from the \nnext_page_token\n field of the response from\nthe previous call.\n\n\n\n\n\n\n\n\n\n\nOptional General Properties\n\n\nThe following properties can configure any call, and are not specific to this method.\n\n\n\n\n\n\n-p $-xgafv=string\n\n\n\n\nV1 error format.\n\n\n\n\n\n\n\n\n-p access-token=string\n\n\n\n\nOAuth access token.\n\n\n\n\n\n\n\n\n-p alt=string\n\n\n\n\nData format for response.\n\n\n\n\n\n\n\n\n-p callback=string\n\n\n\n\nJSONP\n\n\n\n\n\n\n\n\n-p fields=string\n\n\n\n\nSelector specifying which fields to include in a partial response.\n\n\n\n\n\n\n\n\n-p key=string\n\n\n\n\nAPI key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.\n\n\n\n\n\n\n\n\n-p oauth-token=string\n\n\n\n\nOAuth 2.0 token for the current user.\n\n\n\n\n\n\n\n\n-p pretty-print=boolean\n\n\n\n\nReturns response with indentations and line breaks.\n\n\n\n\n\n\n\n\n-p quota-user=string\n\n\n\n\nAvailable to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.\n\n\n\n\n\n\n\n\n-p upload-type=string\n\n\n\n\nLegacy upload protocol for media (e.g. \nmedia\n, \nmultipart\n).\n\n\n\n\n\n\n\n\n-p upload-protocol=string\n\n\n\n\nUpload protocol for media (e.g. \nraw\n, \nmultipart\n).", 
            "title": "Models List"
        }, 
        {
            "location": "/projects_models-list/#scopes", 
            "text": "You will need authorization for the  https://www.googleapis.com/auth/cloud-platform  scope to make a valid call.  If unset, the scope for this method defaults to  https://www.googleapis.com/auth/cloud-platform .\nYou can set the scope for this method like this:  ml1 --scope  scope  projects models-list ...", 
            "title": "Scopes"
        }, 
        {
            "location": "/projects_models-list/#required-scalar-argument", 
            "text": "parent   (string)  Required. The name of the project whose models are to be listed.", 
            "title": "Required Scalar Argument"
        }, 
        {
            "location": "/projects_models-list/#optional-output-flags", 
            "text": "The method's return value a JSON encoded structure, which will be written to standard output by default.   -o out  out  specifies the  destination  to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The  destination  may be  -  to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.", 
            "title": "Optional Output Flags"
        }, 
        {
            "location": "/projects_models-list/#optional-method-properties", 
            "text": "You may set the following properties to further configure the call. Please note that  -p  is followed by one \nor more key-value-pairs, and is called like this  -p k1=v1 k2=v2  even though the listing below repeats the -p  for completeness.    -p page-size=integer    Optional. The number of models to retrieve per  page  of results. If there\n    are more remaining results than this number, the response message will\n    contain a valid value in the  next_page_token  field.  The default value is 20, and the maximum page size is 100.      -p filter=string   Optional. Specifies the subset of models to retrieve.     -p page-token=string    Optional. A page token to request the next page of results.  You get the token from the  next_page_token  field of the response from\nthe previous call.", 
            "title": "Optional Method Properties"
        }, 
        {
            "location": "/projects_models-list/#optional-general-properties", 
            "text": "The following properties can configure any call, and are not specific to this method.    -p $-xgafv=string   V1 error format.     -p access-token=string   OAuth access token.     -p alt=string   Data format for response.     -p callback=string   JSONP     -p fields=string   Selector specifying which fields to include in a partial response.     -p key=string   API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.     -p oauth-token=string   OAuth 2.0 token for the current user.     -p pretty-print=boolean   Returns response with indentations and line breaks.     -p quota-user=string   Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.     -p upload-type=string   Legacy upload protocol for media (e.g.  media ,  multipart ).     -p upload-protocol=string   Upload protocol for media (e.g.  raw ,  multipart ).", 
            "title": "Optional General Properties"
        }, 
        {
            "location": "/projects_models-patch/", 
            "text": "Updates a specific model resource.\n\n\nCurrently the only supported fields to update are \ndescription\n and\n\ndefault_version.name\n.\n\n\nScopes\n\n\nYou will need authorization for the \nhttps://www.googleapis.com/auth/cloud-platform\n scope to make a valid call.\n\n\nIf unset, the scope for this method defaults to \nhttps://www.googleapis.com/auth/cloud-platform\n.\nYou can set the scope for this method like this: \nml1 --scope \nscope\n projects models-patch ...\n\n\nRequired Scalar Argument\n\n\n\n\nname\n \n(string)\n\n\nRequired. The project name.\n\n\n\n\n\n\n\n\nRequired Request Value\n\n\nThe request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure.\nIn the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely.\n\n\nFor example, a structure like this:\n\n\nGoogleCloudMlV1__Model:\n  default-version:\n    auto-scaling:\n      min-nodes: integer\n    create-time: string\n    deployment-uri: string\n    description: string\n    error-message: string\n    etag: string\n    framework: string\n    is-default: boolean\n    labels: { string: string }\n    last-use-time: string\n    machine-type: string\n    manual-scaling:\n      nodes: integer\n    name: string\n    package-uris: [string]\n    prediction-class: string\n    python-version: string\n    runtime-version: string\n    service-account: string\n    state: string\n  description: string\n  etag: string\n  labels: { string: string }\n  name: string\n  online-prediction-console-logging: boolean\n  online-prediction-logging: boolean\n  regions: [string]\n\n\n\n\n\ncan be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time.\n\n\n\n\n\n\n-r .default-version.auto-scaling    min-nodes=50\n\n\n\n\n\n\nOptional. The minimum number of nodes to allocate for this model. These\n    nodes are always up, starting from the time the model is deployed.\n    Therefore, the cost of operating this model will be at least\n    \nrate\n * \nmin_nodes\n * number of hours since last billing cycle,\n    where \nrate\n is the cost per node-hour as documented in the\n    \npricing guide\n,\n    even if no predictions are performed. There is additional cost for each\n    prediction performed.\n\n\nUnlike manual scaling, if the load gets too heavy for the nodes\nthat are up, the service will automatically add nodes to handle the\nincreased load as well as scale back as traffic drops, always maintaining\nat least \nmin_nodes\n. You will be charged for the time in which additional\nnodes are used.\n\n\nIf not specified, \nmin_nodes\n defaults to 0, in which case, when traffic\nto a model stops (and after a cool-down period), nodes will be shut down\nand no charges will be incurred until traffic to the model resumes.\n\n\nYou can set \nmin_nodes\n when creating the model version, and you can also\nupdate \nmin_nodes\n for an existing version:\n\npre\n\nupdate_body.json:\n{\n  \nautoScaling\n: {\n    \nminNodes\n: 5\n  }\n}\n\n/pre\n\nHTTP request:\n\npre\n\nPATCH\nhttps://ml.googleapis.com/v1/{name=projects/\n/models/\n/versions/*}?update_mask=autoScaling.minNodes\n-d @./update_body.json\n\n/pre\n\n\n\n\n\n\n\n\n\n\n..    create-time=ipsum\n\n\n\n\nOutput only. The time the version was created.\n\n\n\n\n\n\n\n\ndeployment-uri=ut\n\n\n\n\n\n\nRequired. The Cloud Storage location of the trained model used to\n    create the version. See the\n    \nguide to model\n    deployment\n for more\n    information.\n\n\nWhen passing Version to\n\nprojects.models.versions.create\n\nthe model service uses the specified location as the source of the model.\nOnce deployed, the model version is hosted by the prediction service, so\nthis location is useful only as a historical record.\nThe total number of model files can\nt exceed 1000.\n* \ndescription=dolor\n\n    - Optional. The description specified for the version when it was created.\n* \nerror-message=sea\n\n    - Output only. The details of a failure or a cancellation.\n* \netag=ut\n\n    - \netag\n is used for optimistic concurrency control as a way to help\nprevent simultaneous updates of a model from overwriting each other.\nIt is strongly suggested that systems make use of the \netag\n in the\nread-modify-write cycle to perform model updates in order to avoid race\nconditions: An \netag\n is returned in the response to \nGetVersion\n, and\nsystems are expected to put that etag in the request to \nUpdateVersion\n to\nensure that their change will be applied to the model as intended.\n* \nframework=eirmod\n\n    - Optional. The machine learning framework AI Platform uses to train\nthis version of the model. Valid values are \nTENSORFLOW\n, \nSCIKIT_LEARN\n,\n\nXGBOOST\n. If you do not specify a framework, AI Platform\nwill analyze files in the deployment_uri to determine a framework. If you\nchoose \nSCIKIT_LEARN\n or \nXGBOOST\n, you must also set the runtime version\nof the model to 1.4 or greater.\n\n\nDo \nnot\n specify a framework if you\nre deploying a \ncustom\nprediction routine\n.\n* \nis-default=true\n\n    - Output only. If true, this version will be used to handle prediction\nrequests that do not specify a version.\n\n\nYou can change the default version by calling\n\nprojects.methods.versions.setDefault\n.\n* \nlabels=key=voluptua.\n\n    - Optional. One or more labels that you can add, to organize your model\nversions. Each label is a key-value pair, where both the key and the value\nare arbitrary strings that you supply.\nFor more information, see the documentation on\n\na href=\n/ml-engine/docs/tensorflow/resource-labels\nusing labels\n/a\n.\n    - the value will be associated with the given \nkey\n\n* \nlast-use-time=dolor\n\n    - Output only. The time the version was last used for prediction.\n* \nmachine-type=et\n\n    - Optional. The type of machine on which to serve the model. Currently only\napplies to online prediction service.\n\ndl\n\n  \ndt\nmls1-c1-m2\n/dt\n\n  \ndd\n\n  The \nb\ndefault\n/b\n machine type, with 1 core and 2 GB RAM. The deprecated\n  name for this machine type is \nmls1-highmem-1\n.\n  \n/dd\n\n  \ndt\nmls1-c4-m2\n/dt\n\n  \ndd\n\n  In \nb\nBeta\n/b\n. This machine type has 4 cores and 2 GB RAM. The\n  deprecated name for this machine type is \nmls1-highcpu-4\n.\n  \n/dd\n\n\n/dl\n\n* \nmanual-scaling    nodes=16\n\n    - The number of nodes to allocate for this model. These nodes are always up,\nstarting from the time the model is deployed, so the cost of operating\nthis model will be proportional to \nnodes\n * number of hours since\nlast billing cycle plus the cost for each prediction performed.\n\n\n\n\n\n\n\n\n\n\n..    name=vero\n\n\n\n\n\n\nRequired.The name specified for the version when it was created.\n\n\nThe version name must be unique within the model it is created in.\n* \npackage-uris=ut\n\n    - Optional. Cloud Storage paths (\ngs://\u2026\n) of packages for \ncustom\nprediction routines\n\nor \nscikit-learn pipelines with custom\ncode\n.\n\n\nFor a custom prediction routine, one of these packages must contain your\nPredictor class (see\n\npredictionClass\n). Additionally,\ninclude any dependencies used by your Predictor or scikit-learn pipeline\nuses that are not already included in your selected \nruntime\nversion\n.\n\n\nIf you specify this field, you must also set\n\nruntimeVersion\n to 1.4 or greater.\n    - Each invocation of this argument appends the given value to the array.\n* \nprediction-class=sed\n\n    - Optional. The fully qualified name\n(\nvar\nmodule_name\n/var\n.\nvar\nclass_name\n/var\n) of a class that implements\nthe Predictor interface described in this reference field. The module\ncontaining this class should be included in a package provided to the\n\npackageUris\n field\n.\n\n\nSpecify this field if and only if you are deploying a \ncustom prediction\nroutine (beta)\n.\nIf you specify this field, you must set\n\nruntimeVersion\n to 1.4 or greater.\n\n\nThe following code sample provides the Predictor interface:\n\n\n```py\nclass Predictor(object):\n\nInterface for constructing custom predictors.\n\n\ndef predict(self, instances, **kwargs):\n    \nPerforms custom prediction.\n\n\nInstances are the decoded values from the request. They have already\nbeen deserialized from JSON.\n\nArgs:\n    instances: A list of prediction input instances.\n    **kwargs: A dictionary of keyword args provided as additional\n        fields on the predict request body.\n\nReturns:\n    A list of outputs containing the prediction results. This list must\n    be JSON serializable.\n\n#34;\n#34;\n#34;\nraise NotImplementedError()\n\n\n\n@classmethod\ndef from_path(cls, model_dir):\n    \nCreates an instance of Predictor using the given path.\n\n\nLoading of the predictor should be done in this method.\n\nArgs:\n    model_dir: The local directory that contains the exported model\n        file along with any additional files uploaded when creating the\n        version resource.\n\nReturns:\n    An instance implementing this Predictor class.\n\n#34;\n#34;\n#34;\nraise NotImplementedError()\n\n\n\n```\n\n\nLearn more about \nthe Predictor interface and custom prediction\nroutines\n.\n* \npython-version=et\n\n    - Optional. The version of Python used in prediction. If not set, the default\nversion is \n2.7\n. Python \n3.5\n is available when \nruntime_version\n is set\nto \n1.4\n and above. Python \n2.7\n works with all supported runtime versions.\n* \nruntime-version=ipsum\n\n    - Optional. The AI Platform runtime version to use for this deployment.\nIf not set, AI Platform uses the default stable version, 1.0. For more\ninformation, see the\n\nruntime version list\n and\n\nhow to manage runtime versions\n.\n* \nservice-account=justo\n\n    - Optional. Specifies the service account for resource access control.\n* \nstate=dolore\n\n    - Output only. The state of a version.\n\n\n\n\n\n\n\n\n\n\n..    description=vero\n\n\n\n\nOptional. The description specified for the model when it was created.\n\n\n\n\n\n\netag=dolor\n\n\netag\n is used for optimistic concurrency control as a way to help\n    prevent simultaneous updates of a model from overwriting each other.\n    It is strongly suggested that systems make use of the \netag\n in the\n    read-modify-write cycle to perform model updates in order to avoid race\n    conditions: An \netag\n is returned in the response to \nGetModel\n, and\n    systems are expected to put that etag in the request to \nUpdateModel\n to\n    ensure that their change will be applied to the model as intended.\n\n\n\n\n\n\nlabels=key=takimata\n\n\nOptional. One or more labels that you can add, to organize your models.\n    Each label is a key-value pair, where both the key and the value are\n    arbitrary strings that you supply.\n    For more information, see the documentation on\n    \na href=\n/ml-engine/docs/tensorflow/resource-labels\nusing labels\n/a\n.\n\n\nthe value will be associated with the given \nkey\n\n\n\n\n\n\nname=et\n\n\n\n\nRequired. The name specified for the model when it was created.\n\n\nThe model name must be unique within the project it is created in.\n* \nonline-prediction-console-logging=false\n\n    - Optional. If true, online prediction nodes send \nstderr\n and \nstdout\n\nstreams to Stackdriver Logging. These can be more verbose than the standard\naccess logs (see \nonlinePredictionLogging\n) and can incur higher cost.\nHowever, they are helpful for debugging. Note that\n\nStackdriver logs may incur a cost\n, especially if\nyour project receives prediction requests at a high QPS. Estimate your\ncosts before enabling this option.\n\n\nDefault is false.\n* \nonline-prediction-logging=false\n\n    - Optional. If true, online prediction access logs are sent to StackDriver\nLogging. These logs are like standard server access logs, containing\ninformation like timestamp and latency for each request. Note that\n\nStackdriver logs may incur a cost\n, especially if\nyour project receives prediction requests at a high queries per second rate\n(QPS). Estimate your costs before enabling this option.\n\n\nDefault is false.\n* \nregions=sed\n\n    - Optional. The list of regions where the model is going to be deployed.\nCurrently only one region per model is supported.\nDefaults to \nus-central1\n if nothing is set.\nSee the \na href=\n/ml-engine/docs/tensorflow/regions\navailable regions\n/a\n\nfor AI Platform services.\nNote:\n*   No matter where a model is deployed, it can always be accessed by\n    users from anywhere, both for online and batch prediction.\n*   The region for a batch prediction job is set by the region field when\n    submitting the batch prediction job and does not take its value from\n    this field.\n    - Each invocation of this argument appends the given value to the array.\n\n\n\n\n\n\n\n\n\n\nAbout Cursors\n\n\nThe cursor position is key to comfortably set complex nested structures. The following rules apply:\n\n\n\n\nThe cursor position is always set relative to the current one, unless the field name starts with the \n.\n character. Fields can be nested such as in \n-r f.s.o\n .\n\n\nThe cursor position is set relative to the top-level structure if it starts with \n.\n, e.g. \n-r .s.s\n\n\nYou can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify \n-r struct.sub_struct=bar\n.\n\n\nYou can move the cursor one level up by using \n..\n. Each additional \n.\n moves it up one additional level. E.g. \n...\n would go three levels up.\n\n\n\n\nOptional Output Flags\n\n\nThe method's return value a JSON encoded structure, which will be written to standard output by default.\n\n\n\n\n-o out\n\n\nout\n specifies the \ndestination\n to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The \ndestination\n may be \n-\n to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.\n\n\n\n\n\n\n\n\nOptional Method Properties\n\n\nYou may set the following properties to further configure the call. Please note that \n-p\n is followed by one \nor more key-value-pairs, and is called like this \n-p k1=v1 k2=v2\n even though the listing below repeats the\n\n-p\n for completeness.\n\n\n\n\n-p update-mask=string\n\n\n\n\nRequired. Specifies the path, relative to \nModel\n, of the field to update.\n\n\nFor example, to change the description of a model to \nfoo\n and set its\ndefault version to \nversion_1\n, the \nupdate_mask\n parameter would be\nspecified as \ndescription\n, \ndefault_version.name\n, and the \nPATCH\n\nrequest body would specify the new value, as follows:\n    {\n      \ndescription\n: \nfoo\n,\n      \ndefaultVersion\n: {\n        \nname\n:\nversion_1\n\n      }\n    }\n\n\nCurrently the supported update masks are \ndescription\n and\n\ndefault_version.name\n.\n\n\n\n\n\n\n\n\n\n\nOptional General Properties\n\n\nThe following properties can configure any call, and are not specific to this method.\n\n\n\n\n\n\n-p $-xgafv=string\n\n\n\n\nV1 error format.\n\n\n\n\n\n\n\n\n-p access-token=string\n\n\n\n\nOAuth access token.\n\n\n\n\n\n\n\n\n-p alt=string\n\n\n\n\nData format for response.\n\n\n\n\n\n\n\n\n-p callback=string\n\n\n\n\nJSONP\n\n\n\n\n\n\n\n\n-p fields=string\n\n\n\n\nSelector specifying which fields to include in a partial response.\n\n\n\n\n\n\n\n\n-p key=string\n\n\n\n\nAPI key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.\n\n\n\n\n\n\n\n\n-p oauth-token=string\n\n\n\n\nOAuth 2.0 token for the current user.\n\n\n\n\n\n\n\n\n-p pretty-print=boolean\n\n\n\n\nReturns response with indentations and line breaks.\n\n\n\n\n\n\n\n\n-p quota-user=string\n\n\n\n\nAvailable to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.\n\n\n\n\n\n\n\n\n-p upload-type=string\n\n\n\n\nLegacy upload protocol for media (e.g. \nmedia\n, \nmultipart\n).\n\n\n\n\n\n\n\n\n-p upload-protocol=string\n\n\n\n\nUpload protocol for media (e.g. \nraw\n, \nmultipart\n).", 
            "title": "Models Patch"
        }, 
        {
            "location": "/projects_models-patch/#scopes", 
            "text": "You will need authorization for the  https://www.googleapis.com/auth/cloud-platform  scope to make a valid call.  If unset, the scope for this method defaults to  https://www.googleapis.com/auth/cloud-platform .\nYou can set the scope for this method like this:  ml1 --scope  scope  projects models-patch ...", 
            "title": "Scopes"
        }, 
        {
            "location": "/projects_models-patch/#required-scalar-argument", 
            "text": "name   (string)  Required. The project name.", 
            "title": "Required Scalar Argument"
        }, 
        {
            "location": "/projects_models-patch/#required-request-value", 
            "text": "The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure.\nIn the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely.  For example, a structure like this:  GoogleCloudMlV1__Model:\n  default-version:\n    auto-scaling:\n      min-nodes: integer\n    create-time: string\n    deployment-uri: string\n    description: string\n    error-message: string\n    etag: string\n    framework: string\n    is-default: boolean\n    labels: { string: string }\n    last-use-time: string\n    machine-type: string\n    manual-scaling:\n      nodes: integer\n    name: string\n    package-uris: [string]\n    prediction-class: string\n    python-version: string\n    runtime-version: string\n    service-account: string\n    state: string\n  description: string\n  etag: string\n  labels: { string: string }\n  name: string\n  online-prediction-console-logging: boolean\n  online-prediction-logging: boolean\n  regions: [string]  can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time.    -r .default-version.auto-scaling    min-nodes=50    Optional. The minimum number of nodes to allocate for this model. These\n    nodes are always up, starting from the time the model is deployed.\n    Therefore, the cost of operating this model will be at least\n     rate  *  min_nodes  * number of hours since last billing cycle,\n    where  rate  is the cost per node-hour as documented in the\n     pricing guide ,\n    even if no predictions are performed. There is additional cost for each\n    prediction performed.  Unlike manual scaling, if the load gets too heavy for the nodes\nthat are up, the service will automatically add nodes to handle the\nincreased load as well as scale back as traffic drops, always maintaining\nat least  min_nodes . You will be charged for the time in which additional\nnodes are used.  If not specified,  min_nodes  defaults to 0, in which case, when traffic\nto a model stops (and after a cool-down period), nodes will be shut down\nand no charges will be incurred until traffic to the model resumes.  You can set  min_nodes  when creating the model version, and you can also\nupdate  min_nodes  for an existing version: pre \nupdate_body.json:\n{\n   autoScaling : {\n     minNodes : 5\n  }\n} /pre \nHTTP request: pre \nPATCH\nhttps://ml.googleapis.com/v1/{name=projects/ /models/ /versions/*}?update_mask=autoScaling.minNodes\n-d @./update_body.json /pre      ..    create-time=ipsum   Output only. The time the version was created.     deployment-uri=ut    Required. The Cloud Storage location of the trained model used to\n    create the version. See the\n     guide to model\n    deployment  for more\n    information.  When passing Version to projects.models.versions.create \nthe model service uses the specified location as the source of the model.\nOnce deployed, the model version is hosted by the prediction service, so\nthis location is useful only as a historical record.\nThe total number of model files can t exceed 1000.\n*  description=dolor \n    - Optional. The description specified for the version when it was created.\n*  error-message=sea \n    - Output only. The details of a failure or a cancellation.\n*  etag=ut \n    -  etag  is used for optimistic concurrency control as a way to help\nprevent simultaneous updates of a model from overwriting each other.\nIt is strongly suggested that systems make use of the  etag  in the\nread-modify-write cycle to perform model updates in order to avoid race\nconditions: An  etag  is returned in the response to  GetVersion , and\nsystems are expected to put that etag in the request to  UpdateVersion  to\nensure that their change will be applied to the model as intended.\n*  framework=eirmod \n    - Optional. The machine learning framework AI Platform uses to train\nthis version of the model. Valid values are  TENSORFLOW ,  SCIKIT_LEARN , XGBOOST . If you do not specify a framework, AI Platform\nwill analyze files in the deployment_uri to determine a framework. If you\nchoose  SCIKIT_LEARN  or  XGBOOST , you must also set the runtime version\nof the model to 1.4 or greater.  Do  not  specify a framework if you re deploying a  custom\nprediction routine .\n*  is-default=true \n    - Output only. If true, this version will be used to handle prediction\nrequests that do not specify a version.  You can change the default version by calling projects.methods.versions.setDefault .\n*  labels=key=voluptua. \n    - Optional. One or more labels that you can add, to organize your model\nversions. Each label is a key-value pair, where both the key and the value\nare arbitrary strings that you supply.\nFor more information, see the documentation on a href= /ml-engine/docs/tensorflow/resource-labels using labels /a .\n    - the value will be associated with the given  key \n*  last-use-time=dolor \n    - Output only. The time the version was last used for prediction.\n*  machine-type=et \n    - Optional. The type of machine on which to serve the model. Currently only\napplies to online prediction service. dl \n   dt mls1-c1-m2 /dt \n   dd \n  The  b default /b  machine type, with 1 core and 2 GB RAM. The deprecated\n  name for this machine type is  mls1-highmem-1 .\n   /dd \n   dt mls1-c4-m2 /dt \n   dd \n  In  b Beta /b . This machine type has 4 cores and 2 GB RAM. The\n  deprecated name for this machine type is  mls1-highcpu-4 .\n   /dd  /dl \n*  manual-scaling    nodes=16 \n    - The number of nodes to allocate for this model. These nodes are always up,\nstarting from the time the model is deployed, so the cost of operating\nthis model will be proportional to  nodes  * number of hours since\nlast billing cycle plus the cost for each prediction performed.      ..    name=vero    Required.The name specified for the version when it was created.  The version name must be unique within the model it is created in.\n*  package-uris=ut \n    - Optional. Cloud Storage paths ( gs://\u2026 ) of packages for  custom\nprediction routines \nor  scikit-learn pipelines with custom\ncode .  For a custom prediction routine, one of these packages must contain your\nPredictor class (see predictionClass ). Additionally,\ninclude any dependencies used by your Predictor or scikit-learn pipeline\nuses that are not already included in your selected  runtime\nversion .  If you specify this field, you must also set runtimeVersion  to 1.4 or greater.\n    - Each invocation of this argument appends the given value to the array.\n*  prediction-class=sed \n    - Optional. The fully qualified name\n( var module_name /var . var class_name /var ) of a class that implements\nthe Predictor interface described in this reference field. The module\ncontaining this class should be included in a package provided to the packageUris  field .  Specify this field if and only if you are deploying a  custom prediction\nroutine (beta) .\nIf you specify this field, you must set runtimeVersion  to 1.4 or greater.  The following code sample provides the Predictor interface:  ```py\nclass Predictor(object): Interface for constructing custom predictors.  def predict(self, instances, **kwargs):\n     Performs custom prediction.  Instances are the decoded values from the request. They have already\nbeen deserialized from JSON.\n\nArgs:\n    instances: A list of prediction input instances.\n    **kwargs: A dictionary of keyword args provided as additional\n        fields on the predict request body.\n\nReturns:\n    A list of outputs containing the prediction results. This list must\n    be JSON serializable. #34; #34; #34;\nraise NotImplementedError()  @classmethod\ndef from_path(cls, model_dir):\n     Creates an instance of Predictor using the given path.  Loading of the predictor should be done in this method.\n\nArgs:\n    model_dir: The local directory that contains the exported model\n        file along with any additional files uploaded when creating the\n        version resource.\n\nReturns:\n    An instance implementing this Predictor class. #34; #34; #34;\nraise NotImplementedError()  ```  Learn more about  the Predictor interface and custom prediction\nroutines .\n*  python-version=et \n    - Optional. The version of Python used in prediction. If not set, the default\nversion is  2.7 . Python  3.5  is available when  runtime_version  is set\nto  1.4  and above. Python  2.7  works with all supported runtime versions.\n*  runtime-version=ipsum \n    - Optional. The AI Platform runtime version to use for this deployment.\nIf not set, AI Platform uses the default stable version, 1.0. For more\ninformation, see the runtime version list  and how to manage runtime versions .\n*  service-account=justo \n    - Optional. Specifies the service account for resource access control.\n*  state=dolore \n    - Output only. The state of a version.      ..    description=vero   Optional. The description specified for the model when it was created.    etag=dolor  etag  is used for optimistic concurrency control as a way to help\n    prevent simultaneous updates of a model from overwriting each other.\n    It is strongly suggested that systems make use of the  etag  in the\n    read-modify-write cycle to perform model updates in order to avoid race\n    conditions: An  etag  is returned in the response to  GetModel , and\n    systems are expected to put that etag in the request to  UpdateModel  to\n    ensure that their change will be applied to the model as intended.    labels=key=takimata  Optional. One or more labels that you can add, to organize your models.\n    Each label is a key-value pair, where both the key and the value are\n    arbitrary strings that you supply.\n    For more information, see the documentation on\n     a href= /ml-engine/docs/tensorflow/resource-labels using labels /a .  the value will be associated with the given  key    name=et   Required. The name specified for the model when it was created.  The model name must be unique within the project it is created in.\n*  online-prediction-console-logging=false \n    - Optional. If true, online prediction nodes send  stderr  and  stdout \nstreams to Stackdriver Logging. These can be more verbose than the standard\naccess logs (see  onlinePredictionLogging ) and can incur higher cost.\nHowever, they are helpful for debugging. Note that Stackdriver logs may incur a cost , especially if\nyour project receives prediction requests at a high QPS. Estimate your\ncosts before enabling this option.  Default is false.\n*  online-prediction-logging=false \n    - Optional. If true, online prediction access logs are sent to StackDriver\nLogging. These logs are like standard server access logs, containing\ninformation like timestamp and latency for each request. Note that Stackdriver logs may incur a cost , especially if\nyour project receives prediction requests at a high queries per second rate\n(QPS). Estimate your costs before enabling this option.  Default is false.\n*  regions=sed \n    - Optional. The list of regions where the model is going to be deployed.\nCurrently only one region per model is supported.\nDefaults to  us-central1  if nothing is set.\nSee the  a href= /ml-engine/docs/tensorflow/regions available regions /a \nfor AI Platform services.\nNote:\n*   No matter where a model is deployed, it can always be accessed by\n    users from anywhere, both for online and batch prediction.\n*   The region for a batch prediction job is set by the region field when\n    submitting the batch prediction job and does not take its value from\n    this field.\n    - Each invocation of this argument appends the given value to the array.", 
            "title": "Required Request Value"
        }, 
        {
            "location": "/projects_models-patch/#about-cursors", 
            "text": "The cursor position is key to comfortably set complex nested structures. The following rules apply:   The cursor position is always set relative to the current one, unless the field name starts with the  .  character. Fields can be nested such as in  -r f.s.o  .  The cursor position is set relative to the top-level structure if it starts with  . , e.g.  -r .s.s  You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify  -r struct.sub_struct=bar .  You can move the cursor one level up by using  .. . Each additional  .  moves it up one additional level. E.g.  ...  would go three levels up.", 
            "title": "About Cursors"
        }, 
        {
            "location": "/projects_models-patch/#optional-output-flags", 
            "text": "The method's return value a JSON encoded structure, which will be written to standard output by default.   -o out  out  specifies the  destination  to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The  destination  may be  -  to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.", 
            "title": "Optional Output Flags"
        }, 
        {
            "location": "/projects_models-patch/#optional-method-properties", 
            "text": "You may set the following properties to further configure the call. Please note that  -p  is followed by one \nor more key-value-pairs, and is called like this  -p k1=v1 k2=v2  even though the listing below repeats the -p  for completeness.   -p update-mask=string   Required. Specifies the path, relative to  Model , of the field to update.  For example, to change the description of a model to  foo  and set its\ndefault version to  version_1 , the  update_mask  parameter would be\nspecified as  description ,  default_version.name , and the  PATCH \nrequest body would specify the new value, as follows:\n    {\n       description :  foo ,\n       defaultVersion : {\n         name : version_1 \n      }\n    }  Currently the supported update masks are  description  and default_version.name .", 
            "title": "Optional Method Properties"
        }, 
        {
            "location": "/projects_models-patch/#optional-general-properties", 
            "text": "The following properties can configure any call, and are not specific to this method.    -p $-xgafv=string   V1 error format.     -p access-token=string   OAuth access token.     -p alt=string   Data format for response.     -p callback=string   JSONP     -p fields=string   Selector specifying which fields to include in a partial response.     -p key=string   API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.     -p oauth-token=string   OAuth 2.0 token for the current user.     -p pretty-print=boolean   Returns response with indentations and line breaks.     -p quota-user=string   Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.     -p upload-type=string   Legacy upload protocol for media (e.g.  media ,  multipart ).     -p upload-protocol=string   Upload protocol for media (e.g.  raw ,  multipart ).", 
            "title": "Optional General Properties"
        }, 
        {
            "location": "/projects_models-set-iam-policy/", 
            "text": "Sets the access control policy on the specified resource. Replaces any\nexisting policy.\n\n\nScopes\n\n\nYou will need authorization for the \nhttps://www.googleapis.com/auth/cloud-platform\n scope to make a valid call.\n\n\nIf unset, the scope for this method defaults to \nhttps://www.googleapis.com/auth/cloud-platform\n.\nYou can set the scope for this method like this: \nml1 --scope \nscope\n projects models-set-iam-policy ...\n\n\nRequired Scalar Argument\n\n\n\n\nresource\n \n(string)\n\n\nREQUIRED: The resource for which the policy is being specified.\n    See the operation documentation for the appropriate value for this field.\n\n\n\n\n\n\n\n\nRequired Request Value\n\n\nThe request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure.\nIn the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely.\n\n\nFor example, a structure like this:\n\n\nGoogleIamV1__SetIamPolicyRequest:\n  policy:\n    etag: string\n    version: integer\n  update-mask: string\n\n\n\n\n\ncan be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time.\n\n\n\n\n\n\n-r .policy    etag=no\n\n\n\n\n\n\netag\n is used for optimistic concurrency control as a way to help\n    prevent simultaneous updates of a policy from overwriting each other.\n    It is strongly suggested that systems make use of the \netag\n in the\n    read-modify-write cycle to perform policy updates in order to avoid race\n    conditions: An \netag\n is returned in the response to \ngetIamPolicy\n, and\n    systems are expected to put that etag in the request to \nsetIamPolicy\n to\n    ensure that their change will be applied to the same version of the policy.\n\n\nIf no \netag\n is provided in the call to \nsetIamPolicy\n, then the existing\npolicy is overwritten blindly.\n* \nversion=63\n\n    - Deprecated.\n\n\n\n\n\n\n\n\n\n\n..    update-mask=rebum.\n\n\n\n\nOPTIONAL: A FieldMask specifying which fields of the policy to modify. Only\n    the fields in the mask will be modified. If no mask is provided, the\n    following default mask is used:\n    paths: \nbindings, etag\n\n    This field is only used by Cloud IAM.\n\n\n\n\n\n\n\n\nAbout Cursors\n\n\nThe cursor position is key to comfortably set complex nested structures. The following rules apply:\n\n\n\n\nThe cursor position is always set relative to the current one, unless the field name starts with the \n.\n character. Fields can be nested such as in \n-r f.s.o\n .\n\n\nThe cursor position is set relative to the top-level structure if it starts with \n.\n, e.g. \n-r .s.s\n\n\nYou can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify \n-r struct.sub_struct=bar\n.\n\n\nYou can move the cursor one level up by using \n..\n. Each additional \n.\n moves it up one additional level. E.g. \n...\n would go three levels up.\n\n\n\n\nOptional Output Flags\n\n\nThe method's return value a JSON encoded structure, which will be written to standard output by default.\n\n\n\n\n-o out\n\n\nout\n specifies the \ndestination\n to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The \ndestination\n may be \n-\n to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.\n\n\n\n\n\n\n\n\nOptional General Properties\n\n\nThe following properties can configure any call, and are not specific to this method.\n\n\n\n\n\n\n-p $-xgafv=string\n\n\n\n\nV1 error format.\n\n\n\n\n\n\n\n\n-p access-token=string\n\n\n\n\nOAuth access token.\n\n\n\n\n\n\n\n\n-p alt=string\n\n\n\n\nData format for response.\n\n\n\n\n\n\n\n\n-p callback=string\n\n\n\n\nJSONP\n\n\n\n\n\n\n\n\n-p fields=string\n\n\n\n\nSelector specifying which fields to include in a partial response.\n\n\n\n\n\n\n\n\n-p key=string\n\n\n\n\nAPI key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.\n\n\n\n\n\n\n\n\n-p oauth-token=string\n\n\n\n\nOAuth 2.0 token for the current user.\n\n\n\n\n\n\n\n\n-p pretty-print=boolean\n\n\n\n\nReturns response with indentations and line breaks.\n\n\n\n\n\n\n\n\n-p quota-user=string\n\n\n\n\nAvailable to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.\n\n\n\n\n\n\n\n\n-p upload-type=string\n\n\n\n\nLegacy upload protocol for media (e.g. \nmedia\n, \nmultipart\n).\n\n\n\n\n\n\n\n\n-p upload-protocol=string\n\n\n\n\nUpload protocol for media (e.g. \nraw\n, \nmultipart\n).", 
            "title": "Models Set Iam Policy"
        }, 
        {
            "location": "/projects_models-set-iam-policy/#scopes", 
            "text": "You will need authorization for the  https://www.googleapis.com/auth/cloud-platform  scope to make a valid call.  If unset, the scope for this method defaults to  https://www.googleapis.com/auth/cloud-platform .\nYou can set the scope for this method like this:  ml1 --scope  scope  projects models-set-iam-policy ...", 
            "title": "Scopes"
        }, 
        {
            "location": "/projects_models-set-iam-policy/#required-scalar-argument", 
            "text": "resource   (string)  REQUIRED: The resource for which the policy is being specified.\n    See the operation documentation for the appropriate value for this field.", 
            "title": "Required Scalar Argument"
        }, 
        {
            "location": "/projects_models-set-iam-policy/#required-request-value", 
            "text": "The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure.\nIn the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely.  For example, a structure like this:  GoogleIamV1__SetIamPolicyRequest:\n  policy:\n    etag: string\n    version: integer\n  update-mask: string  can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time.    -r .policy    etag=no    etag  is used for optimistic concurrency control as a way to help\n    prevent simultaneous updates of a policy from overwriting each other.\n    It is strongly suggested that systems make use of the  etag  in the\n    read-modify-write cycle to perform policy updates in order to avoid race\n    conditions: An  etag  is returned in the response to  getIamPolicy , and\n    systems are expected to put that etag in the request to  setIamPolicy  to\n    ensure that their change will be applied to the same version of the policy.  If no  etag  is provided in the call to  setIamPolicy , then the existing\npolicy is overwritten blindly.\n*  version=63 \n    - Deprecated.      ..    update-mask=rebum.   OPTIONAL: A FieldMask specifying which fields of the policy to modify. Only\n    the fields in the mask will be modified. If no mask is provided, the\n    following default mask is used:\n    paths:  bindings, etag \n    This field is only used by Cloud IAM.", 
            "title": "Required Request Value"
        }, 
        {
            "location": "/projects_models-set-iam-policy/#about-cursors", 
            "text": "The cursor position is key to comfortably set complex nested structures. The following rules apply:   The cursor position is always set relative to the current one, unless the field name starts with the  .  character. Fields can be nested such as in  -r f.s.o  .  The cursor position is set relative to the top-level structure if it starts with  . , e.g.  -r .s.s  You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify  -r struct.sub_struct=bar .  You can move the cursor one level up by using  .. . Each additional  .  moves it up one additional level. E.g.  ...  would go three levels up.", 
            "title": "About Cursors"
        }, 
        {
            "location": "/projects_models-set-iam-policy/#optional-output-flags", 
            "text": "The method's return value a JSON encoded structure, which will be written to standard output by default.   -o out  out  specifies the  destination  to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The  destination  may be  -  to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.", 
            "title": "Optional Output Flags"
        }, 
        {
            "location": "/projects_models-set-iam-policy/#optional-general-properties", 
            "text": "The following properties can configure any call, and are not specific to this method.    -p $-xgafv=string   V1 error format.     -p access-token=string   OAuth access token.     -p alt=string   Data format for response.     -p callback=string   JSONP     -p fields=string   Selector specifying which fields to include in a partial response.     -p key=string   API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.     -p oauth-token=string   OAuth 2.0 token for the current user.     -p pretty-print=boolean   Returns response with indentations and line breaks.     -p quota-user=string   Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.     -p upload-type=string   Legacy upload protocol for media (e.g.  media ,  multipart ).     -p upload-protocol=string   Upload protocol for media (e.g.  raw ,  multipart ).", 
            "title": "Optional General Properties"
        }, 
        {
            "location": "/projects_models-test-iam-permissions/", 
            "text": "Returns permissions that a caller has on the specified resource.\nIf the resource does not exist, this will return an empty set of\npermissions, not a NOT_FOUND error.\n\n\nNote: This operation is designed to be used for building permission-aware\nUIs and command-line tools, not for authorization checking. This operation\nmay \nfail open\n without warning.\n\n\nScopes\n\n\nYou will need authorization for the \nhttps://www.googleapis.com/auth/cloud-platform\n scope to make a valid call.\n\n\nIf unset, the scope for this method defaults to \nhttps://www.googleapis.com/auth/cloud-platform\n.\nYou can set the scope for this method like this: \nml1 --scope \nscope\n projects models-test-iam-permissions ...\n\n\nRequired Scalar Argument\n\n\n\n\nresource\n \n(string)\n\n\nREQUIRED: The resource for which the policy detail is being requested.\n    See the operation documentation for the appropriate value for this field.\n\n\n\n\n\n\n\n\nRequired Request Value\n\n\nThe request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure.\nIn the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely.\n\n\nFor example, a structure like this:\n\n\nGoogleIamV1__TestIamPermissionsRequest:\n  permissions: [string]\n\n\n\n\n\ncan be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time.\n\n\n\n\n-r .    permissions=labore\n\n\nThe set of permissions to check for the \nresource\n. Permissions with\n    wildcards (such as \n or \nstorage.\n) are not allowed. For more\n    information see\n    \nIAM Overview\n.\n\n\nEach invocation of this argument appends the given value to the array.\n\n\n\n\n\n\n\n\nAbout Cursors\n\n\nThe cursor position is key to comfortably set complex nested structures. The following rules apply:\n\n\n\n\nThe cursor position is always set relative to the current one, unless the field name starts with the \n.\n character. Fields can be nested such as in \n-r f.s.o\n .\n\n\nThe cursor position is set relative to the top-level structure if it starts with \n.\n, e.g. \n-r .s.s\n\n\nYou can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify \n-r struct.sub_struct=bar\n.\n\n\nYou can move the cursor one level up by using \n..\n. Each additional \n.\n moves it up one additional level. E.g. \n...\n would go three levels up.\n\n\n\n\nOptional Output Flags\n\n\nThe method's return value a JSON encoded structure, which will be written to standard output by default.\n\n\n\n\n-o out\n\n\nout\n specifies the \ndestination\n to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The \ndestination\n may be \n-\n to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.\n\n\n\n\n\n\n\n\nOptional General Properties\n\n\nThe following properties can configure any call, and are not specific to this method.\n\n\n\n\n\n\n-p $-xgafv=string\n\n\n\n\nV1 error format.\n\n\n\n\n\n\n\n\n-p access-token=string\n\n\n\n\nOAuth access token.\n\n\n\n\n\n\n\n\n-p alt=string\n\n\n\n\nData format for response.\n\n\n\n\n\n\n\n\n-p callback=string\n\n\n\n\nJSONP\n\n\n\n\n\n\n\n\n-p fields=string\n\n\n\n\nSelector specifying which fields to include in a partial response.\n\n\n\n\n\n\n\n\n-p key=string\n\n\n\n\nAPI key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.\n\n\n\n\n\n\n\n\n-p oauth-token=string\n\n\n\n\nOAuth 2.0 token for the current user.\n\n\n\n\n\n\n\n\n-p pretty-print=boolean\n\n\n\n\nReturns response with indentations and line breaks.\n\n\n\n\n\n\n\n\n-p quota-user=string\n\n\n\n\nAvailable to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.\n\n\n\n\n\n\n\n\n-p upload-type=string\n\n\n\n\nLegacy upload protocol for media (e.g. \nmedia\n, \nmultipart\n).\n\n\n\n\n\n\n\n\n-p upload-protocol=string\n\n\n\n\nUpload protocol for media (e.g. \nraw\n, \nmultipart\n).", 
            "title": "Models Test Iam Permissions"
        }, 
        {
            "location": "/projects_models-test-iam-permissions/#scopes", 
            "text": "You will need authorization for the  https://www.googleapis.com/auth/cloud-platform  scope to make a valid call.  If unset, the scope for this method defaults to  https://www.googleapis.com/auth/cloud-platform .\nYou can set the scope for this method like this:  ml1 --scope  scope  projects models-test-iam-permissions ...", 
            "title": "Scopes"
        }, 
        {
            "location": "/projects_models-test-iam-permissions/#required-scalar-argument", 
            "text": "resource   (string)  REQUIRED: The resource for which the policy detail is being requested.\n    See the operation documentation for the appropriate value for this field.", 
            "title": "Required Scalar Argument"
        }, 
        {
            "location": "/projects_models-test-iam-permissions/#required-request-value", 
            "text": "The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure.\nIn the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely.  For example, a structure like this:  GoogleIamV1__TestIamPermissionsRequest:\n  permissions: [string]  can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time.   -r .    permissions=labore  The set of permissions to check for the  resource . Permissions with\n    wildcards (such as   or  storage. ) are not allowed. For more\n    information see\n     IAM Overview .  Each invocation of this argument appends the given value to the array.", 
            "title": "Required Request Value"
        }, 
        {
            "location": "/projects_models-test-iam-permissions/#about-cursors", 
            "text": "The cursor position is key to comfortably set complex nested structures. The following rules apply:   The cursor position is always set relative to the current one, unless the field name starts with the  .  character. Fields can be nested such as in  -r f.s.o  .  The cursor position is set relative to the top-level structure if it starts with  . , e.g.  -r .s.s  You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify  -r struct.sub_struct=bar .  You can move the cursor one level up by using  .. . Each additional  .  moves it up one additional level. E.g.  ...  would go three levels up.", 
            "title": "About Cursors"
        }, 
        {
            "location": "/projects_models-test-iam-permissions/#optional-output-flags", 
            "text": "The method's return value a JSON encoded structure, which will be written to standard output by default.   -o out  out  specifies the  destination  to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The  destination  may be  -  to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.", 
            "title": "Optional Output Flags"
        }, 
        {
            "location": "/projects_models-test-iam-permissions/#optional-general-properties", 
            "text": "The following properties can configure any call, and are not specific to this method.    -p $-xgafv=string   V1 error format.     -p access-token=string   OAuth access token.     -p alt=string   Data format for response.     -p callback=string   JSONP     -p fields=string   Selector specifying which fields to include in a partial response.     -p key=string   API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.     -p oauth-token=string   OAuth 2.0 token for the current user.     -p pretty-print=boolean   Returns response with indentations and line breaks.     -p quota-user=string   Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.     -p upload-type=string   Legacy upload protocol for media (e.g.  media ,  multipart ).     -p upload-protocol=string   Upload protocol for media (e.g.  raw ,  multipart ).", 
            "title": "Optional General Properties"
        }, 
        {
            "location": "/projects_models-versions-create/", 
            "text": "Creates a new version of a model from a trained TensorFlow model.\n\n\nIf the version created in the cloud by this call is the first deployed\nversion of the specified model, it will be made the default version of the\nmodel. When you add a version to a model that already has one or more\nversions, the default version does not automatically change. If you want a\nnew version to be the default, you must call\n\nprojects.models.versions.setDefault\n.\n\n\nScopes\n\n\nYou will need authorization for the \nhttps://www.googleapis.com/auth/cloud-platform\n scope to make a valid call.\n\n\nIf unset, the scope for this method defaults to \nhttps://www.googleapis.com/auth/cloud-platform\n.\nYou can set the scope for this method like this: \nml1 --scope \nscope\n projects models-versions-create ...\n\n\nRequired Scalar Argument\n\n\n\n\nparent\n \n(string)\n\n\nRequired. The name of the model.\n\n\n\n\n\n\n\n\nRequired Request Value\n\n\nThe request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure.\nIn the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely.\n\n\nFor example, a structure like this:\n\n\nGoogleCloudMlV1__Version:\n  auto-scaling:\n    min-nodes: integer\n  create-time: string\n  deployment-uri: string\n  description: string\n  error-message: string\n  etag: string\n  framework: string\n  is-default: boolean\n  labels: { string: string }\n  last-use-time: string\n  machine-type: string\n  manual-scaling:\n    nodes: integer\n  name: string\n  package-uris: [string]\n  prediction-class: string\n  python-version: string\n  runtime-version: string\n  service-account: string\n  state: string\n\n\n\n\n\ncan be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time.\n\n\n\n\n\n\n-r .auto-scaling    min-nodes=19\n\n\n\n\n\n\nOptional. The minimum number of nodes to allocate for this model. These\n    nodes are always up, starting from the time the model is deployed.\n    Therefore, the cost of operating this model will be at least\n    \nrate\n * \nmin_nodes\n * number of hours since last billing cycle,\n    where \nrate\n is the cost per node-hour as documented in the\n    \npricing guide\n,\n    even if no predictions are performed. There is additional cost for each\n    prediction performed.\n\n\nUnlike manual scaling, if the load gets too heavy for the nodes\nthat are up, the service will automatically add nodes to handle the\nincreased load as well as scale back as traffic drops, always maintaining\nat least \nmin_nodes\n. You will be charged for the time in which additional\nnodes are used.\n\n\nIf not specified, \nmin_nodes\n defaults to 0, in which case, when traffic\nto a model stops (and after a cool-down period), nodes will be shut down\nand no charges will be incurred until traffic to the model resumes.\n\n\nYou can set \nmin_nodes\n when creating the model version, and you can also\nupdate \nmin_nodes\n for an existing version:\n\npre\n\nupdate_body.json:\n{\n  \nautoScaling\n: {\n    \nminNodes\n: 5\n  }\n}\n\n/pre\n\nHTTP request:\n\npre\n\nPATCH\nhttps://ml.googleapis.com/v1/{name=projects/\n/models/\n/versions/*}?update_mask=autoScaling.minNodes\n-d @./update_body.json\n\n/pre\n\n\n\n\n\n\n\n\n\n\n..    create-time=elitr\n\n\n\n\nOutput only. The time the version was created.\n\n\n\n\n\n\n\n\ndeployment-uri=consetetur\n\n\n\n\n\n\nRequired. The Cloud Storage location of the trained model used to\n    create the version. See the\n    \nguide to model\n    deployment\n for more\n    information.\n\n\nWhen passing Version to\n\nprojects.models.versions.create\n\nthe model service uses the specified location as the source of the model.\nOnce deployed, the model version is hosted by the prediction service, so\nthis location is useful only as a historical record.\nThe total number of model files can\nt exceed 1000.\n* \ndescription=sea\n\n    - Optional. The description specified for the version when it was created.\n* \nerror-message=elitr\n\n    - Output only. The details of a failure or a cancellation.\n* \netag=at\n\n    - \netag\n is used for optimistic concurrency control as a way to help\nprevent simultaneous updates of a model from overwriting each other.\nIt is strongly suggested that systems make use of the \netag\n in the\nread-modify-write cycle to perform model updates in order to avoid race\nconditions: An \netag\n is returned in the response to \nGetVersion\n, and\nsystems are expected to put that etag in the request to \nUpdateVersion\n to\nensure that their change will be applied to the model as intended.\n* \nframework=sea\n\n    - Optional. The machine learning framework AI Platform uses to train\nthis version of the model. Valid values are \nTENSORFLOW\n, \nSCIKIT_LEARN\n,\n\nXGBOOST\n. If you do not specify a framework, AI Platform\nwill analyze files in the deployment_uri to determine a framework. If you\nchoose \nSCIKIT_LEARN\n or \nXGBOOST\n, you must also set the runtime version\nof the model to 1.4 or greater.\n\n\nDo \nnot\n specify a framework if you\nre deploying a \ncustom\nprediction routine\n.\n* \nis-default=false\n\n    - Output only. If true, this version will be used to handle prediction\nrequests that do not specify a version.\n\n\nYou can change the default version by calling\n\nprojects.methods.versions.setDefault\n.\n* \nlabels=key=diam\n\n    - Optional. One or more labels that you can add, to organize your model\nversions. Each label is a key-value pair, where both the key and the value\nare arbitrary strings that you supply.\nFor more information, see the documentation on\n\na href=\n/ml-engine/docs/tensorflow/resource-labels\nusing labels\n/a\n.\n    - the value will be associated with the given \nkey\n\n* \nlast-use-time=accusam\n\n    - Output only. The time the version was last used for prediction.\n* \nmachine-type=dolores\n\n    - Optional. The type of machine on which to serve the model. Currently only\napplies to online prediction service.\n\ndl\n\n  \ndt\nmls1-c1-m2\n/dt\n\n  \ndd\n\n  The \nb\ndefault\n/b\n machine type, with 1 core and 2 GB RAM. The deprecated\n  name for this machine type is \nmls1-highmem-1\n.\n  \n/dd\n\n  \ndt\nmls1-c4-m2\n/dt\n\n  \ndd\n\n  In \nb\nBeta\n/b\n. This machine type has 4 cores and 2 GB RAM. The\n  deprecated name for this machine type is \nmls1-highcpu-4\n.\n  \n/dd\n\n\n/dl\n\n* \nmanual-scaling    nodes=55\n\n    - The number of nodes to allocate for this model. These nodes are always up,\nstarting from the time the model is deployed, so the cost of operating\nthis model will be proportional to \nnodes\n * number of hours since\nlast billing cycle plus the cost for each prediction performed.\n\n\n\n\n\n\n\n\n\n\n..    name=dolor\n\n\n\n\n\n\nRequired.The name specified for the version when it was created.\n\n\nThe version name must be unique within the model it is created in.\n* \npackage-uris=aliquyam\n\n    - Optional. Cloud Storage paths (\ngs://\u2026\n) of packages for \ncustom\nprediction routines\n\nor \nscikit-learn pipelines with custom\ncode\n.\n\n\nFor a custom prediction routine, one of these packages must contain your\nPredictor class (see\n\npredictionClass\n). Additionally,\ninclude any dependencies used by your Predictor or scikit-learn pipeline\nuses that are not already included in your selected \nruntime\nversion\n.\n\n\nIf you specify this field, you must also set\n\nruntimeVersion\n to 1.4 or greater.\n    - Each invocation of this argument appends the given value to the array.\n* \nprediction-class=elitr\n\n    - Optional. The fully qualified name\n(\nvar\nmodule_name\n/var\n.\nvar\nclass_name\n/var\n) of a class that implements\nthe Predictor interface described in this reference field. The module\ncontaining this class should be included in a package provided to the\n\npackageUris\n field\n.\n\n\nSpecify this field if and only if you are deploying a \ncustom prediction\nroutine (beta)\n.\nIf you specify this field, you must set\n\nruntimeVersion\n to 1.4 or greater.\n\n\nThe following code sample provides the Predictor interface:\n\n\n```py\nclass Predictor(object):\n\nInterface for constructing custom predictors.\n\n\ndef predict(self, instances, **kwargs):\n    \nPerforms custom prediction.\n\n\nInstances are the decoded values from the request. They have already\nbeen deserialized from JSON.\n\nArgs:\n    instances: A list of prediction input instances.\n    **kwargs: A dictionary of keyword args provided as additional\n        fields on the predict request body.\n\nReturns:\n    A list of outputs containing the prediction results. This list must\n    be JSON serializable.\n\n#34;\n#34;\n#34;\nraise NotImplementedError()\n\n\n\n@classmethod\ndef from_path(cls, model_dir):\n    \nCreates an instance of Predictor using the given path.\n\n\nLoading of the predictor should be done in this method.\n\nArgs:\n    model_dir: The local directory that contains the exported model\n        file along with any additional files uploaded when creating the\n        version resource.\n\nReturns:\n    An instance implementing this Predictor class.\n\n#34;\n#34;\n#34;\nraise NotImplementedError()\n\n\n\n```\n\n\nLearn more about \nthe Predictor interface and custom prediction\nroutines\n.\n* \npython-version=ea\n\n    - Optional. The version of Python used in prediction. If not set, the default\nversion is \n2.7\n. Python \n3.5\n is available when \nruntime_version\n is set\nto \n1.4\n and above. Python \n2.7\n works with all supported runtime versions.\n* \nruntime-version=et\n\n    - Optional. The AI Platform runtime version to use for this deployment.\nIf not set, AI Platform uses the default stable version, 1.0. For more\ninformation, see the\n\nruntime version list\n and\n\nhow to manage runtime versions\n.\n* \nservice-account=stet\n\n    - Optional. Specifies the service account for resource access control.\n* \nstate=sed\n\n    - Output only. The state of a version.\n\n\n\n\n\n\n\n\n\n\nAbout Cursors\n\n\nThe cursor position is key to comfortably set complex nested structures. The following rules apply:\n\n\n\n\nThe cursor position is always set relative to the current one, unless the field name starts with the \n.\n character. Fields can be nested such as in \n-r f.s.o\n .\n\n\nThe cursor position is set relative to the top-level structure if it starts with \n.\n, e.g. \n-r .s.s\n\n\nYou can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify \n-r struct.sub_struct=bar\n.\n\n\nYou can move the cursor one level up by using \n..\n. Each additional \n.\n moves it up one additional level. E.g. \n...\n would go three levels up.\n\n\n\n\nOptional Output Flags\n\n\nThe method's return value a JSON encoded structure, which will be written to standard output by default.\n\n\n\n\n-o out\n\n\nout\n specifies the \ndestination\n to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The \ndestination\n may be \n-\n to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.\n\n\n\n\n\n\n\n\nOptional General Properties\n\n\nThe following properties can configure any call, and are not specific to this method.\n\n\n\n\n\n\n-p $-xgafv=string\n\n\n\n\nV1 error format.\n\n\n\n\n\n\n\n\n-p access-token=string\n\n\n\n\nOAuth access token.\n\n\n\n\n\n\n\n\n-p alt=string\n\n\n\n\nData format for response.\n\n\n\n\n\n\n\n\n-p callback=string\n\n\n\n\nJSONP\n\n\n\n\n\n\n\n\n-p fields=string\n\n\n\n\nSelector specifying which fields to include in a partial response.\n\n\n\n\n\n\n\n\n-p key=string\n\n\n\n\nAPI key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.\n\n\n\n\n\n\n\n\n-p oauth-token=string\n\n\n\n\nOAuth 2.0 token for the current user.\n\n\n\n\n\n\n\n\n-p pretty-print=boolean\n\n\n\n\nReturns response with indentations and line breaks.\n\n\n\n\n\n\n\n\n-p quota-user=string\n\n\n\n\nAvailable to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.\n\n\n\n\n\n\n\n\n-p upload-type=string\n\n\n\n\nLegacy upload protocol for media (e.g. \nmedia\n, \nmultipart\n).\n\n\n\n\n\n\n\n\n-p upload-protocol=string\n\n\n\n\nUpload protocol for media (e.g. \nraw\n, \nmultipart\n).", 
            "title": "Models Versions Create"
        }, 
        {
            "location": "/projects_models-versions-create/#scopes", 
            "text": "You will need authorization for the  https://www.googleapis.com/auth/cloud-platform  scope to make a valid call.  If unset, the scope for this method defaults to  https://www.googleapis.com/auth/cloud-platform .\nYou can set the scope for this method like this:  ml1 --scope  scope  projects models-versions-create ...", 
            "title": "Scopes"
        }, 
        {
            "location": "/projects_models-versions-create/#required-scalar-argument", 
            "text": "parent   (string)  Required. The name of the model.", 
            "title": "Required Scalar Argument"
        }, 
        {
            "location": "/projects_models-versions-create/#required-request-value", 
            "text": "The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure.\nIn the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely.  For example, a structure like this:  GoogleCloudMlV1__Version:\n  auto-scaling:\n    min-nodes: integer\n  create-time: string\n  deployment-uri: string\n  description: string\n  error-message: string\n  etag: string\n  framework: string\n  is-default: boolean\n  labels: { string: string }\n  last-use-time: string\n  machine-type: string\n  manual-scaling:\n    nodes: integer\n  name: string\n  package-uris: [string]\n  prediction-class: string\n  python-version: string\n  runtime-version: string\n  service-account: string\n  state: string  can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time.    -r .auto-scaling    min-nodes=19    Optional. The minimum number of nodes to allocate for this model. These\n    nodes are always up, starting from the time the model is deployed.\n    Therefore, the cost of operating this model will be at least\n     rate  *  min_nodes  * number of hours since last billing cycle,\n    where  rate  is the cost per node-hour as documented in the\n     pricing guide ,\n    even if no predictions are performed. There is additional cost for each\n    prediction performed.  Unlike manual scaling, if the load gets too heavy for the nodes\nthat are up, the service will automatically add nodes to handle the\nincreased load as well as scale back as traffic drops, always maintaining\nat least  min_nodes . You will be charged for the time in which additional\nnodes are used.  If not specified,  min_nodes  defaults to 0, in which case, when traffic\nto a model stops (and after a cool-down period), nodes will be shut down\nand no charges will be incurred until traffic to the model resumes.  You can set  min_nodes  when creating the model version, and you can also\nupdate  min_nodes  for an existing version: pre \nupdate_body.json:\n{\n   autoScaling : {\n     minNodes : 5\n  }\n} /pre \nHTTP request: pre \nPATCH\nhttps://ml.googleapis.com/v1/{name=projects/ /models/ /versions/*}?update_mask=autoScaling.minNodes\n-d @./update_body.json /pre      ..    create-time=elitr   Output only. The time the version was created.     deployment-uri=consetetur    Required. The Cloud Storage location of the trained model used to\n    create the version. See the\n     guide to model\n    deployment  for more\n    information.  When passing Version to projects.models.versions.create \nthe model service uses the specified location as the source of the model.\nOnce deployed, the model version is hosted by the prediction service, so\nthis location is useful only as a historical record.\nThe total number of model files can t exceed 1000.\n*  description=sea \n    - Optional. The description specified for the version when it was created.\n*  error-message=elitr \n    - Output only. The details of a failure or a cancellation.\n*  etag=at \n    -  etag  is used for optimistic concurrency control as a way to help\nprevent simultaneous updates of a model from overwriting each other.\nIt is strongly suggested that systems make use of the  etag  in the\nread-modify-write cycle to perform model updates in order to avoid race\nconditions: An  etag  is returned in the response to  GetVersion , and\nsystems are expected to put that etag in the request to  UpdateVersion  to\nensure that their change will be applied to the model as intended.\n*  framework=sea \n    - Optional. The machine learning framework AI Platform uses to train\nthis version of the model. Valid values are  TENSORFLOW ,  SCIKIT_LEARN , XGBOOST . If you do not specify a framework, AI Platform\nwill analyze files in the deployment_uri to determine a framework. If you\nchoose  SCIKIT_LEARN  or  XGBOOST , you must also set the runtime version\nof the model to 1.4 or greater.  Do  not  specify a framework if you re deploying a  custom\nprediction routine .\n*  is-default=false \n    - Output only. If true, this version will be used to handle prediction\nrequests that do not specify a version.  You can change the default version by calling projects.methods.versions.setDefault .\n*  labels=key=diam \n    - Optional. One or more labels that you can add, to organize your model\nversions. Each label is a key-value pair, where both the key and the value\nare arbitrary strings that you supply.\nFor more information, see the documentation on a href= /ml-engine/docs/tensorflow/resource-labels using labels /a .\n    - the value will be associated with the given  key \n*  last-use-time=accusam \n    - Output only. The time the version was last used for prediction.\n*  machine-type=dolores \n    - Optional. The type of machine on which to serve the model. Currently only\napplies to online prediction service. dl \n   dt mls1-c1-m2 /dt \n   dd \n  The  b default /b  machine type, with 1 core and 2 GB RAM. The deprecated\n  name for this machine type is  mls1-highmem-1 .\n   /dd \n   dt mls1-c4-m2 /dt \n   dd \n  In  b Beta /b . This machine type has 4 cores and 2 GB RAM. The\n  deprecated name for this machine type is  mls1-highcpu-4 .\n   /dd  /dl \n*  manual-scaling    nodes=55 \n    - The number of nodes to allocate for this model. These nodes are always up,\nstarting from the time the model is deployed, so the cost of operating\nthis model will be proportional to  nodes  * number of hours since\nlast billing cycle plus the cost for each prediction performed.      ..    name=dolor    Required.The name specified for the version when it was created.  The version name must be unique within the model it is created in.\n*  package-uris=aliquyam \n    - Optional. Cloud Storage paths ( gs://\u2026 ) of packages for  custom\nprediction routines \nor  scikit-learn pipelines with custom\ncode .  For a custom prediction routine, one of these packages must contain your\nPredictor class (see predictionClass ). Additionally,\ninclude any dependencies used by your Predictor or scikit-learn pipeline\nuses that are not already included in your selected  runtime\nversion .  If you specify this field, you must also set runtimeVersion  to 1.4 or greater.\n    - Each invocation of this argument appends the given value to the array.\n*  prediction-class=elitr \n    - Optional. The fully qualified name\n( var module_name /var . var class_name /var ) of a class that implements\nthe Predictor interface described in this reference field. The module\ncontaining this class should be included in a package provided to the packageUris  field .  Specify this field if and only if you are deploying a  custom prediction\nroutine (beta) .\nIf you specify this field, you must set runtimeVersion  to 1.4 or greater.  The following code sample provides the Predictor interface:  ```py\nclass Predictor(object): Interface for constructing custom predictors.  def predict(self, instances, **kwargs):\n     Performs custom prediction.  Instances are the decoded values from the request. They have already\nbeen deserialized from JSON.\n\nArgs:\n    instances: A list of prediction input instances.\n    **kwargs: A dictionary of keyword args provided as additional\n        fields on the predict request body.\n\nReturns:\n    A list of outputs containing the prediction results. This list must\n    be JSON serializable. #34; #34; #34;\nraise NotImplementedError()  @classmethod\ndef from_path(cls, model_dir):\n     Creates an instance of Predictor using the given path.  Loading of the predictor should be done in this method.\n\nArgs:\n    model_dir: The local directory that contains the exported model\n        file along with any additional files uploaded when creating the\n        version resource.\n\nReturns:\n    An instance implementing this Predictor class. #34; #34; #34;\nraise NotImplementedError()  ```  Learn more about  the Predictor interface and custom prediction\nroutines .\n*  python-version=ea \n    - Optional. The version of Python used in prediction. If not set, the default\nversion is  2.7 . Python  3.5  is available when  runtime_version  is set\nto  1.4  and above. Python  2.7  works with all supported runtime versions.\n*  runtime-version=et \n    - Optional. The AI Platform runtime version to use for this deployment.\nIf not set, AI Platform uses the default stable version, 1.0. For more\ninformation, see the runtime version list  and how to manage runtime versions .\n*  service-account=stet \n    - Optional. Specifies the service account for resource access control.\n*  state=sed \n    - Output only. The state of a version.", 
            "title": "Required Request Value"
        }, 
        {
            "location": "/projects_models-versions-create/#about-cursors", 
            "text": "The cursor position is key to comfortably set complex nested structures. The following rules apply:   The cursor position is always set relative to the current one, unless the field name starts with the  .  character. Fields can be nested such as in  -r f.s.o  .  The cursor position is set relative to the top-level structure if it starts with  . , e.g.  -r .s.s  You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify  -r struct.sub_struct=bar .  You can move the cursor one level up by using  .. . Each additional  .  moves it up one additional level. E.g.  ...  would go three levels up.", 
            "title": "About Cursors"
        }, 
        {
            "location": "/projects_models-versions-create/#optional-output-flags", 
            "text": "The method's return value a JSON encoded structure, which will be written to standard output by default.   -o out  out  specifies the  destination  to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The  destination  may be  -  to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.", 
            "title": "Optional Output Flags"
        }, 
        {
            "location": "/projects_models-versions-create/#optional-general-properties", 
            "text": "The following properties can configure any call, and are not specific to this method.    -p $-xgafv=string   V1 error format.     -p access-token=string   OAuth access token.     -p alt=string   Data format for response.     -p callback=string   JSONP     -p fields=string   Selector specifying which fields to include in a partial response.     -p key=string   API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.     -p oauth-token=string   OAuth 2.0 token for the current user.     -p pretty-print=boolean   Returns response with indentations and line breaks.     -p quota-user=string   Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.     -p upload-type=string   Legacy upload protocol for media (e.g.  media ,  multipart ).     -p upload-protocol=string   Upload protocol for media (e.g.  raw ,  multipart ).", 
            "title": "Optional General Properties"
        }, 
        {
            "location": "/projects_models-versions-delete/", 
            "text": "Deletes a model version.\n\n\nEach model can have multiple versions deployed and in use at any given\ntime. Use this method to remove a single version.\n\n\nNote: You cannot delete the version that is set as the default version\nof the model unless it is the only remaining version.\n\n\nScopes\n\n\nYou will need authorization for the \nhttps://www.googleapis.com/auth/cloud-platform\n scope to make a valid call.\n\n\nIf unset, the scope for this method defaults to \nhttps://www.googleapis.com/auth/cloud-platform\n.\nYou can set the scope for this method like this: \nml1 --scope \nscope\n projects models-versions-delete ...\n\n\nRequired Scalar Argument\n\n\n\n\nname\n \n(string)\n\n\nRequired. The name of the version. You can get the names of all the\n    versions of a model by calling\n    \nprojects.models.versions.list\n.\n\n\n\n\n\n\n\n\nOptional Output Flags\n\n\nThe method's return value a JSON encoded structure, which will be written to standard output by default.\n\n\n\n\n-o out\n\n\nout\n specifies the \ndestination\n to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The \ndestination\n may be \n-\n to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.\n\n\n\n\n\n\n\n\nOptional General Properties\n\n\nThe following properties can configure any call, and are not specific to this method.\n\n\n\n\n\n\n-p $-xgafv=string\n\n\n\n\nV1 error format.\n\n\n\n\n\n\n\n\n-p access-token=string\n\n\n\n\nOAuth access token.\n\n\n\n\n\n\n\n\n-p alt=string\n\n\n\n\nData format for response.\n\n\n\n\n\n\n\n\n-p callback=string\n\n\n\n\nJSONP\n\n\n\n\n\n\n\n\n-p fields=string\n\n\n\n\nSelector specifying which fields to include in a partial response.\n\n\n\n\n\n\n\n\n-p key=string\n\n\n\n\nAPI key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.\n\n\n\n\n\n\n\n\n-p oauth-token=string\n\n\n\n\nOAuth 2.0 token for the current user.\n\n\n\n\n\n\n\n\n-p pretty-print=boolean\n\n\n\n\nReturns response with indentations and line breaks.\n\n\n\n\n\n\n\n\n-p quota-user=string\n\n\n\n\nAvailable to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.\n\n\n\n\n\n\n\n\n-p upload-type=string\n\n\n\n\nLegacy upload protocol for media (e.g. \nmedia\n, \nmultipart\n).\n\n\n\n\n\n\n\n\n-p upload-protocol=string\n\n\n\n\nUpload protocol for media (e.g. \nraw\n, \nmultipart\n).", 
            "title": "Models Versions Delete"
        }, 
        {
            "location": "/projects_models-versions-delete/#scopes", 
            "text": "You will need authorization for the  https://www.googleapis.com/auth/cloud-platform  scope to make a valid call.  If unset, the scope for this method defaults to  https://www.googleapis.com/auth/cloud-platform .\nYou can set the scope for this method like this:  ml1 --scope  scope  projects models-versions-delete ...", 
            "title": "Scopes"
        }, 
        {
            "location": "/projects_models-versions-delete/#required-scalar-argument", 
            "text": "name   (string)  Required. The name of the version. You can get the names of all the\n    versions of a model by calling\n     projects.models.versions.list .", 
            "title": "Required Scalar Argument"
        }, 
        {
            "location": "/projects_models-versions-delete/#optional-output-flags", 
            "text": "The method's return value a JSON encoded structure, which will be written to standard output by default.   -o out  out  specifies the  destination  to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The  destination  may be  -  to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.", 
            "title": "Optional Output Flags"
        }, 
        {
            "location": "/projects_models-versions-delete/#optional-general-properties", 
            "text": "The following properties can configure any call, and are not specific to this method.    -p $-xgafv=string   V1 error format.     -p access-token=string   OAuth access token.     -p alt=string   Data format for response.     -p callback=string   JSONP     -p fields=string   Selector specifying which fields to include in a partial response.     -p key=string   API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.     -p oauth-token=string   OAuth 2.0 token for the current user.     -p pretty-print=boolean   Returns response with indentations and line breaks.     -p quota-user=string   Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.     -p upload-type=string   Legacy upload protocol for media (e.g.  media ,  multipart ).     -p upload-protocol=string   Upload protocol for media (e.g.  raw ,  multipart ).", 
            "title": "Optional General Properties"
        }, 
        {
            "location": "/projects_models-versions-get/", 
            "text": "Gets information about a model version.\n\n\nModels can have multiple versions. You can call\n\nprojects.models.versions.list\n\nto get the same information that this method returns for all of the\nversions of a model.\n\n\nScopes\n\n\nYou will need authorization for the \nhttps://www.googleapis.com/auth/cloud-platform\n scope to make a valid call.\n\n\nIf unset, the scope for this method defaults to \nhttps://www.googleapis.com/auth/cloud-platform\n.\nYou can set the scope for this method like this: \nml1 --scope \nscope\n projects models-versions-get ...\n\n\nRequired Scalar Argument\n\n\n\n\nname\n \n(string)\n\n\nRequired. The name of the version.\n\n\n\n\n\n\n\n\nOptional Output Flags\n\n\nThe method's return value a JSON encoded structure, which will be written to standard output by default.\n\n\n\n\n-o out\n\n\nout\n specifies the \ndestination\n to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The \ndestination\n may be \n-\n to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.\n\n\n\n\n\n\n\n\nOptional General Properties\n\n\nThe following properties can configure any call, and are not specific to this method.\n\n\n\n\n\n\n-p $-xgafv=string\n\n\n\n\nV1 error format.\n\n\n\n\n\n\n\n\n-p access-token=string\n\n\n\n\nOAuth access token.\n\n\n\n\n\n\n\n\n-p alt=string\n\n\n\n\nData format for response.\n\n\n\n\n\n\n\n\n-p callback=string\n\n\n\n\nJSONP\n\n\n\n\n\n\n\n\n-p fields=string\n\n\n\n\nSelector specifying which fields to include in a partial response.\n\n\n\n\n\n\n\n\n-p key=string\n\n\n\n\nAPI key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.\n\n\n\n\n\n\n\n\n-p oauth-token=string\n\n\n\n\nOAuth 2.0 token for the current user.\n\n\n\n\n\n\n\n\n-p pretty-print=boolean\n\n\n\n\nReturns response with indentations and line breaks.\n\n\n\n\n\n\n\n\n-p quota-user=string\n\n\n\n\nAvailable to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.\n\n\n\n\n\n\n\n\n-p upload-type=string\n\n\n\n\nLegacy upload protocol for media (e.g. \nmedia\n, \nmultipart\n).\n\n\n\n\n\n\n\n\n-p upload-protocol=string\n\n\n\n\nUpload protocol for media (e.g. \nraw\n, \nmultipart\n).", 
            "title": "Models Versions Get"
        }, 
        {
            "location": "/projects_models-versions-get/#scopes", 
            "text": "You will need authorization for the  https://www.googleapis.com/auth/cloud-platform  scope to make a valid call.  If unset, the scope for this method defaults to  https://www.googleapis.com/auth/cloud-platform .\nYou can set the scope for this method like this:  ml1 --scope  scope  projects models-versions-get ...", 
            "title": "Scopes"
        }, 
        {
            "location": "/projects_models-versions-get/#required-scalar-argument", 
            "text": "name   (string)  Required. The name of the version.", 
            "title": "Required Scalar Argument"
        }, 
        {
            "location": "/projects_models-versions-get/#optional-output-flags", 
            "text": "The method's return value a JSON encoded structure, which will be written to standard output by default.   -o out  out  specifies the  destination  to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The  destination  may be  -  to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.", 
            "title": "Optional Output Flags"
        }, 
        {
            "location": "/projects_models-versions-get/#optional-general-properties", 
            "text": "The following properties can configure any call, and are not specific to this method.    -p $-xgafv=string   V1 error format.     -p access-token=string   OAuth access token.     -p alt=string   Data format for response.     -p callback=string   JSONP     -p fields=string   Selector specifying which fields to include in a partial response.     -p key=string   API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.     -p oauth-token=string   OAuth 2.0 token for the current user.     -p pretty-print=boolean   Returns response with indentations and line breaks.     -p quota-user=string   Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.     -p upload-type=string   Legacy upload protocol for media (e.g.  media ,  multipart ).     -p upload-protocol=string   Upload protocol for media (e.g.  raw ,  multipart ).", 
            "title": "Optional General Properties"
        }, 
        {
            "location": "/projects_models-versions-list/", 
            "text": "Gets basic information about all the versions of a model.\n\n\nIf you expect that a model has many versions, or if you need to handle\nonly a limited number of results at a time, you can request that the list\nbe retrieved in batches (called pages).\n\n\nIf there are no versions that match the request parameters, the list\nrequest returns an empty response body: {}.\n\n\nScopes\n\n\nYou will need authorization for the \nhttps://www.googleapis.com/auth/cloud-platform\n scope to make a valid call.\n\n\nIf unset, the scope for this method defaults to \nhttps://www.googleapis.com/auth/cloud-platform\n.\nYou can set the scope for this method like this: \nml1 --scope \nscope\n projects models-versions-list ...\n\n\nRequired Scalar Argument\n\n\n\n\nparent\n \n(string)\n\n\nRequired. The name of the model for which to list the version.\n\n\n\n\n\n\n\n\nOptional Output Flags\n\n\nThe method's return value a JSON encoded structure, which will be written to standard output by default.\n\n\n\n\n-o out\n\n\nout\n specifies the \ndestination\n to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The \ndestination\n may be \n-\n to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.\n\n\n\n\n\n\n\n\nOptional Method Properties\n\n\nYou may set the following properties to further configure the call. Please note that \n-p\n is followed by one \nor more key-value-pairs, and is called like this \n-p k1=v1 k2=v2\n even though the listing below repeats the\n\n-p\n for completeness.\n\n\n\n\n\n\n-p page-size=integer\n\n\n\n\n\n\nOptional. The number of versions to retrieve per \npage\n of results. If\n    there are more remaining results than this number, the response message\n    will contain a valid value in the \nnext_page_token\n field.\n\n\nThe default value is 20, and the maximum page size is 100.\n\n\n\n\n\n\n\n\n\n\n-p filter=string\n\n\n\n\nOptional. Specifies the subset of versions to retrieve.\n\n\n\n\n\n\n\n\n-p page-token=string\n\n\n\n\n\n\nOptional. A page token to request the next page of results.\n\n\nYou get the token from the \nnext_page_token\n field of the response from\nthe previous call.\n\n\n\n\n\n\n\n\n\n\nOptional General Properties\n\n\nThe following properties can configure any call, and are not specific to this method.\n\n\n\n\n\n\n-p $-xgafv=string\n\n\n\n\nV1 error format.\n\n\n\n\n\n\n\n\n-p access-token=string\n\n\n\n\nOAuth access token.\n\n\n\n\n\n\n\n\n-p alt=string\n\n\n\n\nData format for response.\n\n\n\n\n\n\n\n\n-p callback=string\n\n\n\n\nJSONP\n\n\n\n\n\n\n\n\n-p fields=string\n\n\n\n\nSelector specifying which fields to include in a partial response.\n\n\n\n\n\n\n\n\n-p key=string\n\n\n\n\nAPI key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.\n\n\n\n\n\n\n\n\n-p oauth-token=string\n\n\n\n\nOAuth 2.0 token for the current user.\n\n\n\n\n\n\n\n\n-p pretty-print=boolean\n\n\n\n\nReturns response with indentations and line breaks.\n\n\n\n\n\n\n\n\n-p quota-user=string\n\n\n\n\nAvailable to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.\n\n\n\n\n\n\n\n\n-p upload-type=string\n\n\n\n\nLegacy upload protocol for media (e.g. \nmedia\n, \nmultipart\n).\n\n\n\n\n\n\n\n\n-p upload-protocol=string\n\n\n\n\nUpload protocol for media (e.g. \nraw\n, \nmultipart\n).", 
            "title": "Models Versions List"
        }, 
        {
            "location": "/projects_models-versions-list/#scopes", 
            "text": "You will need authorization for the  https://www.googleapis.com/auth/cloud-platform  scope to make a valid call.  If unset, the scope for this method defaults to  https://www.googleapis.com/auth/cloud-platform .\nYou can set the scope for this method like this:  ml1 --scope  scope  projects models-versions-list ...", 
            "title": "Scopes"
        }, 
        {
            "location": "/projects_models-versions-list/#required-scalar-argument", 
            "text": "parent   (string)  Required. The name of the model for which to list the version.", 
            "title": "Required Scalar Argument"
        }, 
        {
            "location": "/projects_models-versions-list/#optional-output-flags", 
            "text": "The method's return value a JSON encoded structure, which will be written to standard output by default.   -o out  out  specifies the  destination  to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The  destination  may be  -  to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.", 
            "title": "Optional Output Flags"
        }, 
        {
            "location": "/projects_models-versions-list/#optional-method-properties", 
            "text": "You may set the following properties to further configure the call. Please note that  -p  is followed by one \nor more key-value-pairs, and is called like this  -p k1=v1 k2=v2  even though the listing below repeats the -p  for completeness.    -p page-size=integer    Optional. The number of versions to retrieve per  page  of results. If\n    there are more remaining results than this number, the response message\n    will contain a valid value in the  next_page_token  field.  The default value is 20, and the maximum page size is 100.      -p filter=string   Optional. Specifies the subset of versions to retrieve.     -p page-token=string    Optional. A page token to request the next page of results.  You get the token from the  next_page_token  field of the response from\nthe previous call.", 
            "title": "Optional Method Properties"
        }, 
        {
            "location": "/projects_models-versions-list/#optional-general-properties", 
            "text": "The following properties can configure any call, and are not specific to this method.    -p $-xgafv=string   V1 error format.     -p access-token=string   OAuth access token.     -p alt=string   Data format for response.     -p callback=string   JSONP     -p fields=string   Selector specifying which fields to include in a partial response.     -p key=string   API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.     -p oauth-token=string   OAuth 2.0 token for the current user.     -p pretty-print=boolean   Returns response with indentations and line breaks.     -p quota-user=string   Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.     -p upload-type=string   Legacy upload protocol for media (e.g.  media ,  multipart ).     -p upload-protocol=string   Upload protocol for media (e.g.  raw ,  multipart ).", 
            "title": "Optional General Properties"
        }, 
        {
            "location": "/projects_models-versions-patch/", 
            "text": "Updates the specified Version resource.\n\n\nCurrently the only update-able fields are \ndescription\n and\n\nautoScaling.minNodes\n.\n\n\nScopes\n\n\nYou will need authorization for the \nhttps://www.googleapis.com/auth/cloud-platform\n scope to make a valid call.\n\n\nIf unset, the scope for this method defaults to \nhttps://www.googleapis.com/auth/cloud-platform\n.\nYou can set the scope for this method like this: \nml1 --scope \nscope\n projects models-versions-patch ...\n\n\nRequired Scalar Argument\n\n\n\n\nname\n \n(string)\n\n\nRequired. The name of the model.\n\n\n\n\n\n\n\n\nRequired Request Value\n\n\nThe request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure.\nIn the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely.\n\n\nFor example, a structure like this:\n\n\nGoogleCloudMlV1__Version:\n  auto-scaling:\n    min-nodes: integer\n  create-time: string\n  deployment-uri: string\n  description: string\n  error-message: string\n  etag: string\n  framework: string\n  is-default: boolean\n  labels: { string: string }\n  last-use-time: string\n  machine-type: string\n  manual-scaling:\n    nodes: integer\n  name: string\n  package-uris: [string]\n  prediction-class: string\n  python-version: string\n  runtime-version: string\n  service-account: string\n  state: string\n\n\n\n\n\ncan be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time.\n\n\n\n\n\n\n-r .auto-scaling    min-nodes=2\n\n\n\n\n\n\nOptional. The minimum number of nodes to allocate for this model. These\n    nodes are always up, starting from the time the model is deployed.\n    Therefore, the cost of operating this model will be at least\n    \nrate\n * \nmin_nodes\n * number of hours since last billing cycle,\n    where \nrate\n is the cost per node-hour as documented in the\n    \npricing guide\n,\n    even if no predictions are performed. There is additional cost for each\n    prediction performed.\n\n\nUnlike manual scaling, if the load gets too heavy for the nodes\nthat are up, the service will automatically add nodes to handle the\nincreased load as well as scale back as traffic drops, always maintaining\nat least \nmin_nodes\n. You will be charged for the time in which additional\nnodes are used.\n\n\nIf not specified, \nmin_nodes\n defaults to 0, in which case, when traffic\nto a model stops (and after a cool-down period), nodes will be shut down\nand no charges will be incurred until traffic to the model resumes.\n\n\nYou can set \nmin_nodes\n when creating the model version, and you can also\nupdate \nmin_nodes\n for an existing version:\n\npre\n\nupdate_body.json:\n{\n  \nautoScaling\n: {\n    \nminNodes\n: 5\n  }\n}\n\n/pre\n\nHTTP request:\n\npre\n\nPATCH\nhttps://ml.googleapis.com/v1/{name=projects/\n/models/\n/versions/*}?update_mask=autoScaling.minNodes\n-d @./update_body.json\n\n/pre\n\n\n\n\n\n\n\n\n\n\n..    create-time=sanctus\n\n\n\n\nOutput only. The time the version was created.\n\n\n\n\n\n\n\n\ndeployment-uri=dolore\n\n\n\n\n\n\nRequired. The Cloud Storage location of the trained model used to\n    create the version. See the\n    \nguide to model\n    deployment\n for more\n    information.\n\n\nWhen passing Version to\n\nprojects.models.versions.create\n\nthe model service uses the specified location as the source of the model.\nOnce deployed, the model version is hosted by the prediction service, so\nthis location is useful only as a historical record.\nThe total number of model files can\nt exceed 1000.\n* \ndescription=lorem\n\n    - Optional. The description specified for the version when it was created.\n* \nerror-message=consetetur\n\n    - Output only. The details of a failure or a cancellation.\n* \netag=consetetur\n\n    - \netag\n is used for optimistic concurrency control as a way to help\nprevent simultaneous updates of a model from overwriting each other.\nIt is strongly suggested that systems make use of the \netag\n in the\nread-modify-write cycle to perform model updates in order to avoid race\nconditions: An \netag\n is returned in the response to \nGetVersion\n, and\nsystems are expected to put that etag in the request to \nUpdateVersion\n to\nensure that their change will be applied to the model as intended.\n* \nframework=eirmod\n\n    - Optional. The machine learning framework AI Platform uses to train\nthis version of the model. Valid values are \nTENSORFLOW\n, \nSCIKIT_LEARN\n,\n\nXGBOOST\n. If you do not specify a framework, AI Platform\nwill analyze files in the deployment_uri to determine a framework. If you\nchoose \nSCIKIT_LEARN\n or \nXGBOOST\n, you must also set the runtime version\nof the model to 1.4 or greater.\n\n\nDo \nnot\n specify a framework if you\nre deploying a \ncustom\nprediction routine\n.\n* \nis-default=true\n\n    - Output only. If true, this version will be used to handle prediction\nrequests that do not specify a version.\n\n\nYou can change the default version by calling\n\nprojects.methods.versions.setDefault\n.\n* \nlabels=key=gubergren\n\n    - Optional. One or more labels that you can add, to organize your model\nversions. Each label is a key-value pair, where both the key and the value\nare arbitrary strings that you supply.\nFor more information, see the documentation on\n\na href=\n/ml-engine/docs/tensorflow/resource-labels\nusing labels\n/a\n.\n    - the value will be associated with the given \nkey\n\n* \nlast-use-time=et\n\n    - Output only. The time the version was last used for prediction.\n* \nmachine-type=sadipscing\n\n    - Optional. The type of machine on which to serve the model. Currently only\napplies to online prediction service.\n\ndl\n\n  \ndt\nmls1-c1-m2\n/dt\n\n  \ndd\n\n  The \nb\ndefault\n/b\n machine type, with 1 core and 2 GB RAM. The deprecated\n  name for this machine type is \nmls1-highmem-1\n.\n  \n/dd\n\n  \ndt\nmls1-c4-m2\n/dt\n\n  \ndd\n\n  In \nb\nBeta\n/b\n. This machine type has 4 cores and 2 GB RAM. The\n  deprecated name for this machine type is \nmls1-highcpu-4\n.\n  \n/dd\n\n\n/dl\n\n* \nmanual-scaling    nodes=28\n\n    - The number of nodes to allocate for this model. These nodes are always up,\nstarting from the time the model is deployed, so the cost of operating\nthis model will be proportional to \nnodes\n * number of hours since\nlast billing cycle plus the cost for each prediction performed.\n\n\n\n\n\n\n\n\n\n\n..    name=magna\n\n\n\n\n\n\nRequired.The name specified for the version when it was created.\n\n\nThe version name must be unique within the model it is created in.\n* \npackage-uris=lorem\n\n    - Optional. Cloud Storage paths (\ngs://\u2026\n) of packages for \ncustom\nprediction routines\n\nor \nscikit-learn pipelines with custom\ncode\n.\n\n\nFor a custom prediction routine, one of these packages must contain your\nPredictor class (see\n\npredictionClass\n). Additionally,\ninclude any dependencies used by your Predictor or scikit-learn pipeline\nuses that are not already included in your selected \nruntime\nversion\n.\n\n\nIf you specify this field, you must also set\n\nruntimeVersion\n to 1.4 or greater.\n    - Each invocation of this argument appends the given value to the array.\n* \nprediction-class=rebum.\n\n    - Optional. The fully qualified name\n(\nvar\nmodule_name\n/var\n.\nvar\nclass_name\n/var\n) of a class that implements\nthe Predictor interface described in this reference field. The module\ncontaining this class should be included in a package provided to the\n\npackageUris\n field\n.\n\n\nSpecify this field if and only if you are deploying a \ncustom prediction\nroutine (beta)\n.\nIf you specify this field, you must set\n\nruntimeVersion\n to 1.4 or greater.\n\n\nThe following code sample provides the Predictor interface:\n\n\n```py\nclass Predictor(object):\n\nInterface for constructing custom predictors.\n\n\ndef predict(self, instances, **kwargs):\n    \nPerforms custom prediction.\n\n\nInstances are the decoded values from the request. They have already\nbeen deserialized from JSON.\n\nArgs:\n    instances: A list of prediction input instances.\n    **kwargs: A dictionary of keyword args provided as additional\n        fields on the predict request body.\n\nReturns:\n    A list of outputs containing the prediction results. This list must\n    be JSON serializable.\n\n#34;\n#34;\n#34;\nraise NotImplementedError()\n\n\n\n@classmethod\ndef from_path(cls, model_dir):\n    \nCreates an instance of Predictor using the given path.\n\n\nLoading of the predictor should be done in this method.\n\nArgs:\n    model_dir: The local directory that contains the exported model\n        file along with any additional files uploaded when creating the\n        version resource.\n\nReturns:\n    An instance implementing this Predictor class.\n\n#34;\n#34;\n#34;\nraise NotImplementedError()\n\n\n\n```\n\n\nLearn more about \nthe Predictor interface and custom prediction\nroutines\n.\n* \npython-version=et\n\n    - Optional. The version of Python used in prediction. If not set, the default\nversion is \n2.7\n. Python \n3.5\n is available when \nruntime_version\n is set\nto \n1.4\n and above. Python \n2.7\n works with all supported runtime versions.\n* \nruntime-version=clita\n\n    - Optional. The AI Platform runtime version to use for this deployment.\nIf not set, AI Platform uses the default stable version, 1.0. For more\ninformation, see the\n\nruntime version list\n and\n\nhow to manage runtime versions\n.\n* \nservice-account=eos\n\n    - Optional. Specifies the service account for resource access control.\n* \nstate=dolores\n\n    - Output only. The state of a version.\n\n\n\n\n\n\n\n\n\n\nAbout Cursors\n\n\nThe cursor position is key to comfortably set complex nested structures. The following rules apply:\n\n\n\n\nThe cursor position is always set relative to the current one, unless the field name starts with the \n.\n character. Fields can be nested such as in \n-r f.s.o\n .\n\n\nThe cursor position is set relative to the top-level structure if it starts with \n.\n, e.g. \n-r .s.s\n\n\nYou can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify \n-r struct.sub_struct=bar\n.\n\n\nYou can move the cursor one level up by using \n..\n. Each additional \n.\n moves it up one additional level. E.g. \n...\n would go three levels up.\n\n\n\n\nOptional Output Flags\n\n\nThe method's return value a JSON encoded structure, which will be written to standard output by default.\n\n\n\n\n-o out\n\n\nout\n specifies the \ndestination\n to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The \ndestination\n may be \n-\n to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.\n\n\n\n\n\n\n\n\nOptional Method Properties\n\n\nYou may set the following properties to further configure the call. Please note that \n-p\n is followed by one \nor more key-value-pairs, and is called like this \n-p k1=v1 k2=v2\n even though the listing below repeats the\n\n-p\n for completeness.\n\n\n\n\n-p update-mask=string\n\n\n\n\nRequired. Specifies the path, relative to \nVersion\n, of the field to\n    update. Must be present and non-empty.\n\n\nFor example, to change the description of a version to \nfoo\n, the\n\nupdate_mask\n parameter would be specified as \ndescription\n, and the\n\nPATCH\n request body would specify the new value, as follows:\n    {\n      \ndescription\n: \nfoo\n\n    }\n\n\nCurrently the only supported update mask fields are \ndescription\n and\n\nautoScaling.minNodes\n.\n\n\n\n\n\n\n\n\n\n\nOptional General Properties\n\n\nThe following properties can configure any call, and are not specific to this method.\n\n\n\n\n\n\n-p $-xgafv=string\n\n\n\n\nV1 error format.\n\n\n\n\n\n\n\n\n-p access-token=string\n\n\n\n\nOAuth access token.\n\n\n\n\n\n\n\n\n-p alt=string\n\n\n\n\nData format for response.\n\n\n\n\n\n\n\n\n-p callback=string\n\n\n\n\nJSONP\n\n\n\n\n\n\n\n\n-p fields=string\n\n\n\n\nSelector specifying which fields to include in a partial response.\n\n\n\n\n\n\n\n\n-p key=string\n\n\n\n\nAPI key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.\n\n\n\n\n\n\n\n\n-p oauth-token=string\n\n\n\n\nOAuth 2.0 token for the current user.\n\n\n\n\n\n\n\n\n-p pretty-print=boolean\n\n\n\n\nReturns response with indentations and line breaks.\n\n\n\n\n\n\n\n\n-p quota-user=string\n\n\n\n\nAvailable to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.\n\n\n\n\n\n\n\n\n-p upload-type=string\n\n\n\n\nLegacy upload protocol for media (e.g. \nmedia\n, \nmultipart\n).\n\n\n\n\n\n\n\n\n-p upload-protocol=string\n\n\n\n\nUpload protocol for media (e.g. \nraw\n, \nmultipart\n).", 
            "title": "Models Versions Patch"
        }, 
        {
            "location": "/projects_models-versions-patch/#scopes", 
            "text": "You will need authorization for the  https://www.googleapis.com/auth/cloud-platform  scope to make a valid call.  If unset, the scope for this method defaults to  https://www.googleapis.com/auth/cloud-platform .\nYou can set the scope for this method like this:  ml1 --scope  scope  projects models-versions-patch ...", 
            "title": "Scopes"
        }, 
        {
            "location": "/projects_models-versions-patch/#required-scalar-argument", 
            "text": "name   (string)  Required. The name of the model.", 
            "title": "Required Scalar Argument"
        }, 
        {
            "location": "/projects_models-versions-patch/#required-request-value", 
            "text": "The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure.\nIn the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely.  For example, a structure like this:  GoogleCloudMlV1__Version:\n  auto-scaling:\n    min-nodes: integer\n  create-time: string\n  deployment-uri: string\n  description: string\n  error-message: string\n  etag: string\n  framework: string\n  is-default: boolean\n  labels: { string: string }\n  last-use-time: string\n  machine-type: string\n  manual-scaling:\n    nodes: integer\n  name: string\n  package-uris: [string]\n  prediction-class: string\n  python-version: string\n  runtime-version: string\n  service-account: string\n  state: string  can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time.    -r .auto-scaling    min-nodes=2    Optional. The minimum number of nodes to allocate for this model. These\n    nodes are always up, starting from the time the model is deployed.\n    Therefore, the cost of operating this model will be at least\n     rate  *  min_nodes  * number of hours since last billing cycle,\n    where  rate  is the cost per node-hour as documented in the\n     pricing guide ,\n    even if no predictions are performed. There is additional cost for each\n    prediction performed.  Unlike manual scaling, if the load gets too heavy for the nodes\nthat are up, the service will automatically add nodes to handle the\nincreased load as well as scale back as traffic drops, always maintaining\nat least  min_nodes . You will be charged for the time in which additional\nnodes are used.  If not specified,  min_nodes  defaults to 0, in which case, when traffic\nto a model stops (and after a cool-down period), nodes will be shut down\nand no charges will be incurred until traffic to the model resumes.  You can set  min_nodes  when creating the model version, and you can also\nupdate  min_nodes  for an existing version: pre \nupdate_body.json:\n{\n   autoScaling : {\n     minNodes : 5\n  }\n} /pre \nHTTP request: pre \nPATCH\nhttps://ml.googleapis.com/v1/{name=projects/ /models/ /versions/*}?update_mask=autoScaling.minNodes\n-d @./update_body.json /pre      ..    create-time=sanctus   Output only. The time the version was created.     deployment-uri=dolore    Required. The Cloud Storage location of the trained model used to\n    create the version. See the\n     guide to model\n    deployment  for more\n    information.  When passing Version to projects.models.versions.create \nthe model service uses the specified location as the source of the model.\nOnce deployed, the model version is hosted by the prediction service, so\nthis location is useful only as a historical record.\nThe total number of model files can t exceed 1000.\n*  description=lorem \n    - Optional. The description specified for the version when it was created.\n*  error-message=consetetur \n    - Output only. The details of a failure or a cancellation.\n*  etag=consetetur \n    -  etag  is used for optimistic concurrency control as a way to help\nprevent simultaneous updates of a model from overwriting each other.\nIt is strongly suggested that systems make use of the  etag  in the\nread-modify-write cycle to perform model updates in order to avoid race\nconditions: An  etag  is returned in the response to  GetVersion , and\nsystems are expected to put that etag in the request to  UpdateVersion  to\nensure that their change will be applied to the model as intended.\n*  framework=eirmod \n    - Optional. The machine learning framework AI Platform uses to train\nthis version of the model. Valid values are  TENSORFLOW ,  SCIKIT_LEARN , XGBOOST . If you do not specify a framework, AI Platform\nwill analyze files in the deployment_uri to determine a framework. If you\nchoose  SCIKIT_LEARN  or  XGBOOST , you must also set the runtime version\nof the model to 1.4 or greater.  Do  not  specify a framework if you re deploying a  custom\nprediction routine .\n*  is-default=true \n    - Output only. If true, this version will be used to handle prediction\nrequests that do not specify a version.  You can change the default version by calling projects.methods.versions.setDefault .\n*  labels=key=gubergren \n    - Optional. One or more labels that you can add, to organize your model\nversions. Each label is a key-value pair, where both the key and the value\nare arbitrary strings that you supply.\nFor more information, see the documentation on a href= /ml-engine/docs/tensorflow/resource-labels using labels /a .\n    - the value will be associated with the given  key \n*  last-use-time=et \n    - Output only. The time the version was last used for prediction.\n*  machine-type=sadipscing \n    - Optional. The type of machine on which to serve the model. Currently only\napplies to online prediction service. dl \n   dt mls1-c1-m2 /dt \n   dd \n  The  b default /b  machine type, with 1 core and 2 GB RAM. The deprecated\n  name for this machine type is  mls1-highmem-1 .\n   /dd \n   dt mls1-c4-m2 /dt \n   dd \n  In  b Beta /b . This machine type has 4 cores and 2 GB RAM. The\n  deprecated name for this machine type is  mls1-highcpu-4 .\n   /dd  /dl \n*  manual-scaling    nodes=28 \n    - The number of nodes to allocate for this model. These nodes are always up,\nstarting from the time the model is deployed, so the cost of operating\nthis model will be proportional to  nodes  * number of hours since\nlast billing cycle plus the cost for each prediction performed.      ..    name=magna    Required.The name specified for the version when it was created.  The version name must be unique within the model it is created in.\n*  package-uris=lorem \n    - Optional. Cloud Storage paths ( gs://\u2026 ) of packages for  custom\nprediction routines \nor  scikit-learn pipelines with custom\ncode .  For a custom prediction routine, one of these packages must contain your\nPredictor class (see predictionClass ). Additionally,\ninclude any dependencies used by your Predictor or scikit-learn pipeline\nuses that are not already included in your selected  runtime\nversion .  If you specify this field, you must also set runtimeVersion  to 1.4 or greater.\n    - Each invocation of this argument appends the given value to the array.\n*  prediction-class=rebum. \n    - Optional. The fully qualified name\n( var module_name /var . var class_name /var ) of a class that implements\nthe Predictor interface described in this reference field. The module\ncontaining this class should be included in a package provided to the packageUris  field .  Specify this field if and only if you are deploying a  custom prediction\nroutine (beta) .\nIf you specify this field, you must set runtimeVersion  to 1.4 or greater.  The following code sample provides the Predictor interface:  ```py\nclass Predictor(object): Interface for constructing custom predictors.  def predict(self, instances, **kwargs):\n     Performs custom prediction.  Instances are the decoded values from the request. They have already\nbeen deserialized from JSON.\n\nArgs:\n    instances: A list of prediction input instances.\n    **kwargs: A dictionary of keyword args provided as additional\n        fields on the predict request body.\n\nReturns:\n    A list of outputs containing the prediction results. This list must\n    be JSON serializable. #34; #34; #34;\nraise NotImplementedError()  @classmethod\ndef from_path(cls, model_dir):\n     Creates an instance of Predictor using the given path.  Loading of the predictor should be done in this method.\n\nArgs:\n    model_dir: The local directory that contains the exported model\n        file along with any additional files uploaded when creating the\n        version resource.\n\nReturns:\n    An instance implementing this Predictor class. #34; #34; #34;\nraise NotImplementedError()  ```  Learn more about  the Predictor interface and custom prediction\nroutines .\n*  python-version=et \n    - Optional. The version of Python used in prediction. If not set, the default\nversion is  2.7 . Python  3.5  is available when  runtime_version  is set\nto  1.4  and above. Python  2.7  works with all supported runtime versions.\n*  runtime-version=clita \n    - Optional. The AI Platform runtime version to use for this deployment.\nIf not set, AI Platform uses the default stable version, 1.0. For more\ninformation, see the runtime version list  and how to manage runtime versions .\n*  service-account=eos \n    - Optional. Specifies the service account for resource access control.\n*  state=dolores \n    - Output only. The state of a version.", 
            "title": "Required Request Value"
        }, 
        {
            "location": "/projects_models-versions-patch/#about-cursors", 
            "text": "The cursor position is key to comfortably set complex nested structures. The following rules apply:   The cursor position is always set relative to the current one, unless the field name starts with the  .  character. Fields can be nested such as in  -r f.s.o  .  The cursor position is set relative to the top-level structure if it starts with  . , e.g.  -r .s.s  You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify  -r struct.sub_struct=bar .  You can move the cursor one level up by using  .. . Each additional  .  moves it up one additional level. E.g.  ...  would go three levels up.", 
            "title": "About Cursors"
        }, 
        {
            "location": "/projects_models-versions-patch/#optional-output-flags", 
            "text": "The method's return value a JSON encoded structure, which will be written to standard output by default.   -o out  out  specifies the  destination  to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The  destination  may be  -  to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.", 
            "title": "Optional Output Flags"
        }, 
        {
            "location": "/projects_models-versions-patch/#optional-method-properties", 
            "text": "You may set the following properties to further configure the call. Please note that  -p  is followed by one \nor more key-value-pairs, and is called like this  -p k1=v1 k2=v2  even though the listing below repeats the -p  for completeness.   -p update-mask=string   Required. Specifies the path, relative to  Version , of the field to\n    update. Must be present and non-empty.  For example, to change the description of a version to  foo , the update_mask  parameter would be specified as  description , and the PATCH  request body would specify the new value, as follows:\n    {\n       description :  foo \n    }  Currently the only supported update mask fields are  description  and autoScaling.minNodes .", 
            "title": "Optional Method Properties"
        }, 
        {
            "location": "/projects_models-versions-patch/#optional-general-properties", 
            "text": "The following properties can configure any call, and are not specific to this method.    -p $-xgafv=string   V1 error format.     -p access-token=string   OAuth access token.     -p alt=string   Data format for response.     -p callback=string   JSONP     -p fields=string   Selector specifying which fields to include in a partial response.     -p key=string   API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.     -p oauth-token=string   OAuth 2.0 token for the current user.     -p pretty-print=boolean   Returns response with indentations and line breaks.     -p quota-user=string   Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.     -p upload-type=string   Legacy upload protocol for media (e.g.  media ,  multipart ).     -p upload-protocol=string   Upload protocol for media (e.g.  raw ,  multipart ).", 
            "title": "Optional General Properties"
        }, 
        {
            "location": "/projects_models-versions-set-default/", 
            "text": "Designates a version to be the default for the model.\n\n\nThe default version is used for prediction requests made against the model\nthat don\nt specify a version.\n\n\nThe first version to be created for a model is automatically set as the\ndefault. You must make any subsequent changes to the default version\nsetting manually using this method.\n\n\nScopes\n\n\nYou will need authorization for the \nhttps://www.googleapis.com/auth/cloud-platform\n scope to make a valid call.\n\n\nIf unset, the scope for this method defaults to \nhttps://www.googleapis.com/auth/cloud-platform\n.\nYou can set the scope for this method like this: \nml1 --scope \nscope\n projects models-versions-set-default ...\n\n\nRequired Scalar Argument\n\n\n\n\nname\n \n(string)\n\n\nRequired. The name of the version to make the default for the model. You\n    can get the names of all the versions of a model by calling\n    \nprojects.models.versions.list\n.\n\n\n\n\n\n\n\n\nRequired Request Value\n\n\nThe request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure.\nIn the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely.\n\n\nFor example, a structure like this:\n\n\nGoogleCloudMlV1__SetDefaultVersionRequest:\n\n\n\n\n\ncan be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time.\n\n\nAbout Cursors\n\n\nThe cursor position is key to comfortably set complex nested structures. The following rules apply:\n\n\n\n\nThe cursor position is always set relative to the current one, unless the field name starts with the \n.\n character. Fields can be nested such as in \n-r f.s.o\n .\n\n\nThe cursor position is set relative to the top-level structure if it starts with \n.\n, e.g. \n-r .s.s\n\n\nYou can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify \n-r struct.sub_struct=bar\n.\n\n\nYou can move the cursor one level up by using \n..\n. Each additional \n.\n moves it up one additional level. E.g. \n...\n would go three levels up.\n\n\n\n\nOptional Output Flags\n\n\nThe method's return value a JSON encoded structure, which will be written to standard output by default.\n\n\n\n\n-o out\n\n\nout\n specifies the \ndestination\n to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The \ndestination\n may be \n-\n to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.\n\n\n\n\n\n\n\n\nOptional General Properties\n\n\nThe following properties can configure any call, and are not specific to this method.\n\n\n\n\n\n\n-p $-xgafv=string\n\n\n\n\nV1 error format.\n\n\n\n\n\n\n\n\n-p access-token=string\n\n\n\n\nOAuth access token.\n\n\n\n\n\n\n\n\n-p alt=string\n\n\n\n\nData format for response.\n\n\n\n\n\n\n\n\n-p callback=string\n\n\n\n\nJSONP\n\n\n\n\n\n\n\n\n-p fields=string\n\n\n\n\nSelector specifying which fields to include in a partial response.\n\n\n\n\n\n\n\n\n-p key=string\n\n\n\n\nAPI key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.\n\n\n\n\n\n\n\n\n-p oauth-token=string\n\n\n\n\nOAuth 2.0 token for the current user.\n\n\n\n\n\n\n\n\n-p pretty-print=boolean\n\n\n\n\nReturns response with indentations and line breaks.\n\n\n\n\n\n\n\n\n-p quota-user=string\n\n\n\n\nAvailable to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.\n\n\n\n\n\n\n\n\n-p upload-type=string\n\n\n\n\nLegacy upload protocol for media (e.g. \nmedia\n, \nmultipart\n).\n\n\n\n\n\n\n\n\n-p upload-protocol=string\n\n\n\n\nUpload protocol for media (e.g. \nraw\n, \nmultipart\n).", 
            "title": "Models Versions Set Default"
        }, 
        {
            "location": "/projects_models-versions-set-default/#scopes", 
            "text": "You will need authorization for the  https://www.googleapis.com/auth/cloud-platform  scope to make a valid call.  If unset, the scope for this method defaults to  https://www.googleapis.com/auth/cloud-platform .\nYou can set the scope for this method like this:  ml1 --scope  scope  projects models-versions-set-default ...", 
            "title": "Scopes"
        }, 
        {
            "location": "/projects_models-versions-set-default/#required-scalar-argument", 
            "text": "name   (string)  Required. The name of the version to make the default for the model. You\n    can get the names of all the versions of a model by calling\n     projects.models.versions.list .", 
            "title": "Required Scalar Argument"
        }, 
        {
            "location": "/projects_models-versions-set-default/#required-request-value", 
            "text": "The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure.\nIn the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely.  For example, a structure like this:  GoogleCloudMlV1__SetDefaultVersionRequest:  can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time.", 
            "title": "Required Request Value"
        }, 
        {
            "location": "/projects_models-versions-set-default/#about-cursors", 
            "text": "The cursor position is key to comfortably set complex nested structures. The following rules apply:   The cursor position is always set relative to the current one, unless the field name starts with the  .  character. Fields can be nested such as in  -r f.s.o  .  The cursor position is set relative to the top-level structure if it starts with  . , e.g.  -r .s.s  You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify  -r struct.sub_struct=bar .  You can move the cursor one level up by using  .. . Each additional  .  moves it up one additional level. E.g.  ...  would go three levels up.", 
            "title": "About Cursors"
        }, 
        {
            "location": "/projects_models-versions-set-default/#optional-output-flags", 
            "text": "The method's return value a JSON encoded structure, which will be written to standard output by default.   -o out  out  specifies the  destination  to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The  destination  may be  -  to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.", 
            "title": "Optional Output Flags"
        }, 
        {
            "location": "/projects_models-versions-set-default/#optional-general-properties", 
            "text": "The following properties can configure any call, and are not specific to this method.    -p $-xgafv=string   V1 error format.     -p access-token=string   OAuth access token.     -p alt=string   Data format for response.     -p callback=string   JSONP     -p fields=string   Selector specifying which fields to include in a partial response.     -p key=string   API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.     -p oauth-token=string   OAuth 2.0 token for the current user.     -p pretty-print=boolean   Returns response with indentations and line breaks.     -p quota-user=string   Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.     -p upload-type=string   Legacy upload protocol for media (e.g.  media ,  multipart ).     -p upload-protocol=string   Upload protocol for media (e.g.  raw ,  multipart ).", 
            "title": "Optional General Properties"
        }, 
        {
            "location": "/projects_operations-cancel/", 
            "text": "Starts asynchronous cancellation on a long-running operation.  The server\nmakes a best effort to cancel the operation, but success is not\nguaranteed.  If the server doesn\nt support this method, it returns\n\ngoogle.rpc.Code.UNIMPLEMENTED\n.  Clients can use\nOperations.GetOperation or\nother methods to check whether the cancellation succeeded or whether the\noperation completed despite cancellation. On successful cancellation,\nthe operation is not deleted; instead, it becomes an operation with\nan Operation.error value with a google.rpc.Status.code of 1,\ncorresponding to \nCode.CANCELLED\n.\n\n\nScopes\n\n\nYou will need authorization for the \nhttps://www.googleapis.com/auth/cloud-platform\n scope to make a valid call.\n\n\nIf unset, the scope for this method defaults to \nhttps://www.googleapis.com/auth/cloud-platform\n.\nYou can set the scope for this method like this: \nml1 --scope \nscope\n projects operations-cancel ...\n\n\nRequired Scalar Argument\n\n\n\n\nname\n \n(string)\n\n\nThe name of the operation resource to be cancelled.\n\n\n\n\n\n\n\n\nOptional Output Flags\n\n\nThe method's return value a JSON encoded structure, which will be written to standard output by default.\n\n\n\n\n-o out\n\n\nout\n specifies the \ndestination\n to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The \ndestination\n may be \n-\n to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.\n\n\n\n\n\n\n\n\nOptional General Properties\n\n\nThe following properties can configure any call, and are not specific to this method.\n\n\n\n\n\n\n-p $-xgafv=string\n\n\n\n\nV1 error format.\n\n\n\n\n\n\n\n\n-p access-token=string\n\n\n\n\nOAuth access token.\n\n\n\n\n\n\n\n\n-p alt=string\n\n\n\n\nData format for response.\n\n\n\n\n\n\n\n\n-p callback=string\n\n\n\n\nJSONP\n\n\n\n\n\n\n\n\n-p fields=string\n\n\n\n\nSelector specifying which fields to include in a partial response.\n\n\n\n\n\n\n\n\n-p key=string\n\n\n\n\nAPI key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.\n\n\n\n\n\n\n\n\n-p oauth-token=string\n\n\n\n\nOAuth 2.0 token for the current user.\n\n\n\n\n\n\n\n\n-p pretty-print=boolean\n\n\n\n\nReturns response with indentations and line breaks.\n\n\n\n\n\n\n\n\n-p quota-user=string\n\n\n\n\nAvailable to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.\n\n\n\n\n\n\n\n\n-p upload-type=string\n\n\n\n\nLegacy upload protocol for media (e.g. \nmedia\n, \nmultipart\n).\n\n\n\n\n\n\n\n\n-p upload-protocol=string\n\n\n\n\nUpload protocol for media (e.g. \nraw\n, \nmultipart\n).", 
            "title": "Operations Cancel"
        }, 
        {
            "location": "/projects_operations-cancel/#scopes", 
            "text": "You will need authorization for the  https://www.googleapis.com/auth/cloud-platform  scope to make a valid call.  If unset, the scope for this method defaults to  https://www.googleapis.com/auth/cloud-platform .\nYou can set the scope for this method like this:  ml1 --scope  scope  projects operations-cancel ...", 
            "title": "Scopes"
        }, 
        {
            "location": "/projects_operations-cancel/#required-scalar-argument", 
            "text": "name   (string)  The name of the operation resource to be cancelled.", 
            "title": "Required Scalar Argument"
        }, 
        {
            "location": "/projects_operations-cancel/#optional-output-flags", 
            "text": "The method's return value a JSON encoded structure, which will be written to standard output by default.   -o out  out  specifies the  destination  to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The  destination  may be  -  to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.", 
            "title": "Optional Output Flags"
        }, 
        {
            "location": "/projects_operations-cancel/#optional-general-properties", 
            "text": "The following properties can configure any call, and are not specific to this method.    -p $-xgafv=string   V1 error format.     -p access-token=string   OAuth access token.     -p alt=string   Data format for response.     -p callback=string   JSONP     -p fields=string   Selector specifying which fields to include in a partial response.     -p key=string   API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.     -p oauth-token=string   OAuth 2.0 token for the current user.     -p pretty-print=boolean   Returns response with indentations and line breaks.     -p quota-user=string   Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.     -p upload-type=string   Legacy upload protocol for media (e.g.  media ,  multipart ).     -p upload-protocol=string   Upload protocol for media (e.g.  raw ,  multipart ).", 
            "title": "Optional General Properties"
        }, 
        {
            "location": "/projects_operations-get/", 
            "text": "Gets the latest state of a long-running operation.  Clients can use this\nmethod to poll the operation result at intervals as recommended by the API\nservice.\n\n\nScopes\n\n\nYou will need authorization for the \nhttps://www.googleapis.com/auth/cloud-platform\n scope to make a valid call.\n\n\nIf unset, the scope for this method defaults to \nhttps://www.googleapis.com/auth/cloud-platform\n.\nYou can set the scope for this method like this: \nml1 --scope \nscope\n projects operations-get ...\n\n\nRequired Scalar Argument\n\n\n\n\nname\n \n(string)\n\n\nThe name of the operation resource.\n\n\n\n\n\n\n\n\nOptional Output Flags\n\n\nThe method's return value a JSON encoded structure, which will be written to standard output by default.\n\n\n\n\n-o out\n\n\nout\n specifies the \ndestination\n to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The \ndestination\n may be \n-\n to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.\n\n\n\n\n\n\n\n\nOptional General Properties\n\n\nThe following properties can configure any call, and are not specific to this method.\n\n\n\n\n\n\n-p $-xgafv=string\n\n\n\n\nV1 error format.\n\n\n\n\n\n\n\n\n-p access-token=string\n\n\n\n\nOAuth access token.\n\n\n\n\n\n\n\n\n-p alt=string\n\n\n\n\nData format for response.\n\n\n\n\n\n\n\n\n-p callback=string\n\n\n\n\nJSONP\n\n\n\n\n\n\n\n\n-p fields=string\n\n\n\n\nSelector specifying which fields to include in a partial response.\n\n\n\n\n\n\n\n\n-p key=string\n\n\n\n\nAPI key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.\n\n\n\n\n\n\n\n\n-p oauth-token=string\n\n\n\n\nOAuth 2.0 token for the current user.\n\n\n\n\n\n\n\n\n-p pretty-print=boolean\n\n\n\n\nReturns response with indentations and line breaks.\n\n\n\n\n\n\n\n\n-p quota-user=string\n\n\n\n\nAvailable to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.\n\n\n\n\n\n\n\n\n-p upload-type=string\n\n\n\n\nLegacy upload protocol for media (e.g. \nmedia\n, \nmultipart\n).\n\n\n\n\n\n\n\n\n-p upload-protocol=string\n\n\n\n\nUpload protocol for media (e.g. \nraw\n, \nmultipart\n).", 
            "title": "Operations Get"
        }, 
        {
            "location": "/projects_operations-get/#scopes", 
            "text": "You will need authorization for the  https://www.googleapis.com/auth/cloud-platform  scope to make a valid call.  If unset, the scope for this method defaults to  https://www.googleapis.com/auth/cloud-platform .\nYou can set the scope for this method like this:  ml1 --scope  scope  projects operations-get ...", 
            "title": "Scopes"
        }, 
        {
            "location": "/projects_operations-get/#required-scalar-argument", 
            "text": "name   (string)  The name of the operation resource.", 
            "title": "Required Scalar Argument"
        }, 
        {
            "location": "/projects_operations-get/#optional-output-flags", 
            "text": "The method's return value a JSON encoded structure, which will be written to standard output by default.   -o out  out  specifies the  destination  to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The  destination  may be  -  to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.", 
            "title": "Optional Output Flags"
        }, 
        {
            "location": "/projects_operations-get/#optional-general-properties", 
            "text": "The following properties can configure any call, and are not specific to this method.    -p $-xgafv=string   V1 error format.     -p access-token=string   OAuth access token.     -p alt=string   Data format for response.     -p callback=string   JSONP     -p fields=string   Selector specifying which fields to include in a partial response.     -p key=string   API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.     -p oauth-token=string   OAuth 2.0 token for the current user.     -p pretty-print=boolean   Returns response with indentations and line breaks.     -p quota-user=string   Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.     -p upload-type=string   Legacy upload protocol for media (e.g.  media ,  multipart ).     -p upload-protocol=string   Upload protocol for media (e.g.  raw ,  multipart ).", 
            "title": "Optional General Properties"
        }, 
        {
            "location": "/projects_operations-list/", 
            "text": "Lists operations that match the specified filter in the request. If the\nserver doesn\nt support this method, it returns \nUNIMPLEMENTED\n.\n\n\nNOTE: the \nname\n binding allows API services to override the binding\nto use different resource name schemes, such as \nusers/*/operations\n. To\noverride the binding, API services can add a binding such as\n\n#34;/v1/{name=users/*}/operations\n#34;\n to their service configuration.\nFor backwards compatibility, the default name includes the operations\ncollection id, however overriding users must ensure the name binding\nis the parent resource, without the operations collection id.\n\n\nScopes\n\n\nYou will need authorization for the \nhttps://www.googleapis.com/auth/cloud-platform\n scope to make a valid call.\n\n\nIf unset, the scope for this method defaults to \nhttps://www.googleapis.com/auth/cloud-platform\n.\nYou can set the scope for this method like this: \nml1 --scope \nscope\n projects operations-list ...\n\n\nRequired Scalar Argument\n\n\n\n\nname\n \n(string)\n\n\nThe name of the operation\ns parent resource.\n\n\n\n\n\n\n\n\nOptional Output Flags\n\n\nThe method's return value a JSON encoded structure, which will be written to standard output by default.\n\n\n\n\n-o out\n\n\nout\n specifies the \ndestination\n to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The \ndestination\n may be \n-\n to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.\n\n\n\n\n\n\n\n\nOptional Method Properties\n\n\nYou may set the following properties to further configure the call. Please note that \n-p\n is followed by one \nor more key-value-pairs, and is called like this \n-p k1=v1 k2=v2\n even though the listing below repeats the\n\n-p\n for completeness.\n\n\n\n\n\n\n-p filter=string\n\n\n\n\nThe standard list filter.\n\n\n\n\n\n\n\n\n-p page-token=string\n\n\n\n\nThe standard list page token.\n\n\n\n\n\n\n\n\n-p page-size=integer\n\n\n\n\nThe standard list page size.\n\n\n\n\n\n\n\n\nOptional General Properties\n\n\nThe following properties can configure any call, and are not specific to this method.\n\n\n\n\n\n\n-p $-xgafv=string\n\n\n\n\nV1 error format.\n\n\n\n\n\n\n\n\n-p access-token=string\n\n\n\n\nOAuth access token.\n\n\n\n\n\n\n\n\n-p alt=string\n\n\n\n\nData format for response.\n\n\n\n\n\n\n\n\n-p callback=string\n\n\n\n\nJSONP\n\n\n\n\n\n\n\n\n-p fields=string\n\n\n\n\nSelector specifying which fields to include in a partial response.\n\n\n\n\n\n\n\n\n-p key=string\n\n\n\n\nAPI key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.\n\n\n\n\n\n\n\n\n-p oauth-token=string\n\n\n\n\nOAuth 2.0 token for the current user.\n\n\n\n\n\n\n\n\n-p pretty-print=boolean\n\n\n\n\nReturns response with indentations and line breaks.\n\n\n\n\n\n\n\n\n-p quota-user=string\n\n\n\n\nAvailable to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.\n\n\n\n\n\n\n\n\n-p upload-type=string\n\n\n\n\nLegacy upload protocol for media (e.g. \nmedia\n, \nmultipart\n).\n\n\n\n\n\n\n\n\n-p upload-protocol=string\n\n\n\n\nUpload protocol for media (e.g. \nraw\n, \nmultipart\n).", 
            "title": "Operations List"
        }, 
        {
            "location": "/projects_operations-list/#scopes", 
            "text": "You will need authorization for the  https://www.googleapis.com/auth/cloud-platform  scope to make a valid call.  If unset, the scope for this method defaults to  https://www.googleapis.com/auth/cloud-platform .\nYou can set the scope for this method like this:  ml1 --scope  scope  projects operations-list ...", 
            "title": "Scopes"
        }, 
        {
            "location": "/projects_operations-list/#required-scalar-argument", 
            "text": "name   (string)  The name of the operation s parent resource.", 
            "title": "Required Scalar Argument"
        }, 
        {
            "location": "/projects_operations-list/#optional-output-flags", 
            "text": "The method's return value a JSON encoded structure, which will be written to standard output by default.   -o out  out  specifies the  destination  to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The  destination  may be  -  to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.", 
            "title": "Optional Output Flags"
        }, 
        {
            "location": "/projects_operations-list/#optional-method-properties", 
            "text": "You may set the following properties to further configure the call. Please note that  -p  is followed by one \nor more key-value-pairs, and is called like this  -p k1=v1 k2=v2  even though the listing below repeats the -p  for completeness.    -p filter=string   The standard list filter.     -p page-token=string   The standard list page token.     -p page-size=integer   The standard list page size.", 
            "title": "Optional Method Properties"
        }, 
        {
            "location": "/projects_operations-list/#optional-general-properties", 
            "text": "The following properties can configure any call, and are not specific to this method.    -p $-xgafv=string   V1 error format.     -p access-token=string   OAuth access token.     -p alt=string   Data format for response.     -p callback=string   JSONP     -p fields=string   Selector specifying which fields to include in a partial response.     -p key=string   API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.     -p oauth-token=string   OAuth 2.0 token for the current user.     -p pretty-print=boolean   Returns response with indentations and line breaks.     -p quota-user=string   Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.     -p upload-type=string   Legacy upload protocol for media (e.g.  media ,  multipart ).     -p upload-protocol=string   Upload protocol for media (e.g.  raw ,  multipart ).", 
            "title": "Optional General Properties"
        }, 
        {
            "location": "/projects_predict/", 
            "text": "Performs prediction on the data in the request.\nAI Platform implements a custom \npredict\n verb on top of an HTTP POST\nmethod. \np\nFor details of the request and response format, see the \nguide\nto the \npredict request format\n.\n\n\nScopes\n\n\nYou will need authorization for the \nhttps://www.googleapis.com/auth/cloud-platform\n scope to make a valid call.\n\n\nIf unset, the scope for this method defaults to \nhttps://www.googleapis.com/auth/cloud-platform\n.\nYou can set the scope for this method like this: \nml1 --scope \nscope\n projects predict ...\n\n\nRequired Scalar Argument\n\n\n\n\nname\n \n(string)\n\n\n\n\nRequired. The resource name of a model or a version.\n\n\nAuthorization: requires the \npredict\n permission on the specified resource.\n\n\nRequired Request Value\n\n\n\n\n\n\n\n\n\n\nThe request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure.\nIn the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely.\n\n\nFor example, a structure like this:\n\n\nGoogleCloudMlV1__PredictRequest:\n  http-body:\n    content-type: string\n    data: string\n\n\n\n\n\ncan be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time.\n\n\n\n\n-r .http-body    content-type=vero\n\n\nThe HTTP Content-Type header value specifying the content type of the body.\n\n\n\n\n\n\ndata=consetetur\n\n\nThe HTTP request/response body as raw binary.\n\n\n\n\n\n\n\n\nAbout Cursors\n\n\nThe cursor position is key to comfortably set complex nested structures. The following rules apply:\n\n\n\n\nThe cursor position is always set relative to the current one, unless the field name starts with the \n.\n character. Fields can be nested such as in \n-r f.s.o\n .\n\n\nThe cursor position is set relative to the top-level structure if it starts with \n.\n, e.g. \n-r .s.s\n\n\nYou can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify \n-r struct.sub_struct=bar\n.\n\n\nYou can move the cursor one level up by using \n..\n. Each additional \n.\n moves it up one additional level. E.g. \n...\n would go three levels up.\n\n\n\n\nOptional Output Flags\n\n\nThe method's return value a JSON encoded structure, which will be written to standard output by default.\n\n\n\n\n-o out\n\n\nout\n specifies the \ndestination\n to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The \ndestination\n may be \n-\n to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.\n\n\n\n\n\n\n\n\nOptional General Properties\n\n\nThe following properties can configure any call, and are not specific to this method.\n\n\n\n\n\n\n-p $-xgafv=string\n\n\n\n\nV1 error format.\n\n\n\n\n\n\n\n\n-p access-token=string\n\n\n\n\nOAuth access token.\n\n\n\n\n\n\n\n\n-p alt=string\n\n\n\n\nData format for response.\n\n\n\n\n\n\n\n\n-p callback=string\n\n\n\n\nJSONP\n\n\n\n\n\n\n\n\n-p fields=string\n\n\n\n\nSelector specifying which fields to include in a partial response.\n\n\n\n\n\n\n\n\n-p key=string\n\n\n\n\nAPI key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.\n\n\n\n\n\n\n\n\n-p oauth-token=string\n\n\n\n\nOAuth 2.0 token for the current user.\n\n\n\n\n\n\n\n\n-p pretty-print=boolean\n\n\n\n\nReturns response with indentations and line breaks.\n\n\n\n\n\n\n\n\n-p quota-user=string\n\n\n\n\nAvailable to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.\n\n\n\n\n\n\n\n\n-p upload-type=string\n\n\n\n\nLegacy upload protocol for media (e.g. \nmedia\n, \nmultipart\n).\n\n\n\n\n\n\n\n\n-p upload-protocol=string\n\n\n\n\nUpload protocol for media (e.g. \nraw\n, \nmultipart\n).", 
            "title": "Predict"
        }, 
        {
            "location": "/projects_predict/#scopes", 
            "text": "You will need authorization for the  https://www.googleapis.com/auth/cloud-platform  scope to make a valid call.  If unset, the scope for this method defaults to  https://www.googleapis.com/auth/cloud-platform .\nYou can set the scope for this method like this:  ml1 --scope  scope  projects predict ...", 
            "title": "Scopes"
        }, 
        {
            "location": "/projects_predict/#required-scalar-argument", 
            "text": "name   (string)   Required. The resource name of a model or a version.  Authorization: requires the  predict  permission on the specified resource.", 
            "title": "Required Scalar Argument"
        }, 
        {
            "location": "/projects_predict/#required-request-value", 
            "text": "The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure.\nIn the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely.  For example, a structure like this:  GoogleCloudMlV1__PredictRequest:\n  http-body:\n    content-type: string\n    data: string  can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time.   -r .http-body    content-type=vero  The HTTP Content-Type header value specifying the content type of the body.    data=consetetur  The HTTP request/response body as raw binary.", 
            "title": "Required Request Value"
        }, 
        {
            "location": "/projects_predict/#about-cursors", 
            "text": "The cursor position is key to comfortably set complex nested structures. The following rules apply:   The cursor position is always set relative to the current one, unless the field name starts with the  .  character. Fields can be nested such as in  -r f.s.o  .  The cursor position is set relative to the top-level structure if it starts with  . , e.g.  -r .s.s  You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify  -r struct.sub_struct=bar .  You can move the cursor one level up by using  .. . Each additional  .  moves it up one additional level. E.g.  ...  would go three levels up.", 
            "title": "About Cursors"
        }, 
        {
            "location": "/projects_predict/#optional-output-flags", 
            "text": "The method's return value a JSON encoded structure, which will be written to standard output by default.   -o out  out  specifies the  destination  to which to write the server's result to.\n  It will be a JSON-encoded structure.\n  The  destination  may be  -  to indicate standard output, or a filepath that is to contain the received bytes.\n  If unset, it defaults to standard output.", 
            "title": "Optional Output Flags"
        }, 
        {
            "location": "/projects_predict/#optional-general-properties", 
            "text": "The following properties can configure any call, and are not specific to this method.    -p $-xgafv=string   V1 error format.     -p access-token=string   OAuth access token.     -p alt=string   Data format for response.     -p callback=string   JSONP     -p fields=string   Selector specifying which fields to include in a partial response.     -p key=string   API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.     -p oauth-token=string   OAuth 2.0 token for the current user.     -p pretty-print=boolean   Returns response with indentations and line breaks.     -p quota-user=string   Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.     -p upload-type=string   Legacy upload protocol for media (e.g.  media ,  multipart ).     -p upload-protocol=string   Upload protocol for media (e.g.  raw ,  multipart ).", 
            "title": "Optional General Properties"
        }
    ]
}