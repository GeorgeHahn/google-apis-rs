initSidebarItems({"enum":[["Error",""],["Scope","Identifies the an OAuth2 authorization scope. A scope is needed when requesting an authorization token."]],"fn":[["remove_json_null_values",""]],"struct":[["BeginTransactionRequest","The request for BeginTransaction."],["Binding","Associates `members` with a `role`."],["ChildLink","Metadata associated with a parent-child relationship appearing in a PlanNode."],["Chunk",""],["CommitRequest","The request for Commit."],["CommitResponse","The response for Commit."],["ContentRange","Implements the Content-Range header, for serialization only"],["CreateDatabaseRequest","The request for CreateDatabase."],["CreateInstanceRequest","The request for CreateInstance."],["CreateSessionRequest","The request for CreateSession."],["Database","A Cloud Spanner database."],["DefaultDelegate","A delegate with a conservative default implementation, which is used if no other delegate is set."],["Delete","Arguments to delete operations."],["DummyNetworkStream",""],["Empty","A generic empty message that you can re-use to avoid defining duplicated empty messages in your APIs. A typical example is to use it as the request or the response type of an API method. For instance:"],["ErrorResponse","A utility to represent detailed errors we might see in case there are BadRequests. The latter happen if the sent parameters or request structures are unsound"],["ExecuteBatchDmlRequest","The request for ExecuteBatchDml"],["ExecuteBatchDmlResponse","The response for ExecuteBatchDml. Contains a list of ResultSet, one for each DML statement that has successfully executed. If a statement fails, the error is returned as part of the response payload. Clients can determine whether all DML statements have run successfully, or if a statement failed, using one of the following approaches:"],["ExecuteSqlRequest","The request for ExecuteSql and ExecuteStreamingSql."],["Expr","Represents an expression text. Example:"],["Field","Message representing a single field of a struct."],["GetDatabaseDdlResponse","The response for GetDatabaseDdl."],["GetIamPolicyRequest","Request message for `GetIamPolicy` method."],["Instance","An isolated set of Cloud Spanner resources on which databases can be hosted."],["InstanceConfig","A possible configuration for a Cloud Spanner instance. Configurations define the geographic placement of nodes and their replication."],["JsonServerError","A utility type which can decode a server response that indicates error"],["KeyRange","KeyRange represents a range of rows in a table or index."],["KeySet","`KeySet` defines a collection of Cloud Spanner keys and/or key ranges. All the keys are expected to be in the same table or index. The keys need not be sorted in any particular way."],["ListDatabasesResponse","The response for ListDatabases."],["ListInstanceConfigsResponse","The response for ListInstanceConfigs."],["ListInstancesResponse","The response for ListInstances."],["ListOperationsResponse","The response message for Operations.ListOperations."],["ListSessionsResponse","The response for ListSessions."],["MethodInfo","Contains information about an API request."],["MultiPartReader","Provides a `Read` interface that converts multiple parts into the protocol identified by RFC2387. Note: This implementation is just as rich as it needs to be to perform uploads to google APIs, and might not be a fully-featured implementation."],["Mutation","A modification to one or more Cloud Spanner rows.  Mutations can be applied to a Cloud Spanner database by sending them in a Commit call."],["Operation","This resource represents a long-running operation that is the result of a network API call."],["PartialResultSet","Partial results from a streaming read or SQL query. Streaming reads and SQL queries better tolerate large result sets, large rows, and large values, but are a little trickier to consume."],["Partition","Information returned for each partition returned in a PartitionResponse."],["PartitionOptions","Options for a PartitionQueryRequest and PartitionReadRequest."],["PartitionQueryRequest","The request for PartitionQuery"],["PartitionReadRequest","The request for PartitionRead"],["PartitionResponse","The response for PartitionQuery or PartitionRead"],["PartitionedDml","Message type to initiate a Partitioned DML transaction."],["PlanNode","Node information for nodes appearing in a QueryPlan.plan_nodes."],["Policy","Defines an Identity and Access Management (IAM) policy. It is used to specify access control policies for Cloud Platform resources."],["ProjectInstanceConfigGetCall","Gets information about a particular instance configuration."],["ProjectInstanceConfigListCall","Lists the supported instance configurations for a given project."],["ProjectInstanceCreateCall","Creates an instance and begins preparing it to begin serving. The returned long-running operation can be used to track the progress of preparing the new instance. The instance name is assigned by the caller. If the named instance already exists, `CreateInstance` returns `ALREADY_EXISTS`."],["ProjectInstanceDatabaseCreateCall","Creates a new Cloud Spanner database and starts to prepare it for serving. The returned long-running operation will have a name of the format `<database_name>/operations/<operation_id>` and can be used to track preparation of the database. The metadata field type is CreateDatabaseMetadata. The response field type is Database, if successful."],["ProjectInstanceDatabaseDropDatabaseCall","Drops (aka deletes) a Cloud Spanner database."],["ProjectInstanceDatabaseGetCall","Gets the state of a Cloud Spanner database."],["ProjectInstanceDatabaseGetDdlCall","Returns the schema of a Cloud Spanner database as a list of formatted DDL statements. This method does not show pending schema updates, those may be queried using the Operations API."],["ProjectInstanceDatabaseGetIamPolicyCall","Gets the access control policy for a database resource. Returns an empty policy if a database exists but does not have a policy set."],["ProjectInstanceDatabaseListCall","Lists Cloud Spanner databases."],["ProjectInstanceDatabaseOperationCancelCall","Starts asynchronous cancellation on a long-running operation.  The server makes a best effort to cancel the operation, but success is not guaranteed.  If the server doesn't support this method, it returns `google.rpc.Code.UNIMPLEMENTED`.  Clients can use Operations.GetOperation or other methods to check whether the cancellation succeeded or whether the operation completed despite cancellation. On successful cancellation, the operation is not deleted; instead, it becomes an operation with an Operation.error value with a google.rpc.Status.code of 1, corresponding to `Code.CANCELLED`."],["ProjectInstanceDatabaseOperationDeleteCall","Deletes a long-running operation. This method indicates that the client is no longer interested in the operation result. It does not cancel the operation. If the server doesn't support this method, it returns `google.rpc.Code.UNIMPLEMENTED`."],["ProjectInstanceDatabaseOperationGetCall","Gets the latest state of a long-running operation.  Clients can use this method to poll the operation result at intervals as recommended by the API service."],["ProjectInstanceDatabaseOperationListCall","Lists operations that match the specified filter in the request. If the server doesn't support this method, it returns `UNIMPLEMENTED`."],["ProjectInstanceDatabaseSessionBeginTransactionCall","Begins a new transaction. This step can often be skipped: Read, ExecuteSql and Commit can begin a new transaction as a side-effect."],["ProjectInstanceDatabaseSessionCommitCall","Commits a transaction. The request includes the mutations to be applied to rows in the database."],["ProjectInstanceDatabaseSessionCreateCall","Creates a new session. A session can be used to perform transactions that read and/or modify data in a Cloud Spanner database. Sessions are meant to be reused for many consecutive transactions."],["ProjectInstanceDatabaseSessionDeleteCall","Ends a session, releasing server resources associated with it. This will asynchronously trigger cancellation of any operations that are running with this session."],["ProjectInstanceDatabaseSessionExecuteBatchDmlCall","Executes a batch of SQL DML statements. This method allows many statements to be run with lower latency than submitting them sequentially with ExecuteSql."],["ProjectInstanceDatabaseSessionExecuteSqlCall","Executes an SQL statement, returning all results in a single reply. This method cannot be used to return a result set larger than 10 MiB; if the query yields more data than that, the query fails with a `FAILED_PRECONDITION` error."],["ProjectInstanceDatabaseSessionExecuteStreamingSqlCall","Like ExecuteSql, except returns the result set as a stream. Unlike ExecuteSql, there is no limit on the size of the returned result set. However, no individual row in the result set can exceed 100 MiB, and no column value can exceed 10 MiB."],["ProjectInstanceDatabaseSessionGetCall","Gets a session. Returns `NOT_FOUND` if the session does not exist. This is mainly useful for determining whether a session is still alive."],["ProjectInstanceDatabaseSessionListCall","Lists all sessions in a given database."],["ProjectInstanceDatabaseSessionPartitionQueryCall","Creates a set of partition tokens that can be used to execute a query operation in parallel.  Each of the returned partition tokens can be used by ExecuteStreamingSql to specify a subset of the query result to read.  The same session and read-only transaction must be used by the PartitionQueryRequest used to create the partition tokens and the ExecuteSqlRequests that use the partition tokens."],["ProjectInstanceDatabaseSessionPartitionReadCall","Creates a set of partition tokens that can be used to execute a read operation in parallel.  Each of the returned partition tokens can be used by StreamingRead to specify a subset of the read result to read.  The same session and read-only transaction must be used by the PartitionReadRequest used to create the partition tokens and the ReadRequests that use the partition tokens.  There are no ordering guarantees on rows returned among the returned partition tokens, or even within each individual StreamingRead call issued with a partition_token."],["ProjectInstanceDatabaseSessionReadCall","Reads rows from the database using key lookups and scans, as a simple key/value style alternative to ExecuteSql.  This method cannot be used to return a result set larger than 10 MiB; if the read matches more data than that, the read fails with a `FAILED_PRECONDITION` error."],["ProjectInstanceDatabaseSessionRollbackCall","Rolls back a transaction, releasing any locks it holds. It is a good idea to call this for any transaction that includes one or more Read or ExecuteSql requests and ultimately decides not to commit."],["ProjectInstanceDatabaseSessionStreamingReadCall","Like Read, except returns the result set as a stream. Unlike Read, there is no limit on the size of the returned result set. However, no individual row in the result set can exceed 100 MiB, and no column value can exceed 10 MiB."],["ProjectInstanceDatabaseSetIamPolicyCall","Sets the access control policy on a database resource. Replaces any existing policy."],["ProjectInstanceDatabaseTestIamPermissionCall","Returns permissions that the caller has on the specified database resource."],["ProjectInstanceDatabaseUpdateDdlCall","Updates the schema of a Cloud Spanner database by creating/altering/dropping tables, columns, indexes, etc. The returned long-running operation will have a name of the format `<database_name>/operations/<operation_id>` and can be used to track execution of the schema change(s). The metadata field type is UpdateDatabaseDdlMetadata.  The operation has no response."],["ProjectInstanceDeleteCall","Deletes an instance."],["ProjectInstanceGetCall","Gets information about a particular instance."],["ProjectInstanceGetIamPolicyCall","Gets the access control policy for an instance resource. Returns an empty policy if an instance exists but does not have a policy set."],["ProjectInstanceListCall","Lists all instances in the given project."],["ProjectInstanceOperationCancelCall","Starts asynchronous cancellation on a long-running operation.  The server makes a best effort to cancel the operation, but success is not guaranteed.  If the server doesn't support this method, it returns `google.rpc.Code.UNIMPLEMENTED`.  Clients can use Operations.GetOperation or other methods to check whether the cancellation succeeded or whether the operation completed despite cancellation. On successful cancellation, the operation is not deleted; instead, it becomes an operation with an Operation.error value with a google.rpc.Status.code of 1, corresponding to `Code.CANCELLED`."],["ProjectInstanceOperationDeleteCall","Deletes a long-running operation. This method indicates that the client is no longer interested in the operation result. It does not cancel the operation. If the server doesn't support this method, it returns `google.rpc.Code.UNIMPLEMENTED`."],["ProjectInstanceOperationGetCall","Gets the latest state of a long-running operation.  Clients can use this method to poll the operation result at intervals as recommended by the API service."],["ProjectInstanceOperationListCall","Lists operations that match the specified filter in the request. If the server doesn't support this method, it returns `UNIMPLEMENTED`."],["ProjectInstancePatchCall","Updates an instance, and begins allocating or releasing resources as requested. The returned long-running operation can be used to track the progress of updating the instance. If the named instance does not exist, returns `NOT_FOUND`."],["ProjectInstanceSetIamPolicyCall","Sets the access control policy on an instance resource. Replaces any existing policy."],["ProjectInstanceTestIamPermissionCall","Returns permissions that the caller has on the specified instance resource."],["ProjectMethods","A builder providing access to all methods supported on project resources. It is not used directly, but through the `Spanner` hub."],["QueryPlan","Contains an ordered list of nodes appearing in the query plan."],["RangeResponseHeader",""],["ReadOnly","Message type to initiate a read-only transaction."],["ReadRequest","The request for Read and StreamingRead."],["ReadWrite","Message type to initiate a read-write transaction. Currently this transaction type has no options."],["ReplicaInfo","There is no detailed description."],["ResultSet","Results from Read or ExecuteSql."],["ResultSetMetadata","Metadata about a ResultSet or PartialResultSet."],["ResultSetStats","Additional statistics about a ResultSet or PartialResultSet."],["ResumableUploadHelper","A utility type to perform a resumable upload from start to end."],["RollbackRequest","The request for Rollback."],["ServerError",""],["ServerMessage",""],["Session","A session in the Cloud Spanner API."],["SetIamPolicyRequest","Request message for `SetIamPolicy` method."],["ShortRepresentation","Condensed representation of a node and its subtree. Only present for `SCALAR` PlanNode(s)."],["Spanner","Central instance to access all Spanner related resource activities"],["Statement","A single DML statement."],["Status","The `Status` type defines a logical error model that is suitable for different programming environments, including REST APIs and RPC APIs. It is used by gRPC. Each `Status` message contains three pieces of data: error code, error message, and error details."],["StructType","`StructType` defines the fields of a STRUCT type."],["TestIamPermissionsRequest","Request message for `TestIamPermissions` method."],["TestIamPermissionsResponse","Response message for `TestIamPermissions` method."],["Transaction","A transaction."],["TransactionOptions","Transactions"],["TransactionSelector","This message is used to select the transaction in which a Read or ExecuteSql call runs."],["Type","`Type` indicates the type of a Cloud Spanner value, as might be stored in a table cell or returned from an SQL query."],["UpdateDatabaseDdlRequest","Enqueues the given DDL statements to be applied, in order but not necessarily all at once, to the database schema at some point (or points) in the future. The server checks that the statements are executable (syntactically valid, name tables that exist, etc.) before enqueueing them, but they may still fail upon later execution (e.g., if a statement from another batch of statements is applied first and it conflicts in some way, or if there is some data-related problem like a `NULL` value in a column to which `NOT NULL` would be added). If a statement fails, all subsequent statements in the batch are automatically cancelled."],["UpdateInstanceRequest","The request for UpdateInstance."],["Write","Arguments to insert, update, insert_or_update, and replace operations."],["XUploadContentType","The `X-Upload-Content-Type` header."]],"trait":[["CallBuilder","Identifies types which represent builders for a particular resource method"],["Delegate","A trait specifying functionality to help controlling any request performed by the API. The trait has a conservative default implementation."],["Hub","Identifies the Hub. There is only one per library, this trait is supposed to make intended use more explicit. The hub allows to access all resource methods more easily."],["MethodsBuilder","Identifies types for building methods of a particular resource type"],["NestedType","Identifies types which are only used by other types internally. They have no special meaning, this trait just marks them for completeness."],["Part","Identifies types which are only used as part of other types, which usually are carrying the `Resource` trait."],["ReadSeek","A utility to specify reader types which provide seeking capabilities too"],["RequestValue","Identifies types which are used in API requests."],["Resource","Identifies types which can be inserted and deleted. Types with this trait are most commonly used by clients of this API."],["ResponseResult","Identifies types which are used in API responses."],["ToParts","A trait for all types that can convert themselves into a parts string"],["UnusedType","Identifies types which are not actually used by the API This might be a bug within the google API schema."]],"type":[["Result","A universal result type used as return for all calls."]]});